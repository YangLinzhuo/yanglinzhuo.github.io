<!DOCTYPE html><html lang="zh-CN"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=2"/><meta name="theme-color" content="#222"/><meta http-equiv="X-UA-COMPATIBLE" content="IE=edge,chrome=1"/><meta name="renderer" content="webkit"/><link rel="icon" type="image/ico" sizes="32x32" href="/assets/favicon.ico"/><link rel="apple-touch-icon" sizes="180x180" href="/assets/apple-touch-icon.png"/><meta name="google-site-verification" content="Ig99nzT1giHSuUb64OgOizEW1I6xFnRm9g9SFZaybjs"/><link rel="alternate" href="/rss.xml" title="林•初夏" type="application/rss+xml"><link rel="alternate" href="/atom.xml" title="林•初夏" type="application/atom+xml"><link rel="alternate" type="application/json" title="林•初夏" href="https://linn-ylz.com/feed.json"/><link rel="preconnect" href="https://s4.zstatic.net"/><link rel="preconnect" href="https://at.alicdn.com"/><link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Mulish:400,400italic,700,700italic%7CFredericka%20the%20Great:400,400italic,700,700italic%7CNoto%20Serif%20JP:400,400italic,700,700italic%7CNoto%20Serif%20SC:400,400italic,700,700italic%7CInconsolata:400,400italic,700,700italic&display=swap&subset=latin,latin-ext" media="none" onload="this.media&#x3D;&#39;all&#39;"><link rel="stylesheet" href="/css/app.css?v=0.4.21"><link rel="modulepreload" href="/js/chunk-6AJ2PQW3.js"></link><link rel="modulepreload" href="/js/chunk-BRN6GUAA.js"></link><link rel="modulepreload" href="/js/chunk-KRBLNQRW.js"></link><link rel="modulepreload" href="/js/chunk-VGO2KDCQ.js"></link><link rel="modulepreload" href="/js/chunk-WIQECBEN.js"></link><link rel="modulepreload" href="/js/comments-4RLTOHUO.js"></link><link rel="modulepreload" href="/js/copy-tex-K5C7WGAF.js"></link><link rel="modulepreload" href="/js/index.esm-I2SPRUW7.js"></link><link rel="modulepreload" href="/js/post-CKJWHVRN.js"></link><link rel="modulepreload" href="/js/quicklink-3PXSLVVU.js"></link><link rel="modulepreload" href="/js/siteInit.js"></link><link rel="modulepreload" href="/js/waline-OYD5BWGN.js"></link><link rel="stylesheet" href="/css/comments-F4ZGS7LD.css" media="none" onload="this.media&#x3D;&#39;all&#39;"></link><link rel="stylesheet" href="/css/siteInit.css" media="none" onload="this.media&#x3D;&#39;all&#39;"></link><link rel="stylesheet" href="/css/waline-IDNZKML2.css" media="none" onload="this.media&#x3D;&#39;all&#39;"></link><link rel="preload" href="https://cdn.jsdelivr.net/gh/YangLinzhuo/yanglinzhuo.github.io@latest/images/article-cover/img(14).webp" as="image" fetchpriority="high"><link rel="preload" href="https://cdn.jsdelivr.net/gh/YangLinzhuo/yanglinzhuo.github.io@latest/images/article-cover/img(77).webp" as="image" fetchpriority="high"><link rel="preload" href="https://cdn.jsdelivr.net/gh/YangLinzhuo/yanglinzhuo.github.io@latest/images/article-cover/img(93).webp" as="image" fetchpriority="high"><link rel="preload" href="https://cdn.jsdelivr.net/gh/YangLinzhuo/yanglinzhuo.github.io@latest/images/article-cover/img(67).webp" as="image" fetchpriority="high"><link rel="preload" href="https://cdn.jsdelivr.net/gh/YangLinzhuo/yanglinzhuo.github.io@latest/images/article-cover/img(1).webp" as="image" fetchpriority="high"><link rel="preload" href="https://cdn.jsdelivr.net/gh/YangLinzhuo/yanglinzhuo.github.io@latest/images/article-cover/img(52).webp" as="image" fetchpriority="high"><meta name="keywords" content="Computer-Science,CUDA"/><meta name="description" content="Linn 的个人博客"/><link rel="canonical" href="https://linn-ylz.com/Computer-Science/CUDA/CUDA-SGEMM-optimization-notes/"><title>CUDA SGEMM优化笔记</title><!-- hexo injector head_end start --><script> let HEXO_MMEDIA_DATA = { js: [], css: [], aplayerData: [], metingData: [], artPlayerData: [], dplayerData: []}; </script><!-- hexo injector head_end end --><meta name="generator" content="Hexo 7.3.0"></head><body itemscope itemtype="http://schema.org/WebPage"><div id="loading"><div class="cat"><div class="body"></div><div class="head"><div class="face"></div></div><div class="foot"><div class="tummy-end"></div><div class="bottom"></div><div class="legs left"></div><div class="legs right"></div></div><div class="paw"><div class="hands left"></div><div class="hands right"></div></div></div></div><div id="container"><header id="header" itemscope itemtype="http://schema.org/WPHeader"><div class="inner"><div id="brand"><div class="pjax"><h1 itemprop="name headline">CUDA SGEMM优化笔记</h1><div class="meta"><span class="item" title="创建时间：2023-10-01 09:19:53"><span class="icon"><i class="ic i-calendar"></i></span><span class="text">发表于</span><time itemprop="dateCreated datePublished" datetime="2023-10-01T09:19:53+08:00">2023-10-01</time></span><span class="item" title="本文字数"><span class="icon"><i class="ic i-pen"></i></span><span class="text">本文字数</span><span>28k</span><span class="text">字</span></span><span class="item" title="阅读时长"><span class="icon"><i class="ic i-clock"></i></span><span class="text">阅读时长</span><span>25 分钟</span></span></div></div></div><nav id="nav"><div class="inner"><div class="toggle"><div class="lines" aria-label="切换导航栏"><span class="line"></span><span class="line"></span><span class="line"></span></div></div><ul class="menu"><li class="item title"><a href="/" rel="start">Linn's Shoka</a></li></ul><ul class="right" id="rightNav"><li class="item theme"><i class="ic i-sun"></i></li><li class="item search"><i class="ic i-search"></i></li></ul></div></nav></div><div class="pjax" id="imgs"><ul><li class="item" style="background-image: url(&quot;https://cdn.jsdelivr.net/gh/YangLinzhuo/yanglinzhuo.github.io@latest/images/article-cover/img(14).webp&quot;);"></li><li class="item" style="background-image: url(&quot;https://cdn.jsdelivr.net/gh/YangLinzhuo/yanglinzhuo.github.io@latest/images/article-cover/img(77).webp&quot;);"></li><li class="item" style="background-image: url(&quot;https://cdn.jsdelivr.net/gh/YangLinzhuo/yanglinzhuo.github.io@latest/images/article-cover/img(93).webp&quot;);"></li><li class="item" style="background-image: url(&quot;https://cdn.jsdelivr.net/gh/YangLinzhuo/yanglinzhuo.github.io@latest/images/article-cover/img(67).webp&quot;);"></li><li class="item" style="background-image: url(&quot;https://cdn.jsdelivr.net/gh/YangLinzhuo/yanglinzhuo.github.io@latest/images/article-cover/img(1).webp&quot;);"></li><li class="item" style="background-image: url(&quot;https://cdn.jsdelivr.net/gh/YangLinzhuo/yanglinzhuo.github.io@latest/images/article-cover/img(52).webp&quot;);"></li></ul></div></header><div id="waves"><svg class="waves" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" viewBox="0 24 150 28" preserveAspectRatio="none" shape-rendering="auto"><defs><path id="gentle-wave" d="M-160 44c30 0 58-18 88-18s 58 18 88 18 58-18 88-18 58 18 88 18 v44h-352z"></path></defs><g class="parallax"><use xlink:href="#gentle-wave" x="48" y="0"></use><use xlink:href="#gentle-wave" x="48" y="3"></use><use xlink:href="#gentle-wave" x="48" y="5"></use><use xlink:href="#gentle-wave" x="48" y="7"></use></g></svg></div><main><div class="inner"><div class="pjax" id="main"><div class="article wrap"><div class="breadcrumb" itemListElement itemscope itemtype="https://schema.org/BreadcrumbList"><i class="ic i-home"></i><span><a href="/">首页</a></span><i class="ic i-angle-right"></i><span itemprop="itemListElement" itemscope="itemscope" itemtype="https://schema.org/ListItem"><a href="/categories/Computer-Science/" itemprop="item" rel="index" title="分类于Computer-Science"><span itemprop="name">Computer-Science<meta itemprop="position" content="0"/></span></a></span><i class="ic i-angle-right"></i><span class="current" itemprop="itemListElement" itemscope="itemscope" itemtype="https://schema.org/ListItem"><a href="/categories/Computer-Science/CUDA/" itemprop="item" rel="index" title="分类于CUDA"><span itemprop="name">CUDA<meta itemprop="position" content="1"/></span></a></span></div><article class="post block" itemscope="itemscope" itemtype="http://schema.org/Article" lang="zh-CN"><link itemprop="mainEntityOfPage" href="https://linn-ylz.com/Computer-Science/CUDA/CUDA-SGEMM-optimization-notes/"/><span hidden="hidden" itemprop="author" itemscope="itemscope" itemtype="http://schema.org/Person"><meta itemprop="image" content="/assets/my_small_avatar.jpg"/><meta itemprop="name" content="Linn"/><meta itemprop="description" content="Linn 的书架, Linn 的个人博客"/></span><span hidden="hidden" itemprop="publisher" itemscope="itemscope" itemtype="http://schema.org/Organization"><meta itemprop="name" content="林•初夏"/></span><div class="body md" itemprop="articleBody"><h2 id="前言"><a class="anchor" href="#前言">#</a> 前言</h2>
<p>本篇博客记录了最近学习的 CUDA 单精度 GEMM 算法的优化过程。</p>
<p>GEMM 算法是指 General Matrix Multiplication 算法，可以说是大多数线性代数算法的基础，也是目前热门的深度学习中最常用的基础计算，因此优化 GEMM 算法对于许多的应用有着重大意义。本篇博客关注的是 NVIDIA 的 GPU 设备上的 GEMM 算法实现，以 cuBLAS 库的算法性能作为比较基线，不断优化算法以逼近该基线。</p>
<p><img loading="lazy" data-src="/images/cuda/SGEMM-optimization/kernel-performance/kernel-cublas.png" alt="cuBLAS kernel" /></p>
<h2 id="基础知识"><a class="anchor" href="#基础知识">#</a> 基础知识</h2>
<p>本节将简要介绍 GPU 的计算模型和内存模型的基础知识。因为算法优化部分的内容较长，本节尽量精简。如果之后有时间，后续可能会详细介绍该部分的内容。</p>
<h3 id="gpu-计算模型"><a class="anchor" href="#gpu-计算模型">#</a> GPU 计算模型</h3>
<p><img loading="lazy" data-src="/images/cuda/SGEMM-optimization/CUDA-computation-model.png" alt="CUDA Computation Model" /></p>
<p>GPU 的计算模型可以分为上图所示的三级。最基础的执行单元是 thread，用于执行控制单元下发的指令。每个 thread 都属于某一个 block，block 可以有三个维度，在线程中可以通过 CUDA 内置的变量来获取线程对应的 id。每个 block 则又属于一个 grid，grid 也可以有三个维度，有 CUDA 内置变量用于确定 block 的 id。</p>
<p>对于 thread，可以使用  <code>threadIdx.x</code> ， <code>threadIdx.y</code> ， <code>threadIdx.z</code>  获取其在三个维度上的坐标以确定其 “身份”。当然，如果某一个维度的大小为 1，那么我们计算时可以省略。我们可以通过  <code>blockDim.x</code> ， <code>blockDim.y</code> ， <code>blockDim.z</code>  获取线程所在 block 三个维度的大小。类似地，block 可以使用  <code>blockIdx.x</code> ， <code>bloxkIdx.y</code> ， <code>blockIdx.z</code>  获取其在三个维度上的坐标， <code>gridDim.x</code> ， <code>gridDim.y</code> ， <code>gridDim.z</code>  可以获取 block 所在 grid 的三个维度的大小。</p>
<p>而具体到调度层面，需要注意，CUDA 以 block 为单位，将其中的线程调度到某一个 SM（Streaming Multiprocessor）上执行，而在真正执行的时候，CUDA 会将 block 中的线程以 32 个为一个 warp 进行调度，它们的线程 id 连续。如果线程数量不是 32 的倍数，那么 CUDA 会将其补齐。所以我们为每个 block 分配线程时，尽量将数量设置为 32 的倍数。</p>
<p>另外提一句，在访存的时候，会以 half-warp 为单位访存，也就是线程 id 连续的 16 个线程一组进行访存，在考虑 bank conflict 的时候需要注意这一点。</p>
<p>在调用编写的核函数时，我们需要指定 grid 和 block 的维度，一个简单的示例如下：</p>
<pre><code class="language-c">// Kernel definition  
__global__ void MatAdd(float A[N][N], float B[N][N], float C[N][N])  
&#123;  
    int i = blockIdx.x * blockDim.x + threadIdx.x;  
    int j = blockIdx.y * blockDim.y + threadIdx.y;  
    if (i &lt; N &amp;&amp; j &lt; N)  
        C[i][j] = A[i][j] + B[i][j];  
&#125;  
int main()  
&#123;  
    ...  
    // Kernel invocation  
    dim3 threadsPerBlock(16, 16);  
    dim3 numBlocks(N / threadsPerBlock.x, N / threadsPerBlock.y);  
    MatAdd&lt;&lt;&lt;numBlocks, threadsPerBlock&gt;&gt;&gt;(A, B, C);  
    ...  
&#125;
</code></pre>
<h3 id="gpu-内存模型"><a class="anchor" href="#gpu-内存模型">#</a> GPU 内存模型</h3>
<p>GPU 的内存可以分为 off-chip 和 on-chip 内存两大类别。off-chip 的特点是容量大，但是访存延迟高；on-chip 的特点则是容量小，但是访存延迟低。</p>
<p>off-chip 内存主要有 global memory，on-chip 内存则主要有 shared memory 和 register。三者中，register 的访存速度最快，shared memory 次之，global memory 最慢。</p>
<p><img loading="lazy" data-src="/images/cuda/SGEMM-optimization/memory-hierarchy.png" alt="CUDA Memory Hierarchy" /></p>
<p>如上图所示，每个 block 之间共享 global memory，而每个 block 自己则有一块 shared memory，block 中的每个 thread 共享这块 shared memory。此外，每个线程有自己独占的 register 和 local memory，local memory 一般也存放在 global memory 中。</p>
<p>由于 global memory 访存延迟较高，我们很多时候都会将数据读取到 shared memory 中；在某些情况下，甚至会手动使用 register 来缓存 shared memory 中的数据。</p>
<p>可以说，想要优化好 CUDA 上的算法，必须要注意降低或者隐藏访存延迟的开销，在后续的算法优化中我们可以看到这一点。</p>
<p>在调用编写的核函数之前，我们需要使用  <code>cudaMalloc</code>  和  <code>cudaMemcpy</code>  函数来在 GPU 上分配内存，并将 host 侧的数据拷贝到 device 侧。</p>
<h2 id="gemm-算法优化"><a class="anchor" href="#gemm-算法优化">#</a> GEMM 算法优化</h2>
<p>cuBLAS 中实现的通用的 GEMM 算法形式为 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>C</mi><mo>=</mo><mi>α</mi><mi>A</mi><mi>B</mi><mo>+</mo><mi>β</mi><mi>C</mi></mrow><annotation encoding="application/x-tex">C=\alpha AB+\beta C</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.07153em;">C</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.7667em;vertical-align:-0.0833em;"></span><span class="mord mathnormal" style="margin-right:0.0037em;">α</span><span class="mord mathnormal">A</span><span class="mord mathnormal" style="margin-right:0.05017em;">B</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.8889em;vertical-align:-0.1944em;"></span><span class="mord mathnormal" style="margin-right:0.07153em;">βC</span></span></span></span>。其中 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>A</mi><mo separator="true">,</mo><mi>B</mi><mo separator="true">,</mo><mi>C</mi></mrow><annotation encoding="application/x-tex">A,B,C</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8778em;vertical-align:-0.1944em;"></span><span class="mord mathnormal">A</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal" style="margin-right:0.05017em;">B</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal" style="margin-right:0.07153em;">C</span></span></span></span> 均为矩阵，shape 为 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>M</mi><mo>×</mo><mi>K</mi><mo separator="true">,</mo><mi>K</mi><mo>×</mo><mi>N</mi><mo separator="true">,</mo><mi>M</mi><mo>×</mo><mi>N</mi></mrow><annotation encoding="application/x-tex">M\times K,K\times N,M \times N</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7667em;vertical-align:-0.0833em;"></span><span class="mord mathnormal" style="margin-right:0.10903em;">M</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.8778em;vertical-align:-0.1944em;"></span><span class="mord mathnormal" style="margin-right:0.07153em;">K</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal" style="margin-right:0.07153em;">K</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.8778em;vertical-align:-0.1944em;"></span><span class="mord mathnormal" style="margin-right:0.10903em;">N</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal" style="margin-right:0.10903em;">M</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.10903em;">N</span></span></span></span>，<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>α</mi></mrow><annotation encoding="application/x-tex">\alpha</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em;"></span><span class="mord mathnormal" style="margin-right:0.0037em;">α</span></span></span></span> 和 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>β</mi></mrow><annotation encoding="application/x-tex">\beta</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8889em;vertical-align:-0.1944em;"></span><span class="mord mathnormal" style="margin-right:0.05278em;">β</span></span></span></span> 为标量。</p>
<p>最简单的实现是 CPU 的串行算法。如果我们对于某个算法在 GPU 中的实现感到难以下手，那么我们可以先从 CPU 算法开始。</p>
<pre><code class="language-cpp">#define OFFSET(row, col, stride) ((row) * (stride) + (col))
void cpu_naive_matmul(int M, int N, int K, float alpha, float *A, float *B, float beta, float *C) &#123;
    for (int m = 0; m &lt; M; ++m) &#123;
        for (int n = 0; n &lt; N; ++n) &#123;
            float val = 0.;
            for (int k = 0; k &lt; K; ++k) &#123;
                val += A[OFFSET(m, k, K)] * B[OFFSET(k, n, N)];
            &#125;
            C[OFFSET(m, n, N)] = alpha * val + beta * C[OFFSET(m, n, N)];
        &#125;
    &#125;
&#125;
</code></pre>
<h3 id="naive-实现"><a class="anchor" href="#naive-实现">#</a> Naive 实现</h3>
<p>本节介绍最简单的 CUDA SGEMM 实现，每个线程负责矩阵 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>C</mi></mrow><annotation encoding="application/x-tex">C</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.07153em;">C</span></span></span></span> 中的一个元素的计算。</p>
<p><img loading="lazy" data-src="/images/cuda/SGEMM-optimization/naive-kernel.png" alt="CUDA naive kernel 实现" /></p>
<p>假定我们启动核函数时的 block 大小为 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>B</mi><mi>M</mi><mo>×</mo><mi>B</mi><mi>N</mi></mrow><annotation encoding="application/x-tex">BM\times BN</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7667em;vertical-align:-0.0833em;"></span><span class="mord mathnormal" style="margin-right:0.10903em;">BM</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.10903em;">BN</span></span></span></span>，那么我们可以计算每个线程对应的 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>C</mi></mrow><annotation encoding="application/x-tex">C</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.07153em;">C</span></span></span></span> 中元素的下标：</p>
<pre><code class="language-c">int col = blockIdx.x * blockDim.x + threadIdx.x;  
int row = blockIdx.y * blockDim.y + threadIdx.y;
</code></pre>
<p>我们在启动核函数时，一个 grid 中可能会包含多个 block，所以这里还要使用  <code>blockIdx.x</code> ， <code>blockIdx.y</code>  和  <code>blockDim.x</code>  和  <code>blockDim.y</code>  相乘获取每个 block 的基址，即每个 block 最左上方的元素对应的下标。然后再分别加上线程在 block 中的偏移  <code>threadIdx.x</code>  和  <code>threadIdx.y</code> 。</p>
<p>后续的步骤就和 CPU 版本的代码相差无几了：</p>
<pre><code class="language-c">if (row &lt; M &amp;&amp; col &lt; N) &#123;  
    float val = 0.;  
    for (int k = 0; k &lt; K; ++k) &#123;  
        val += A[OFFSET(row, k, K)] * B[OFFSET(k, col, N)];  
    &#125;  
    C[OFFSET(row, col, N)] = alpha * val + beta * C[OFFSET(row, col, N)];  
&#125;
</code></pre>
<p>这里加上了  <code>if (row &lt; M &amp;&amp; col &lt; N)</code>  判断以防越界，因为有时候<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>M</mi></mrow><annotation encoding="application/x-tex">M</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.10903em;">M</span></span></span></span> 无法被 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>B</mi><mi>M</mi></mrow><annotation encoding="application/x-tex">BM</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.10903em;">BM</span></span></span></span>，或者 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>N</mi></mrow><annotation encoding="application/x-tex">N</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.10903em;">N</span></span></span></span> 无法被 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>B</mi><mi>N</mi></mrow><annotation encoding="application/x-tex">BN</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.10903em;">BN</span></span></span></span> 整除。</p>
<p>完整代码如下：</p>
<pre><code class="language-c">#define OFFSET(row, col, stride) ((row) * (stride) + (col))  
__global__ void naive_kernel(int M, int N, int K, 
                             float alpha, float *A, float *B, float beta, float *C) &#123;  
    int col = blockIdx.x * blockDim.x + threadIdx.x;  
    int row = blockIdx.y * blockDim.y + threadIdx.y;  
    if (row &lt; M &amp;&amp; col &lt; N) &#123;  
        float val = 0.;  
        for (int k = 0; k &lt; K; ++k) &#123;  
            val += A[OFFSET(row, k, K)] * B[OFFSET(k, col, N)];  
        &#125;  
        C[OFFSET(row, col, N)] = alpha * val + beta * C[OFFSET(row, col, N)];  
    &#125;  
&#125;
</code></pre>
<p>性能比较如下：</p>
<p><img loading="lazy" data-src="/images/cuda/SGEMM-optimization/kernel-performance/kernel-naive.png" alt="naive kernel" /></p>
<p>可以看到，朴素实现的性能基本都在 1000 GFLOPS 左右，只有 cuBLAS 库性能的十分之一。</p>
<p>我们可以做一个简单的计算。对于矩阵 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>C</mi></mrow><annotation encoding="application/x-tex">C</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.07153em;">C</span></span></span></span> 中的每个元素，我们需要访问 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>A</mi></mrow><annotation encoding="application/x-tex">A</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal">A</span></span></span></span> 和 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>B</mi></mrow><annotation encoding="application/x-tex">B</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.05017em;">B</span></span></span></span> 中各 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>K</mi></mrow><annotation encoding="application/x-tex">K</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.07153em;">K</span></span></span></span> 个元素，总共 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>2</mn><mi>K</mi></mrow><annotation encoding="application/x-tex">2K</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord">2</span><span class="mord mathnormal" style="margin-right:0.07153em;">K</span></span></span></span> 次全局内存访问。同时，循环中进行了 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>K</mi></mrow><annotation encoding="application/x-tex">K</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.07153em;">K</span></span></span></span> 次乘法和加法共 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>2</mn><mi>K</mi></mrow><annotation encoding="application/x-tex">2K</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord">2</span><span class="mord mathnormal" style="margin-right:0.07153em;">K</span></span></span></span> 次运算。计算下来，平均每一次计算就需要一次访存。考虑到 global memory 的访存延迟，这样的做法显然是非常没有效率的。</p>
<p>通过 Nsight Compute 工具也可以看到， <code>warp</code>  花费了大量时间等待全局内存的读写：</p>
<p><img loading="lazy" data-src="/images/cuda/SGEMM-optimization/naive-kernel-warp-state.png" alt="naive kernel warp state" /></p>
<p>切换到代码页面也能看到具体是哪些代码导致了这些 stall。可以发现，我们的核心计算语句耗费了大量时间等待访存读写，这也是我们可以优化的着手点。</p>
<p><img loading="lazy" data-src="/images/cuda/SGEMM-optimization/naive-kernel-hotspot-code.png" alt="naive kernel hotspot code" /></p>
<h3 id="使用-shared-memory-优化访存"><a class="anchor" href="#使用-shared-memory-优化访存">#</a> 使用 Shared Memory 优化访存</h3>
<p>朴素实现中对输入的访问全部都是直接对全局内存进行操作。前文中我们提到，全局内存的访存速度是最慢的，这限制了核函数的计算效率，每个线程耗费了大量的时间等待访存。我们可以尝试使用共享内存来缓存一部分的输入。</p>
<p>可以发现，对于 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>C</mi></mrow><annotation encoding="application/x-tex">C</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.07153em;">C</span></span></span></span> 中的每一行元素，在计算过程中都需要访问 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>A</mi></mrow><annotation encoding="application/x-tex">A</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal">A</span></span></span></span> 矩阵中的同一行元素；对于 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>C</mi></mrow><annotation encoding="application/x-tex">C</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.07153em;">C</span></span></span></span> 中每一列元素，在计算过程中需要访问 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>B</mi></mrow><annotation encoding="application/x-tex">B</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.05017em;">B</span></span></span></span> 矩阵中的同一列元素。那么，对于一个 block 中需要计算的 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>B</mi><mi>M</mi><mo>×</mo><mi>B</mi><mi>N</mi></mrow><annotation encoding="application/x-tex">BM \times BN</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7667em;vertical-align:-0.0833em;"></span><span class="mord mathnormal" style="margin-right:0.10903em;">BM</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.10903em;">BN</span></span></span></span> 元素，有许多对相同地址的重复访问。因此，我们可以使用共享内存预先读取全局内存中所需要的元素，然后计算时直接读取共享内存，节省访存时的等待时间。</p>
<p><img loading="lazy" data-src="/images/cuda/SGEMM-optimization/shared-memory-kernel.png" alt="CUDA 使用 shared memory 的实现" /></p>
<p>我们开辟两块 shared memory 中的空间，分别用于存储从 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>A</mi></mrow><annotation encoding="application/x-tex">A</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal">A</span></span></span></span> 和 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>B</mi></mrow><annotation encoding="application/x-tex">B</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.05017em;">B</span></span></span></span> 中读取的元素：</p>
<pre><code class="language-c">__shared__ float As[BM][BK];  
__shared__ float Bs[BK][BN];
</code></pre>
<p>计算时，我们每次需要读取每行或者每列中的 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>B</mi><mi>K</mi></mrow><annotation encoding="application/x-tex">BK</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.05017em;">B</span><span class="mord mathnormal" style="margin-right:0.07153em;">K</span></span></span></span> 个元素，那么需要迭代 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>K</mi><mi mathvariant="normal">/</mi><mi>B</mi><mi>K</mi></mrow><annotation encoding="application/x-tex">K/BK</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.07153em;">K</span><span class="mord">/</span><span class="mord mathnormal" style="margin-right:0.05017em;">B</span><span class="mord mathnormal" style="margin-right:0.07153em;">K</span></span></span></span> 次，每次读取 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>A</mi></mrow><annotation encoding="application/x-tex">A</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal">A</span></span></span></span> 和 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>B</mi></mrow><annotation encoding="application/x-tex">B</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.05017em;">B</span></span></span></span> 中的一块区域的元素。然后对读取的元素，每个线程使用其所需的元素进行计算。</p>
<pre><code class="language-c">float val = 0.;  
int num_shared_block = CEIL_DIV(K, BK); 
A = &amp;A[OFFSET(blockIdx.y * BM, 0, K)]; // Relative position 
B = &amp;B[OFFSET(0, blockIdx.x * BN, N)]; // Relative position
C = &amp;C[OFFSET(blockIdx.y * BM, blockIdx.x * BN, N)]; // Relative position
  
for (int i = 0; i &lt; num_shared_block; ++i) &#123;  
    // Copy data from global memory to shared memory  
    int A_row = threadIdx.y;  
    int A_col = threadIdx.x;  
    if ((blockIdx.y * BM + A_row) &lt; M &amp;&amp; (i * BK + A_col) &lt; K) &#123;  
        As[threadIdx.y][threadIdx.x] = A[OFFSET(A_row, A_col, K)];  
    &#125; else &#123;  
        As[threadIdx.y][threadIdx.x] = 0.;  
    &#125;  
    int B_row = threadIdx.y;  
    int B_col = threadIdx.x;  
    if ((i * BK + B_row) &lt; K &amp;&amp; (blockIdx.x * BN + B_col) &lt; N) &#123;  
        Bs[threadIdx.y][threadIdx.x] = B[OFFSET(B_row, B_col, N)];  
    &#125; else &#123;  
        Bs[threadIdx.y][threadIdx.x] = 0.;  
    &#125;  
    __syncthreads();  
    A += BK;  // Add offset
    B += BK * N;  // Add offset
    for (int k = 0; k &lt; BK; ++k) &#123;  
        val += As[threadIdx.y][k] * Bs[k][threadIdx.x];  
    &#125;  
    __syncthreads();  
&#125;  
</code></pre>
<p>注意上述代码中，我们为三个矩阵的指针添加了偏移量，后续计算坐标时，只需要计算其在子矩阵中的相对位置即可。不过也要注意，在判断是否越界时，需要转换为全局的下标，否则会判断错误。</p>
<p>每次迭代中，我们只计算了 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>C</mi></mrow><annotation encoding="application/x-tex">C</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.07153em;">C</span></span></span></span> 中对应元素值的一部分，待到迭代完毕，便得到了最终的结果。注意迭代过程中，使用了  <code>__syncthreads()</code>  来同步每个线程，防止数据读取不同步，造成读取的数据错误。</p>
<p>最后，将计算结果写回：</p>
<pre><code class="language-c">int C_row = threadIdx.y;  
int C_col = threadIdx.x;  
if ((blockIdx.y * BM + C_row) &lt; M &amp;&amp; (blockIdx.x * BN + C_col) &lt; N) &#123;  
    C[OFFSET(C_row, C_col, N)] = alpha * val + beta * C[OFFSET(C_row, C_col, N)];  
&#125;
</code></pre>
<p><img loading="lazy" data-src="/images/cuda/SGEMM-optimization/kernel-performance/kernel-sm.png" alt="shared memory kernel" /></p>
<p>emmm，理论上而言，每个 block 需要从全局内存中读取 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mfrac><mi>K</mi><mrow><mi>B</mi><mi>K</mi></mrow></mfrac><mo>×</mo><mo stretchy="false">(</mo><mi>B</mi><mi>M</mi><mo>×</mo><mi>B</mi><mi>K</mi><mo>+</mo><mi>B</mi><mi>K</mi><mo>×</mo><mi>B</mi><mi>N</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">\frac{K}{BK}\times(BM\times BK + BK\times BN)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.2173em;vertical-align:-0.345em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8723em;"><span style="top:-2.655em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.05017em;">B</span><span class="mord mathnormal mtight" style="margin-right:0.07153em;">K</span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.394em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.07153em;">K</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.345em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.10903em;">BM</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.7667em;vertical-align:-0.0833em;"></span><span class="mord mathnormal" style="margin-right:0.05017em;">B</span><span class="mord mathnormal" style="margin-right:0.07153em;">K</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.7667em;vertical-align:-0.0833em;"></span><span class="mord mathnormal" style="margin-right:0.05017em;">B</span><span class="mord mathnormal" style="margin-right:0.07153em;">K</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.10903em;">BN</span><span class="mclose">)</span></span></span></span> 个浮点数。而朴素算法中，一个 block 总共需要 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>2</mn><mi>K</mi><mo>×</mo><mi>B</mi><mi>M</mi><mo>×</mo><mi>B</mi><mi>N</mi></mrow><annotation encoding="application/x-tex">2K\times BM \times BN</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7667em;vertical-align:-0.0833em;"></span><span class="mord">2</span><span class="mord mathnormal" style="margin-right:0.07153em;">K</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.7667em;vertical-align:-0.0833em;"></span><span class="mord mathnormal" style="margin-right:0.10903em;">BM</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.10903em;">BN</span></span></span></span> 次访存。可以看到，使用了一维 Tile 方法之后，访存降为了原来的 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mfrac><mn>1</mn><mn>2</mn></mfrac><mo stretchy="false">(</mo><mfrac><mn>1</mn><mrow><mi>B</mi><mi>N</mi></mrow></mfrac><mo>+</mo><mfrac><mn>1</mn><mrow><mi>B</mi><mi>M</mi></mrow></mfrac><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">\frac{1}{2}(\frac{1}{BN}+\frac{1}{BM})</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.1901em;vertical-align:-0.345em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8451em;"><span style="top:-2.655em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">2</span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.394em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.345em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mopen">(</span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8451em;"><span style="top:-2.655em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.10903em;">BN</span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.394em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.345em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:1.1901em;vertical-align:-0.345em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8451em;"><span style="top:-2.655em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.10903em;">BM</span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.394em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.345em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mclose">)</span></span></span></span>。一般有 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>B</mi><mi>M</mi><mo>=</mo><mi>B</mi><mi>N</mi></mrow><annotation encoding="application/x-tex">BM=BN</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.10903em;">BM</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.10903em;">BN</span></span></span></span>，因此，全局内存访问将为了原来的 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mfrac><mn>1</mn><mrow><mi>B</mi><mi>M</mi></mrow></mfrac></mrow><annotation encoding="application/x-tex">\frac{1}{BM}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.1901em;vertical-align:-0.345em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8451em;"><span style="top:-2.655em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.10903em;">BM</span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.394em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.345em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span>。而每个线程的计算量不变，则计算访存比也降低为原来的 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mfrac><mn>1</mn><mrow><mi>B</mi><mi>N</mi></mrow></mfrac></mrow><annotation encoding="application/x-tex">\frac{1}{BN}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.1901em;vertical-align:-0.345em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8451em;"><span style="top:-2.655em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.10903em;">BN</span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.394em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.345em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span>。不过从我测试的结果来看，和 naive 的结果比较并没有明显的区别，甚至还变差了一丢丢。</p>
<p><img loading="lazy" data-src="/images/cuda/SGEMM-optimization/shared-memory-kernel-warp-state.png" alt="shared memory kernel warp state" /></p>
<p>可以看到，这次是  <code>Stall MIO Throttle</code>  这一项的 stall cycles 最多。这一项根据文档说明，一般是某些特殊的数学计算函数、动态分支、共享内存读写导致的，放在我们的上下文中，那就可以肯定是共享内存导致的瓶颈，在横轴上几乎和使用全局内存的代码一致，数值也很接近。这也是为什么这段代码和直接使用全局代码的性能几乎没有变化。</p>
<h3 id="一维-tile"><a class="anchor" href="#一维-tile">#</a> 一维 Tile</h3>
<p>要进一步优化，可以从前文的 profiling 结果入手。我们无论是使用全局内存还是共享内存，主要的瓶颈都在访存上。为了进一步掩盖访存开销，我们要么可以提高访存的效率，要么让每个线程的负载更多一点，以使得能够掩盖访存的开销。</p>
<p>这里我们先尝试提高每个线程的负载， 让每个线程多计算一些元素的输出。这里我们让每个线程计算矩阵 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>C</mi></mrow><annotation encoding="application/x-tex">C</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.07153em;">C</span></span></span></span> 一列中连续几个元素的值。</p>
<p><img loading="lazy" data-src="/images/cuda/SGEMM-optimization/thread-tile-1d-kernel.png" alt="一维 Tile" /></p>
<p>在使用共享内存的基础上，我们添加了一维 Tile 的代码。</p>
<pre><code class="language-c">float val[TM] = &#123;0.&#125;;
</code></pre>
<p>因为每个线程需要计算 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>T</mi><mi>M</mi></mrow><annotation encoding="application/x-tex">TM</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.10903em;">TM</span></span></span></span> 个元素的结果，我们使用一个 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>T</mi><mi>M</mi></mrow><annotation encoding="application/x-tex">TM</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.10903em;">TM</span></span></span></span> 大小的数组来存储中间结果。</p>
<p>在拷贝数据时，每个线程需要在 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>A</mi></mrow><annotation encoding="application/x-tex">A</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal">A</span></span></span></span> 矩阵中多拷贝 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>T</mi><mi>M</mi></mrow><annotation encoding="application/x-tex">TM</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.10903em;">TM</span></span></span></span> 次：</p>
<pre><code class="language-c">// Copy data from global memory to shared memory  
for (int m = 0; m &lt; TM; ++m) &#123;  
    int A_row = threadIdx.y * TM + m;  
    int A_col = threadIdx.x;  
    if ((blockIdx.y * BM + A_row) &lt; M &amp;&amp; (i * BK + A_col) &lt; K) &#123;  
        As[A_row][A_col] = A[OFFSET(A_row, A_col, K)];  
    &#125; else &#123;  
        As[A_row][A_col] = 0.;  
    &#125;  
&#125;
</code></pre>
<p>计算中间结果时，也需要多一层循环：</p>
<pre><code class="language-c">for (int k = 0; k &lt; BK; ++k) &#123;  
    for (int m = 0; m &lt; TM; ++m) &#123;  
        int A_row = threadIdx.y * TM + m;  
        int B_col = threadIdx.x;  
        val[m] += As[A_row][k] * Bs[k][B_col];  
    &#125;  
&#125;
</code></pre>
<p>最后，将计算结果写回：</p>
<pre><code class="language-c">for (int m = 0; m &lt; TM; ++m) &#123;  
    int C_row = threadIdx.y * TM + m;  
    int C_col = threadIdx.x;  
    if ((blockIdx.y * BM + C_row) &lt; M &amp;&amp; (blockIdx.x * BN + C_col) &lt; N) &#123;  
        C[OFFSET(C_row, C_col, N)] = alpha * val[m] + beta * C[OFFSET(C_row, C_col, N)];  
    &#125;  
&#125;
</code></pre>
<p><img loading="lazy" data-src="/images/cuda/SGEMM-optimization/kernel-performance/kernel-tile-1d.png" alt="1d tile kernel" /></p>
<p>可以看到，使用 Tile 之后，性能得到了一定的提升，逼近了 2000 GFLOPS。一个 block 全局访存的数量依然为 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>K</mi><mo stretchy="false">(</mo><mi>M</mi><mo>+</mo><mi>N</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">K(M+N)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.07153em;">K</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.10903em;">M</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.10903em;">N</span><span class="mclose">)</span></span></span></span>，但是每个线程负责的计算量为原来的 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>T</mi><mi>M</mi></mrow><annotation encoding="application/x-tex">TM</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.10903em;">TM</span></span></span></span> 倍，因此计算访存比提升了 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>T</mi><mi>M</mi></mrow><annotation encoding="application/x-tex">TM</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.10903em;">TM</span></span></span></span> 倍。</p>
<p><img loading="lazy" data-src="/images/cuda/SGEMM-optimization/tile-1d-kernel-warp-state.png" alt="tile 1d kernel warp state" /></p>
<p>这次可以看到，相比仅使用共享内存，增加线程计算负载之后  <code>Stall MIO Throttle</code>  这一项的横轴数值有了减小，之前超过了 20 cycles per instruction，现在已经在 20 以下了。不过也可以看出，这一项的延时依然较高，我们还可以有提升空间。</p>
<h3 id="二维-tile"><a class="anchor" href="#二维-tile">#</a> 二维 Tile</h3>
<p>和一维 Tile 类似，这次我们让每个线程负责计算矩阵 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>C</mi></mrow><annotation encoding="application/x-tex">C</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.07153em;">C</span></span></span></span> 中一小块 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>T</mi><mi>M</mi><mo>×</mo><mi>T</mi><mi>N</mi></mrow><annotation encoding="application/x-tex">TM \times TN</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7667em;vertical-align:-0.0833em;"></span><span class="mord mathnormal" style="margin-right:0.10903em;">TM</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.10903em;">TN</span></span></span></span> 区域中的元素，进一步提升每个线程的负载。有了一维 Tile 的代码，我们简单地在其基础之上做少许修改，便可以得到二维 Tile 的代码。</p>
<p>存储中间结果需要分配 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>T</mi><mi>M</mi><mo>×</mo><mi>T</mi><mi>N</mi></mrow><annotation encoding="application/x-tex">TM \times TN</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7667em;vertical-align:-0.0833em;"></span><span class="mord mathnormal" style="margin-right:0.10903em;">TM</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.10903em;">TN</span></span></span></span> 大小的空间：</p>
<pre><code class="language-c">float val[TM][TN] = &#123;0.&#125;;
</code></pre>
<p>注意这里的 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>T</mi><mi>M</mi></mrow><annotation encoding="application/x-tex">TM</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.10903em;">TM</span></span></span></span> 和 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>T</mi><mi>N</mi></mrow><annotation encoding="application/x-tex">TN</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.10903em;">TN</span></span></span></span> 不能设置过大，否则可能寄存器资源不够，导致 register spill，这时中间数据便会使用 local memory 存储，访存速度会慢很多。</p>
<p>拷贝数据时，在矩阵 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>B</mi></mrow><annotation encoding="application/x-tex">B</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.05017em;">B</span></span></span></span> 上也要多拷贝 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>T</mi><mi>N</mi></mrow><annotation encoding="application/x-tex">TN</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.10903em;">TN</span></span></span></span> 次：</p>
<pre><code class="language-c">for (int n = 0; n &lt; TN; ++n) &#123;  
    int B_row = threadIdx.y;  
    int B_col = threadIdx.x * TN + n;  
    if ((i * BK + B_row) &lt; K &amp;&amp; (blockIdx.x * BN + B_col) &lt; N) &#123;  
        Bs[B_row][B_col] = B[OFFSET(B_row, B_col, N)];  
    &#125; else &#123;  
        Bs[B_row][B_col] = 0.;  
    &#125;  
&#125;
</code></pre>
<p>同理，计算结果时需要使用二重循环：</p>
<pre><code class="language-c">for (int k = 0; k &lt; BK; ++k) &#123;  
    for (int m = 0; m &lt; TM; ++m) &#123;  
        int A_row = threadIdx.y * TM + m;  
        for (int n = 0; n &lt; TN; ++n) &#123;  
            int B_col = threadIdx.x * TN + n;  
            val[m][n] += As[A_row][k] * Bs[k][B_col];  
        &#125;  
    &#125;  
&#125;
</code></pre>
<p>结果写回：</p>
<pre><code class="language-c">for (int m = 0; m &lt; TM; ++m) &#123;  
    int C_row = threadIdx.y * TM + m;  
    for (int n = 0; n &lt; TN; ++n) &#123;  
        int C_col = threadIdx.x * TN + n;  
        if ((blockIdx.y * BM + C_row) &lt; M &amp;&amp; (blockIdx.x * BN + C_col) &lt; N) &#123;  
            C[OFFSET(C_row, C_col, N)] = alpha * val[m][n] + beta * C[OFFSET(C_row, C_col, N)];  
        &#125;  
    &#125;  
&#125;
</code></pre>
<p><img loading="lazy" data-src="/images/cuda/SGEMM-optimization/kernel-performance/kernel-tile-2d.png" alt="2d tile kernel" /></p>
<p>可以看到，现在的性能相比朴素的实现有了很大的提升，性能接近了 4000 GFLOPS。在一维 Tile 的基础之上，计算访存比进一步提升了 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>T</mi><mi>N</mi></mrow><annotation encoding="application/x-tex">TN</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.10903em;">TN</span></span></span></span> 倍。</p>
<p><img loading="lazy" data-src="/images/cuda/SGEMM-optimization/tile-2d-kernel-warp-state.png" alt="tile 2d kernel warp state" /></p>
<p>可以看到，现在的  <code>Stall MIO Throttle</code>  已经降低到 11 cycles per instruction。相比仅使用共享内存，降低到了原来的不到一半。性能的数值也和 profiling 的结果能够互相印证。</p>
<h3 id="使用寄存器进一步优化访存"><a class="anchor" href="#使用寄存器进一步优化访存">#</a> 使用寄存器进一步优化访存</h3>
<p>对于二维 Tile 中计算矩阵 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>C</mi></mrow><annotation encoding="application/x-tex">C</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.07153em;">C</span></span></span></span> 结果的代码：</p>
<pre><code class="language-c">for (int k = 0; k &lt; BK; ++k) &#123;  
    for (int m = 0; m &lt; TM; ++m) &#123;  
        int A_row = threadIdx.y * TM + m;  
        for (int n = 0; n &lt; TN; ++n) &#123;  
            int B_col = threadIdx.x * TN + n;  
            val[m][n] += As[A_row][k] * Bs[k][B_col];  
        &#125;  
    &#125;  
&#125;
</code></pre>
<p>可以看到，对于  <code>As</code>  中的内容重复访问了 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>T</mi><mi>N</mi></mrow><annotation encoding="application/x-tex">TN</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.10903em;">TN</span></span></span></span> 次；对于  <code>Bs</code>  中的内容，在外层的  <code>m</code>  迭代中，也会重复访问 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>T</mi><mi>M</mi></mrow><annotation encoding="application/x-tex">TM</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.10903em;">TM</span></span></span></span> 次。因此，我们可以使用寄存器将这部分内容缓存下来，进一步提升访存。</p>
<pre><code class="language-c">for (int k = 0; k &lt; BK; ++k) &#123;  
    for (int m = 0; m &lt; TM; ++m) &#123;  
        int A_row = threadIdx.y * TM + m;  
        As_cache[m] = As[A_row][k];  
    &#125;  
    for (int n = 0; n &lt; TN; ++n) &#123;  
        int B_col = threadIdx.x * TN + n;  
        Bs_cache[n] = Bs[k][B_col];  
    &#125;  
    for (int m = 0; m &lt; TM; ++m) &#123;  
        for (int n = 0; n &lt; TN; ++n) &#123;  
            val[m][n] += As_cache[m] * Bs_cache[n];  
        &#125;  
    &#125;  
&#125;
</code></pre>
<p>不过这部分的优化在我的测试中对性能的提升并不明显。</p>
<p><img loading="lazy" data-src="/images/cuda/SGEMM-optimization/kernel-performance/kernel-reg-cache.png" alt="register cache kernel" /></p>
<p>在 profiling 的结果中发现，和使用之前对于  <code>Stall MIO Throttle</code>  指标几乎没有降低，也就是并没有降低访存的开销。</p>
<p><img loading="lazy" data-src="/images/cuda/SGEMM-optimization/reg-cache-kernel-code.png" alt="register cache kernel code" /></p>
<p>从代码对应图中可以看到，虽然我们使用了寄存器，但是从共享内存读取数据到寄存器中的时候依然存在较大的  <code>MIO</code>  延迟，即这个延迟只是从一条语句转移到了其他语句之上，并没有被我们掩盖掉，所以没有性能提升也就是正常的了。</p>
<h3 id="使用-float4-指令优化访存"><a class="anchor" href="#使用-float4-指令优化访存">#</a> 使用 FLOAT4 指令优化访存</h3>
<p><img loading="lazy" data-src="/images/cuda/SGEMM-optimization/kernel-performance/tile-2d-performance-analysis.png" alt="tile 2d performance analysis" /></p>
<p>通过前面 profiling 的结果，能够发现很大一部分时间仍然花在了等待访存之上。可以看到，内存带宽的使用负载大于计算的负载。访存延迟依然是程序性能的瓶颈。</p>
<p>我们可以进一步利用 GPU  <code>float4</code>  访存特性来进一步优化，让每个元素一次获取 4 个浮点数，进一步减少访存次数。相比于访存 4 次获取 4 个浮点数，通过  <code>float4</code>  向量内存指令所需的访存指令数更少，减少了对内存访问的竞争；另一方面，使用向量加载每个字节需要的索引计算更少，我们只需要计算一次索引即可读取 4 个浮点数。但是这样一来，代码也会变得略显复杂。</p>
<p>同时，我们在读取矩阵 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>A</mi></mrow><annotation encoding="application/x-tex">A</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal">A</span></span></span></span> 的内容时，还要对其进行转置，然后再存储到 shared memory 中，以方便后续线程计算时使用  <code>float4</code>  读取，以避免共享内存的 bank conflict。</p>
<p>我们使用以下宏来定义一次访问 4 个浮点数的操作：</p>
<pre><code class="language-c">#define FETCH_FLOAT4(pointer) (reinterpret_cast&lt;float4*&gt;(&amp;(pointer))[0])
</code></pre>
<p>需要注意，因为使用了 FLOAT4 访存的缘故，矩阵的元素数量必须是 4 的倍数，不再能够支持任意大小的矩阵<sup class="footnote-ref"><a href="#fn1" id="fnref1">[1]</a></sup>。</p>
<p>对于  <code>As</code>  缓存，其分配的空间能够存储 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>B</mi><mi>M</mi><mo>×</mo><mi>B</mi><mi>K</mi></mrow><annotation encoding="application/x-tex">BM\times BK</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7667em;vertical-align:-0.0833em;"></span><span class="mord mathnormal" style="margin-right:0.10903em;">BM</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.05017em;">B</span><span class="mord mathnormal" style="margin-right:0.07153em;">K</span></span></span></span> 个浮点数，在一个 block 中共有 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">(</mo><mi>B</mi><mi>M</mi><mi mathvariant="normal">/</mi><mi>T</mi><mi>M</mi><mo stretchy="false">)</mo><mo>×</mo><mo stretchy="false">(</mo><mi>B</mi><mi>N</mi><mi mathvariant="normal">/</mi><mi>T</mi><mi>N</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">(BM/TM)\times (BN/TN)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.10903em;">BM</span><span class="mord">/</span><span class="mord mathnormal" style="margin-right:0.10903em;">TM</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.10903em;">BN</span><span class="mord">/</span><span class="mord mathnormal" style="margin-right:0.10903em;">TN</span><span class="mclose">)</span></span></span></span> 个线程，每个线程一次读取 4 个浮点数，那么总共需要读取 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mfrac><mrow><mi>B</mi><mi>M</mi><mo>×</mo><mi>B</mi><mi>K</mi></mrow><mrow><mi>B</mi><mi>M</mi><mi mathvariant="normal">/</mi><mi>T</mi><mi>M</mi><mo>×</mo><mi>B</mi><mi>N</mi><mi mathvariant="normal">/</mi><mi>T</mi><mi>N</mi><mo>×</mo><mn>4</mn></mrow></mfrac></mrow><annotation encoding="application/x-tex">\frac{BM\times BK}{BM/TM\times BN/TN \times 4}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.3923em;vertical-align:-0.52em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8723em;"><span style="top:-2.655em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.10903em;">BM</span><span class="mord mtight">/</span><span class="mord mathnormal mtight" style="margin-right:0.10903em;">TM</span><span class="mbin mtight">×</span><span class="mord mathnormal mtight" style="margin-right:0.10903em;">BN</span><span class="mord mtight">/</span><span class="mord mathnormal mtight" style="margin-right:0.10903em;">TN</span><span class="mbin mtight">×</span><span class="mord mtight">4</span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.394em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.10903em;">BM</span><span class="mbin mtight">×</span><span class="mord mathnormal mtight" style="margin-right:0.05017em;">B</span><span class="mord mathnormal mtight" style="margin-right:0.07153em;">K</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.52em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span> 次；同理， <code>Bs</code>  缓存需要读取 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mfrac><mrow><mi>B</mi><mi>K</mi><mo>×</mo><mi>B</mi><mi>N</mi></mrow><mrow><mi>B</mi><mi>M</mi><mi mathvariant="normal">/</mi><mi>T</mi><mi>M</mi><mo>×</mo><mi>B</mi><mi>N</mi><mi mathvariant="normal">/</mi><mi>T</mi><mi>N</mi><mo>×</mo><mn>4</mn></mrow></mfrac></mrow><annotation encoding="application/x-tex">\frac{BK\times BN}{BM/TM\times BN/TN \times 4}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.3923em;vertical-align:-0.52em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8723em;"><span style="top:-2.655em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.10903em;">BM</span><span class="mord mtight">/</span><span class="mord mathnormal mtight" style="margin-right:0.10903em;">TM</span><span class="mbin mtight">×</span><span class="mord mathnormal mtight" style="margin-right:0.10903em;">BN</span><span class="mord mtight">/</span><span class="mord mathnormal mtight" style="margin-right:0.10903em;">TN</span><span class="mbin mtight">×</span><span class="mord mtight">4</span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.394em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.05017em;">B</span><span class="mord mathnormal mtight" style="margin-right:0.07153em;">K</span><span class="mbin mtight">×</span><span class="mord mathnormal mtight" style="margin-right:0.10903em;">BN</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.52em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span>。</p>
<pre><code class="language-c">const int block_row_thread = BN / TN;  
const int block_col_thread = BM / TM;  
const int thread_num = block_row_thread * block_col_thread;
const int load_a_cache_time = (BK * BM) / thread_num / 4;  // Each thread load 4 float
const int load_b_cache_time = (BK * BN) / thread_num / 4;  // Each thread load 4 float
</code></pre>
<p><img loading="lazy" data-src="/images/cuda/SGEMM-optimization/float4-kernel.png" alt="使用 float4 访存" /></p>
<p>如上图所示，假设 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>B</mi><mi>K</mi><mo>=</mo><mn>16</mn></mrow><annotation encoding="application/x-tex">BK=16</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.05017em;">B</span><span class="mord mathnormal" style="margin-right:0.07153em;">K</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">16</span></span></span></span>，共有 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>8</mn></mrow><annotation encoding="application/x-tex">8</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">8</span></span></span></span> 个线程，那么一次读取就能够读完  <code>As</code>  中的两行。那么每个线程下一次读取时间隔的行数就是 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>8</mn><mi mathvariant="normal">/</mi><mo stretchy="false">(</mo><mi>B</mi><mi>K</mi><mi mathvariant="normal">/</mi><mn>4</mn><mo stretchy="false">)</mo><mo>=</mo><mn>2</mn></mrow><annotation encoding="application/x-tex">8/(BK/4)=2</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord">8/</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.05017em;">B</span><span class="mord mathnormal" style="margin-right:0.07153em;">K</span><span class="mord">/4</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">2</span></span></span></span>。</p>
<p>其实，我们不妨把  <code>As</code>  看成一个矩阵元素是  <code>float4</code>  的矩阵，那么原来的  <code>As</code>  就相当于一个大小为 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>B</mi><mi>M</mi><mo>×</mo><mo stretchy="false">(</mo><mi>B</mi><mi>K</mi><mi mathvariant="normal">/</mi><mn>4</mn><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">BM\times (BK/4)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7667em;vertical-align:-0.0833em;"></span><span class="mord mathnormal" style="margin-right:0.10903em;">BM</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.05017em;">B</span><span class="mord mathnormal" style="margin-right:0.07153em;">K</span><span class="mord">/4</span><span class="mclose">)</span></span></span></span> 大小的新矩阵  <code>As_new</code> 。那么，我们可以根据线程的  <code>id</code>  来计算其对应放置的地址偏移，我们不妨把线程看成一维的，这样更方便计算。</p>
<p>首先，计算出线程的 id：</p>
<pre><code class="language-c">int thread_id = threadIdx.y * blockDim.x + threadIdx.x;
</code></pre>
<p><code>As</code>  中每一行需要 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>B</mi><mi>K</mi><mi mathvariant="normal">/</mi><mn>4</mn></mrow><annotation encoding="application/x-tex">BK/4</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.05017em;">B</span><span class="mord mathnormal" style="margin-right:0.07153em;">K</span><span class="mord">/4</span></span></span></span> 个线程读取，那么线程对应的行数为：</p>
<pre><code class="language-c">int a_tile_row = thread_id / (BK / 4);
</code></pre>
<p>同理，对应的列数为  <code>thread_id % (BK / 4)</code> 。不过这是  <code>As_new</code>  中地址便宜，换算回  <code>As</code>  还得乘 4，也就是：</p>
<pre><code class="language-c">int a_tile_col = thread_id % (BK / 4) * 4;
</code></pre>
<p>按照上述方式，我们也可以计算得出  <code>Bs</code>  的对应偏移：</p>
<pre><code class="language-c">int b_tile_row = thread_id / (BN / 4);  
int b_tile_col = thread_id % (BN / 4) * 4;
</code></pre>
<p>上述计算的地址是每次读取的子矩阵中的相对偏移，每次读取时，我们还需要添加一个基址偏移。对于  <code>As</code> ，共有 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>B</mi><mi>M</mi></mrow><annotation encoding="application/x-tex">BM</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.10903em;">BM</span></span></span></span> 行，上面计算得到了共需要读取  <code>load_a_cache_time</code> ，那么可以知道每次需要偏移的大小为：</p>
<pre><code class="language-c">int a_tile_stride = BM / load_a_cache_time;
</code></pre>
<p>同理， <code>Bs</code>  中的对应大小为：</p>
<pre><code class="language-c">int b_tile_stride = BK / load_b_cache_time;
</code></pre>
<p>在读取  <code>As</code>  时，注意还需要对其进行转置，其代码如下：</p>
<pre><code class="language-c">for (int i = 0; i &lt; BM; i += a_tile_stride) &#123;  
    int cache_idx = i / a_tile_stride * 4;  
    FETCH_FLOAT4(load_a_cache[cache_idx]) =  
            FETCH_FLOAT4(A[OFFSET(a_tile_row + i, a_tile_col, K)]);  
    // Use load_a_cache for load 4 float at a time  
    // As is saved as transpose matrix  
    As[a_tile_col][a_tile_row + i] = load_a_cache[cache_idx];  
    As[a_tile_col + 1][a_tile_row + i] = load_a_cache[cache_idx + 1];  
    As[a_tile_col + 2][a_tile_row + i] = load_a_cache[cache_idx + 2];  
    As[a_tile_col + 3][a_tile_row + i] = load_a_cache[cache_idx + 3];  
&#125;
</code></pre>
<p>这里开辟了一个寄存器缓存  <code>load_a_cache</code> ，作为转置时的临时存放空间，其大小为  <code>load_a_cache_time * 4</code> 。注意下面为每次读取单独开辟了空间存储，而不是复用之前的空间。我在测试的时候发现，如果复用之前的空间，会因为数据写入地址的依赖导致计算结果出错。</p>
<pre><code class="language-c">float load_a_cache[4 * load_a_cache_time];
</code></pre>
<p>每次读取时，<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>A</mi></mrow><annotation encoding="application/x-tex">A</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal">A</span></span></span></span> 矩阵的基础行偏移量为循环变量中的  <code>i</code> ，其每次变化  <code>a_tile_stride</code> ，在此基础之上，每个线程本身还需要添加一个行偏移量  <code>a_tile_row</code> ，和列偏移量  <code>a_tile_col</code> 。每次读取 4 个元素，将其存放在  <code>load_a_cache</code>  中的对应位置， <code>cache_idx</code>  可以由  <code>i / a_tile_stride * 4</code>  计算得到， <code>i / a_tile_stride</code>  表示迭代的次数，乘 4 表示每次存放 4 个元素。</p>
<p>读取之后，我们将  <code>load_a_cache</code>  中的元素转置存放在  <code>As</code>  中，注意下标的计算。</p>
<p>类似地， <code>Bs</code>  的读取代码如下：</p>
<pre><code class="language-c">for (int i = 0; i &lt; BK; i += b_tile_stride) &#123;  
    FETCH_FLOAT4(Bs[b_tile_row + i][b_tile_col]) =  
            FETCH_FLOAT4(B[OFFSET(b_tile_row + i, b_tile_col, N)]);  
&#125;
</code></pre>
<p>因为  <code>Bs</code>  不需要转置，我们可以直接将其存放在  <code>Bs</code>  对应位置中。</p>
<p>注意上述代码中的  <code>A</code>  和  <code>B</code>  都预先添加了偏移量， <code>C</code>  也是：</p>
<pre><code class="language-c">A = &amp;A[OFFSET(blockIdx.x * BN;, 0, K)]; // Set block start position  
B = &amp;B[OFFSET(0, blockIdx.y * BM;, N)];  
C = &amp;C[OFFSET(blockIdx.x * BN, blockIdx.y * BM, N)];
</code></pre>
<p>后续的计算基本和二维 Tile 中的代码一致，只不过我们会一次性读取 4 个浮点数：</p>
<pre><code class="language-c">for (int i = 0; i &lt; BK; ++i) &#123;  
    for (int m = 0; m &lt; TM; m += 4) &#123;  
        FETCH_FLOAT4(As_cache[m]) = FETCH_FLOAT4(As[i][ty + m]);  
    &#125;  
    for (int n = 0; n &lt; TN; n += 4) &#123;  
        FETCH_FLOAT4(Bs_cache[n]) = FETCH_FLOAT4(Bs[i][tx + n]);  
    &#125;  
    for (int m = 0; m &lt; TM; ++m) &#123;  
        for (int n = 0; n &lt; TN; ++n) &#123;  
            accum[m][n] += As_cache[m] * Bs_cache[n];  
        &#125;  
    &#125;  
&#125;
</code></pre>
<div class="note info">
<p>注意本文的所有  <code>for</code>  循环代码中，为了简洁，去掉了每个  <code>for</code>  循环上的  <code>#pragma unroll</code>  循环展开指令。实际中可以添加该指令进一步提升指令吞吐。</p>
</div>
<p>后续写回结果，也可以使用  <code>float4</code>  来减少访存次数：</p>
<pre><code class="language-c">float tmp[4] = &#123;0.&#125;;  
for (int m = 0; m &lt; TM; ++m) &#123;  
    for (int n = 0; n &lt; TN; n += 4) &#123;  
        FETCH_FLOAT4(tmp) = FETCH_FLOAT4(C[OFFSET(ty + m, tx + n, N)]);  
        tmp[0] = alpha * accum[m][n] + beta * tmp[0];  
        tmp[1] = alpha * accum[m][n + 1] + beta * tmp[1];  
        tmp[2] = alpha * accum[m][n + 2] + beta * tmp[2];  
        tmp[3] = alpha * accum[m][n + 3] + beta * tmp[3];  
        FETCH_FLOAT4(C[OFFSET(ty + m, tx + n, N)]) = FETCH_FLOAT4(tmp);  
    &#125;  
&#125;
</code></pre>
<p>性能对比如下：</p>
<p><img loading="lazy" data-src="/images/cuda/SGEMM-optimization/kernel-performance/kernel-float4.png" alt="float4 kernel" /></p>
<p>可以看到，使用  <code>float4</code>  访存之后性能得到了很大的提升。每个线程的计算量并没有改变，但是现在每次可以读取 4 个浮点数，全局内存访问次数进一步降低了四分之一。而且指令的执行效率也提升。相比于访存 4 次获取 4 个浮点数，通过  <code>float4</code>  向量内存指令所需的访存指令数更少，减少了对内存访问的竞争；另一方面，使用矢量加载每个字节需要的索引计算更少。这些是隐形的对性能的提升。</p>
<p><img loading="lazy" data-src="/images/cuda/SGEMM-optimization/float4-kernel-warp-state.png" alt="float4 kernel warp state" /></p>
<p>从 profiling 结果可以看到，通过使用  <code>float4</code>  访存基本上消除了  <code>MIO</code>  的延迟。图中的其他指标的延迟也在 1~1.5 cycles per instruction 之间。</p>
<h3 id="数据预取"><a class="anchor" href="#数据预取">#</a> 数据预取</h3>
<p>在上文的代码中，我们在循环中使用了两次  <code>__syncthreads()</code>  来做线程同步，以防止不同线程之间的数据不一致。其中第一个  <code>__syncthreads()</code>  是为了保证写后读（Read-After-Write）的顺序性，这个是无法避免的。</p>
<p>关键在于后一个同步，它是为了防止部分线程还未读取  <code>As</code>  或者  <code>Bs</code>  中的内容，保证读后写（Write-After-Read）的顺序性。它本质上是因为我们在不同迭代中使用了同一块空间来保存我们所需的数据，这两次迭代中的数据之间并不存在真正的依赖关系。如果我们将其写入到其他地址上，那么就不需要使用同步了。</p>
<p>这种方式称为数据预取，又可以称为双缓存（Double Buffering）。我们可以申请两倍所需的空间，用于在迭代中交替使用，从而省去后一次线程同步的操作。</p>
<pre><code class="language-c">__shared__ float As[2][BK][BM];    // transpose shared A for avoid bank conflict, for double buffering  
__shared__ float Bs[2][BK][BN];    // for double buffering

float As_cache[2][TM] = &#123;0.&#125;;  // double buffering  
float Bs_cache[2][TN] = &#123;0.&#125;;  // double buffering
</code></pre>
<p>在迭代中，我们可以使用一个变量来控制写入的地址：</p>
<pre><code class="language-c">int write_idx = 0;

for (int k = 0; k &lt; K; k += BK) &#123;  
    for (int i = 0; i &lt; BM; i += a_tile_stride) &#123;  
        int cache_idx = i / a_tile_stride * 4;  
        FETCH_FLOAT4(load_a_cache[cache_idx]) =  
                FETCH_FLOAT4(A[OFFSET(a_tile_row + i, a_tile_col, K)]);  
        // Use load_a_cache for load 4 float at a time  
        // As is saved as transpose matrix  
        As[write_idx][a_tile_col][a_tile_row + i] = load_a_cache[cache_idx];  
        As[write_idx][a_tile_col + 1][a_tile_row + i] = load_a_cache[cache_idx + 1];  
        As[write_idx][a_tile_col + 2][a_tile_row + i] = load_a_cache[cache_idx + 2];  
        As[write_idx][a_tile_col + 3][a_tile_row + i] = load_a_cache[cache_idx + 3];  
    &#125;
    ...
    
    for (int i = 0; i &lt; BK; i += b_tile_stride) &#123;  
    FETCH_FLOAT4(Bs[write_idx][b_tile_row + i][b_tile_col]) =  
            FETCH_FLOAT4(B[OFFSET(b_tile_row + i, b_tile_col, N)]);  
    &#125;  
    __syncthreads();
    
    ...
    
    for (int i = 0; i &lt; BK; ++i) &#123;  
        for (int m = 0; m &lt; TM; m += 4) &#123;  
            FETCH_FLOAT4(As_cache[write_idx][m]) = FETCH_FLOAT4(As[write_idx][i][ty + m]);  
        &#125;  
        for (int n = 0; n &lt; TN; n += 4) &#123;  
            FETCH_FLOAT4(Bs_cache[write_idx][n]) = FETCH_FLOAT4(Bs[write_idx][i][tx + n]);  
        &#125;  
        for (int m = 0; m &lt; TM; ++m) &#123;  
            for (int n = 0; n &lt; TN; ++n) &#123;  
                accum[m][n] += As_cache[write_idx][m] * Bs_cache[write_idx][n];  
            &#125;  
        &#125;  
    &#125;  
    
    ...
    
    write_idx ^= 1;
&#125;
</code></pre>
<p>性能对比如下：</p>
<p><img loading="lazy" data-src="/images/cuda/SGEMM-optimization/kernel-performance/kernel-double-buffer.png" alt="double buffer kernel" /></p>
<p>使用双缓冲之后，因为避免了多一次的线程同步，性能得到了进一步提升。</p>
<h3 id="避免-shared-memory-bank-conflict"><a class="anchor" href="#避免-shared-memory-bank-conflict">#</a> 避免 Shared Memory Bank Conflict</h3>
<p>经过以上的优化，我们的性能已经非常接近 cuBLAS 的基线了。</p>
<p><img loading="lazy" data-src="/images/cuda/SGEMM-optimization/kernel-performance/shared-memory-bank-conflict.png" alt="shared memory bank conflict" /></p>
<p>但是通过 profiling 可以看到，对共享内存的访问上有 40% 的 Uncoalsced Memory Access。这说明共享内存的访问上存在许多 bank conflict。我们可以使用这篇<a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/518857175">矩阵优化笔记</a> 中的思路来解决这一问题。</p>
<p>我们在通过 Tile 计算的过程中，计算的都是矩阵 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>C</mi></mrow><annotation encoding="application/x-tex">C</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.07153em;">C</span></span></span></span> 中的连续区域的值，我们可以通过 interleaved 的方式，进一步对其分块<sup class="footnote-ref"><a href="#fn2" id="fnref2">[2]</a></sup>：</p>
<p><img loading="lazy" data-src="/images/cuda/SGEMM-optimization/tile-to-avoid-shared-memory-bank-conflict.png" alt="避免 shared memory bank conflict" /></p>
<p>对应到代码中，我们从  <code>As</code>  和  <code>Bs</code>  中读取数据时，不再是连续的一整块数据，而是以 4 为单位间隔读取：</p>
<pre><code class="language-c">for (int k = 0; k &lt; BK; ++k) &#123;  
    for (int m = 0, mm = 0; m &lt; BM &amp;&amp; mm &lt; TM; m += block_row_thread * 4, mm += 4) &#123;  
        int A_row = m + threadIdx.y * 4;  
        FETCH_FLOAT4(As_cache[write_idx][mm]) = FETCH_FLOAT4(As[write_idx][k][A_row]);  
    &#125;  
    for (int n = 0, nn = 0; n &lt; BN &amp;&amp; nn &lt; TN; n += block_col_thread * 4, nn += 4) &#123;  
        int B_col = n + threadIdx.x * 4;  
        FETCH_FLOAT4(Bs_cache[write_idx][nn]) = FETCH_FLOAT4(Bs[write_idx][k][B_col]);  
    &#125;
    ...
&#125;
</code></pre>
<p>而在写回结果时也要注意对矩阵 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>C</mi></mrow><annotation encoding="application/x-tex">C</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.07153em;">C</span></span></span></span> 的下标计算：</p>
<pre><code class="language-c">for (int m = 0; m &lt; TM; m += 4) &#123;  
    int C_row = (m / 4) * (block_row_thread * 4) + threadIdx.y * 4;  
    for (int n = 0; n &lt; TN; n += 4) &#123;  
        int C_col = (n / 4) * (block_col_thread * 4) + threadIdx.x * 4;  
        for (int i = 0; i &lt; 4; ++i) &#123;  
            FETCH_FLOAT4(load_a_cache) = FETCH_FLOAT4(C[OFFSET(C_row + i, C_col, N)]);  
            load_a_cache[0] = alpha * accum[m + i][n] + beta * load_a_cache[0];  
            load_a_cache[1] = alpha * accum[m + i][n + 1] + beta * load_a_cache[1];  
            load_a_cache[2] = alpha * accum[m + i][n + 2] + beta * load_a_cache[2];  
            load_a_cache[3] = alpha * accum[m + i][n + 3] + beta * load_a_cache[3];  
            FETCH_FLOAT4(C[OFFSET(C_row + i, C_col, N)]) = FETCH_FLOAT4(load_a_cache);  
        &#125;  
    &#125;  
&#125;
</code></pre>
<p><img loading="lazy" data-src="/images/cuda/SGEMM-optimization/split-tile-1d-kernel.png" alt="access pattern to avoid shared memory bank conflict" /></p>
<p><code>m</code>  和  <code>n</code>  除以 4 是因为读取时以 4 个浮点数为一组读取，这 4 个浮点数对应的行是相邻的，每 4 行之后，就需要跳跃到下一个对应的位置，乘以  <code>(block_row_thread * 4)</code>  和  <code>(block_col_thread * 4)</code>  即是为此。</p>
<p>在行和列上分别有  <code>block_row_thread</code>  和  <code>block_col_thread</code>  个线程，那么当前线程下一次操作的数据的行和列的起始位置就是  <code>(m / 4) * (block_row_thread * 4)</code>  和  <code>(n / 4) * (block_col_thread * 4)</code> 。</p>
<p>最后，再添加当前线程自己在行和列上的偏移  <code>threadIdx.y * 4</code>  和  <code>threadIdx.x * 4</code> 。</p>
<p>对于  <code>n</code>  可以使用  <code>float4</code>  的方式读取和写入，而对于  <code>m</code> ，我们需要再使用一层循环写入相邻的行中。</p>
<p><img loading="lazy" data-src="/images/cuda/SGEMM-optimization/kernel-performance/kernel-share-bank.png" alt="kernel avoid shared memory bank conflict" /></p>
<p>可以看到，在大矩阵上，现在的性能基本和 cuBLAS 持平了。我们也基本实现了我们的性能优化目标。</p>
<h3 id="寄存器-bank-冲突"><a class="anchor" href="#寄存器-bank-冲突">#</a> 寄存器 bank 冲突</h3>
<p>在处理共享内存 bank 冲突的基础之上，其实还能够进一步考虑处理寄存器的 bank 冲突<sup class="footnote-ref"><a href="#fn3" id="fnref3">[3]</a></sup><sup class="footnote-ref"><a href="#fn4" id="fnref4">[4]</a></sup>。不过这部分内容过于复杂，需要使用到  <code>SASS</code>  的 CUDA 汇编代码。这里就不去具体实现了，仅在这里记录一下。</p>
<h2 id="性能对比总结"><a class="anchor" href="#性能对比总结">#</a> 性能对比总结</h2>
<p>这里以 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>4096</mn><mo>×</mo><mn>4096</mn></mrow><annotation encoding="application/x-tex">4096\times 4096</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7278em;vertical-align:-0.0833em;"></span><span class="mord">4096</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">4096</span></span></span></span> 大小矩阵的性能总结各个优化和 cuBLAS 库的性能比较。</p>
<table>
<thead>
<tr>
<th>Kernel</th>
<th>Ratio to cuBLAS</th>
</tr>
</thead>
<tbody>
<tr>
<td>cublas</td>
<td>1</td>
</tr>
<tr>
<td>naive</td>
<td>0.106</td>
</tr>
<tr>
<td>shared memory</td>
<td>0.091</td>
</tr>
<tr>
<td>tile 1d</td>
<td>0.158</td>
</tr>
<tr>
<td>tile 2d</td>
<td>0.352</td>
</tr>
<tr>
<td>float4</td>
<td>0.857</td>
</tr>
<tr>
<td>double buffering</td>
<td>0.912</td>
</tr>
<tr>
<td>avoid shared memory bank conflict</td>
<td>0.995</td>
</tr>
</tbody>
</table>
<h2 id="总结"><a class="anchor" href="#总结">#</a> 总结</h2>
<p>这次国庆假期前前后后断断续续花费了 5 天完成了这篇优化笔记。前两天几乎全部花在代码编写上，后面三天断断续续完成了文章的内容。为了完成这篇内容，这期间参考了许多的笔记和资料<sup class="footnote-ref"><a href="#fn5" id="fnref5">[5]</a></sup><sup class="footnote-ref"><a href="#fn6" id="fnref6">[6]</a></sup><sup class="footnote-ref"><a href="#fn7" id="fnref7">[7]</a></sup>，最后总算也得到了一个很好的优化结果。之前一直都是单纯的资料阅读，这次的实践确实收获颇丰，自己动手编写代码和直接调用别人的接口感觉确实有很大不同。CUDA 编程也需要了解更多的硬件相关的知识，这次实践中也了解了不少。“纸上得来终觉浅，绝知此事要躬行”。后续可能进一步考虑学习其他深度学习的重要算子的优化。</p>
<p>本次的代码放在我的<a target="_blank" rel="noopener" href="https://github.com/YangLinzhuo/cuda-sgemm-optimization/tree/main">仓库</a>上了，可供参考。</p>
<p>以上。</p>
<h2 id="change-log"><a class="anchor" href="#change-log">#</a> Change Log</h2>
<ul>
<li>2023-10-14：补充 Nsight Compute profiling 结果，修正部分文本错误和措辞</li>
<li>2023-10-15：重绘一些插图</li>
</ul>
<h2 id="附录"><a class="anchor" href="#附录">#</a> 附录</h2>
<h3 id="clion-cuda-编程配置"><a class="anchor" href="#clion-cuda-编程配置">#</a> CLion CUDA 编程配置</h3>
<p>使用 CLion 创建 CUDA 工程， <code>CMakeLists.txt</code>  内容如下：</p>
<pre><code class="language-cmake">cmake_minimum_required(VERSION 3.22)
project(sgemm LANGUAGES CXX CUDA)

set(CMAKE_CUDA_STANDARD 20)
set(CMAKE_CUDA_FLAGS &quot;-O3&quot;)
# For debug
# set(CMAKE_CUDA_FLAGS &quot;-g -G&quot;)
# For Nsight Compute Profiling
# set (CMAKE_CUDA_FLAGS &quot;$&#123;CMAKE_CUDA_FLAGS&#125; -lineinfo&quot;)

find_package(CUDAToolkit REQUIRED)

add_executable($&#123;PROJECT_NAME&#125; main.cu
        src/utils.cu
        src/kernels.cu)

# 可执行文件输出路径
# https://gist.github.com/gavinb/c993f71cf33d2354515c4452a3f8ef30
set(EXECUTABLE_OUTPUT_PATH $&#123;PROJECT_SOURCE_DIR&#125;)

set_target_properties($&#123;PROJECT_NAME&#125; PROPERTIES
        CUDA_SEPARABLE_COMPILATION ON)
# 查询 compute capability https://developer.nvidia.com/cuda-gpus
set_target_properties($&#123;PROJECT_NAME&#125; PROPERTIES CUDA_ARCHITECTURES &quot;86&quot;)

# 配置头文件搜索路径
# 配置 CUDA 相关库头文件
# 参考
# https://stackoverflow.com/questions/51756562/obtaining-the-cuda-include-dir-in-c-targets-with-native-cuda-support-cmake
target_include_directories($&#123;PROJECT_NAME&#125; PRIVATE $&#123;CMAKE_CUDA_TOOLKIT_INCLUDE_DIRECTORIES&#125;)
target_include_directories($&#123;PROJECT_NAME&#125; PUBLIC $&#123;PROJECT_SOURCE_DIR&#125;/src)

# link cudart cublas
target_link_libraries($&#123;PROJECT_NAME&#125; PRIVATE CUDA::cublas)
</code></pre>
<p>此外，需要在  <code>Settings -&gt; Build,Execution,Deployment -&gt; CMake</code>  中的  <code>CMake options</code>  中添加以下参数：</p>
<pre><code class="language-txt">-DCMAKE_CUDA_COMPILER=/usr/local/cuda/bin/nvcc
</code></pre>
<h3 id="cublas-库接口调用"><a class="anchor" href="#cublas-库接口调用">#</a> cuBLAS 库接口调用</h3>
<p>使用  <code>cuBLAS</code>  的矩阵乘法接口  <code>cublasSgemm</code>  函数时，需要注意其参数传递<sup class="footnote-ref"><a href="#fn8" id="fnref8">[8]</a></sup>。</p>
<p>具体的封装参考如下：</p>
<pre><code class="language-c">void test_cublas(cublasHandle_t handle, int M, int N, int K,
                 float alpha, float *A, float *B, float beta, float *C) &#123;
    //cublas列主序计算：https://www.cnblogs.com/cuancuancuanhao/p/7763256.html
    cublasSgemm(handle, CUBLAS_OP_N, CUBLAS_OP_N, N, M, K, &amp;alpha, B, N, A, K, &amp;beta, C, N);
&#125;
</code></pre>
<h3 id="cuda-程序性能-profiling"><a class="anchor" href="#cuda-程序性能-profiling">#</a> CUDA 程序性能 Profiling</h3>
<p>CUDA 性能 profiling 可以去官网<sup class="footnote-ref"><a href="#fn9" id="fnref9">[9]</a></sup>下载 Nsight Compute 和 Nsight System 工具。其中 System 用于粗粒度的性能分析，Compute 用于对核函数的细粒度性能分析。</p>
<hr class="footnotes-sep" />
<section class="footnotes">
<ol class="footnotes-list">
<li id="fn1" class="footnote-item"><p>实际上，对于非 4 的倍数的元素个数，也是可以使用  <code>float4</code>  来访存的，但是在边界条件判断上需要更细致的处理，对性能也会有一定的影响。 <a href="#fnref1" class="footnote-backref">↩︎</a></p>
</li>
<li id="fn2" class="footnote-item"><p>图片来自于这篇知乎的<a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/518857175">矩阵优化笔记</a> <a href="#fnref2" class="footnote-backref">↩︎</a></p>
</li>
<li id="fn3" class="footnote-item"><p><a target="_blank" rel="noopener" href="http://zh0ngtian.tech/posts/96744e8c.html">CUDA 知识点：bank 冲突 | CUDA - zhongtian's blog (zh0ngtian.tech)</a> <a href="#fnref3" class="footnote-backref">↩︎</a></p>
</li>
<li id="fn4" class="footnote-item"><p><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/481600052">深入浅出 GPU 优化系列：GEMM 优化（三） - 知乎 (zhihu.com)</a> <a href="#fnref4" class="footnote-backref">↩︎</a></p>
</li>
<li id="fn5" class="footnote-item"><p><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/518857175">CUDA SGEMM 矩阵乘法优化笔记 —— 从入门到 cublas - 知乎 (zhihu.com)</a> <a href="#fnref5" class="footnote-backref">↩︎</a></p>
</li>
<li id="fn6" class="footnote-item"><p><a target="_blank" rel="noopener" href="https://github.com/wangzyon/NVIDIA_SGEMM_PRACTICE">wangzyon/NVIDIA_SGEMM_PRACTICE: Step-by-step optimization of CUDA SGEMM (github.com)</a> <a href="#fnref6" class="footnote-backref">↩︎</a></p>
</li>
<li id="fn7" class="footnote-item"><p><a target="_blank" rel="noopener" href="https://siboehm.com/articles/22/CUDA-MMM">How to Optimize a CUDA Matmul Kernel for cuBLAS-like Performance: a Worklog (siboehm.com)</a> <a href="#fnref7" class="footnote-backref">↩︎</a></p>
</li>
<li id="fn8" class="footnote-item"><p><a target="_blank" rel="noopener" href="https://www.cnblogs.com/cuancuancuanhao/p/7763256.html">有关 CUBLAS 中的矩阵乘法函数 - 爨爨爨好 - 博客园 (cnblogs.com)</a> <a href="#fnref8" class="footnote-backref">↩︎</a></p>
</li>
<li id="fn9" class="footnote-item"><p><a target="_blank" rel="noopener" href="https://developer.nvidia.com/gameworksdownload#?dn=nsight-systems-2023-3">Gameworks Download Center | NVIDIA Developer</a> <a href="#fnref9" class="footnote-backref">↩︎</a></p>
</li>
</ol>
</section>
<div class="tags"><a href="/tags/Computer-Science/" rel="tag"><i class="ic i-tag"></i>Computer-Science</a><a href="/tags/Algorithm/" rel="tag"><i class="ic i-tag"></i>Algorithm</a><a href="/tags/CUDA/" rel="tag"><i class="ic i-tag"></i>CUDA</a></div></div><footer><div class="meta"><span class="item"><span class="icon"><i class="ic i-eye"></i></span><span class="text">总访问量：</span><span class="waline-pageview-count" id="twikoo_visitors" data-path="/Computer-Science/CUDA/CUDA-SGEMM-optimization-notes/">加载中...</span></span><span class="item"><span class="icon"><i class="ic i-calendar-check"></i></span><span class="text">更新于 </span><time title="修改时间：2024-11-08 23:43:51" itemprop="dateModified" datetime="2024-11-08T23:43:51+08:00">2024-11-08</time></span></div><div class="reward"><button><i class="ic i-heartbeat"></i>赞赏</button><p>请我喝[茶]~(￣▽￣)~*</p><div id="qr"><div><img loading="lazy" data-src="/assets/wechatpay_Linn.png" alt="Linn 微信支付"/><p>微信支付</p></div><div><img loading="lazy" data-src="/assets/alipay_Linn.png" alt="Linn 支付宝"/><p>支付宝</p></div></div></div><div id="copyright"><ul><li class="author"><strong>本文作者：</strong>Linn<i class="ic i-at"><em>@</em></i>林•初夏</li><li class="link"><strong>本文链接：</strong><a href="https://linn-ylz.com/Computer-Science/CUDA/CUDA-SGEMM-optimization-notes/" title="CUDA SGEMM优化笔记">https://linn-ylz.com/Computer-Science/CUDA/CUDA-SGEMM-optimization-notes/</a></li><li class="license"><strong>版权声明：</strong>本站所有文章除特别声明外，均采用 <a target="_blank" rel="noopener" href="https://creativecommons.org/licenses/by-nc-sa/4.0/deed.zh"><i class="ic i-creative-commons"><em>(CC)</em></i>BY-NC-SA</a> 许可协议。转载请注明出处！</li></ul></div></footer></article></div><div class="post-nav"><div class="item left"><a href="/Computer-Science/Python/python-type-annotations-and-custom-types/" rel="prev" itemprop="url" data-background-image="https:&#x2F;&#x2F;cdn.jsdelivr.net&#x2F;gh&#x2F;YangLinzhuo&#x2F;yanglinzhuo.github.io@latest&#x2F;images&#x2F;article-cover&#x2F;img(74).webp" title="Python 类型注释及自定义类型"><span class="type">上一篇</span><span class="category"><i class="ic i-flag"></i>Python</span><h3>Python 类型注释及自定义类型</h3></a></div><div class="item right"><a href="/Computer-Science/Algorithm/binary-search-revision/" rel="next" itemprop="url" data-background-image="https:&#x2F;&#x2F;cdn.jsdelivr.net&#x2F;gh&#x2F;YangLinzhuo&#x2F;yanglinzhuo.github.io@latest&#x2F;images&#x2F;article-cover&#x2F;img(16).webp" title="二分搜索再探"><span class="type">下一篇</span><span class="category"><i class="ic i-flag"></i>Algorithm</span><h3>二分搜索再探</h3></a></div></div><div class="wrap" id="comments"></div></div><div id="sidebar"><div class="inner"><div class="panels"><div class="inner"><div class="contents panel pjax" data-title="文章目录"><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%89%8D%E8%A8%80"><span class="toc-number">1.</span> <span class="toc-text"> 前言</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86"><span class="toc-number">2.</span> <span class="toc-text"> 基础知识</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#gpu-%E8%AE%A1%E7%AE%97%E6%A8%A1%E5%9E%8B"><span class="toc-number">2.1.</span> <span class="toc-text"> GPU 计算模型</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#gpu-%E5%86%85%E5%AD%98%E6%A8%A1%E5%9E%8B"><span class="toc-number">2.2.</span> <span class="toc-text"> GPU 内存模型</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#gemm-%E7%AE%97%E6%B3%95%E4%BC%98%E5%8C%96"><span class="toc-number">3.</span> <span class="toc-text"> GEMM 算法优化</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#naive-%E5%AE%9E%E7%8E%B0"><span class="toc-number">3.1.</span> <span class="toc-text"> Naive 实现</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%BD%BF%E7%94%A8-shared-memory-%E4%BC%98%E5%8C%96%E8%AE%BF%E5%AD%98"><span class="toc-number">3.2.</span> <span class="toc-text"> 使用 Shared Memory 优化访存</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%B8%80%E7%BB%B4-tile"><span class="toc-number">3.3.</span> <span class="toc-text"> 一维 Tile</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%BA%8C%E7%BB%B4-tile"><span class="toc-number">3.4.</span> <span class="toc-text"> 二维 Tile</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%BD%BF%E7%94%A8%E5%AF%84%E5%AD%98%E5%99%A8%E8%BF%9B%E4%B8%80%E6%AD%A5%E4%BC%98%E5%8C%96%E8%AE%BF%E5%AD%98"><span class="toc-number">3.5.</span> <span class="toc-text"> 使用寄存器进一步优化访存</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%BD%BF%E7%94%A8-float4-%E6%8C%87%E4%BB%A4%E4%BC%98%E5%8C%96%E8%AE%BF%E5%AD%98"><span class="toc-number">3.6.</span> <span class="toc-text"> 使用 FLOAT4 指令优化访存</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%95%B0%E6%8D%AE%E9%A2%84%E5%8F%96"><span class="toc-number">3.7.</span> <span class="toc-text"> 数据预取</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E9%81%BF%E5%85%8D-shared-memory-bank-conflict"><span class="toc-number">3.8.</span> <span class="toc-text"> 避免 Shared Memory Bank Conflict</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%AF%84%E5%AD%98%E5%99%A8-bank-%E5%86%B2%E7%AA%81"><span class="toc-number">3.9.</span> <span class="toc-text"> 寄存器 bank 冲突</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%80%A7%E8%83%BD%E5%AF%B9%E6%AF%94%E6%80%BB%E7%BB%93"><span class="toc-number">4.</span> <span class="toc-text"> 性能对比总结</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%80%BB%E7%BB%93"><span class="toc-number">5.</span> <span class="toc-text"> 总结</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#change-log"><span class="toc-number">6.</span> <span class="toc-text"> Change Log</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E9%99%84%E5%BD%95"><span class="toc-number">7.</span> <span class="toc-text"> 附录</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#clion-cuda-%E7%BC%96%E7%A8%8B%E9%85%8D%E7%BD%AE"><span class="toc-number">7.1.</span> <span class="toc-text"> CLion CUDA 编程配置</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#cublas-%E5%BA%93%E6%8E%A5%E5%8F%A3%E8%B0%83%E7%94%A8"><span class="toc-number">7.2.</span> <span class="toc-text"> cuBLAS 库接口调用</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#cuda-%E7%A8%8B%E5%BA%8F%E6%80%A7%E8%83%BD-profiling"><span class="toc-number">7.3.</span> <span class="toc-text"> CUDA 程序性能 Profiling</span></a></li></ol></li></ol></div><div class="related panel pjax" data-title="系列文章"><ul><li  class="active"><a href="/Computer-Science/CUDA/CUDA-SGEMM-optimization-notes/" rel="bookmark" title="CUDA SGEMM优化笔记">CUDA SGEMM优化笔记</a></li><li ><a href="/Computer-Science/CUDA/CUTLASS/cute-layout/" rel="bookmark" title="CUTLASS 中的 CuTe Layout">CUTLASS 中的 CuTe Layout</a></li></ul></div><div class="overview panel" data-title="站点概览"><div class="author" itemprop="author" itemscope="itemscope" itemtype="http://schema.org/Person"><img class="image" loading="lazy" decoding="async" itemprop="image" alt="Linn" src="/assets/my_small_avatar.jpg"/><p class="name" itemprop="name">Linn</p><div class="description" itemprop="description">Linn 的个人博客</div></div><nav class="state"><div class="item posts"><a href="/archives/"><span class="count">39</span><span class="name">文章</span></a></div><div class="item categories"><a href="/categories/"><span class="count">15</span><span class="name">分类</span></a></div><div class="item tags"><a href="/tags/"><span class="count">35</span><span class="name">标签</span></a></div></nav><div class="social"><a target="_blank" rel="noopener" href="https://github.com/YangLinzhuo" class="item github" title="https:&#x2F;&#x2F;github.com&#x2F;YangLinzhuo"><i class="ic i-github"></i></a><a target="_blank" rel="noopener" href="https://www.zhihu.com/people/yang-lin-zhuo" class="item zhihu" title="https:&#x2F;&#x2F;www.zhihu.com&#x2F;people&#x2F;yang-lin-zhuo"><i class="ic i-zhihu"></i></a><a target="_blank" rel="noopener" href="https://music.163.com/#/user/home?id=279175670" class="item music" title="https:&#x2F;&#x2F;music.163.com&#x2F;#&#x2F;user&#x2F;home?id&#x3D;279175670"><i class="ic i-cloud-music"></i></a><a target="_blank" rel="noopener" href="https://weibo.com/linnylz" class="item weibo" title="https:&#x2F;&#x2F;weibo.com&#x2F;linnylz"><i class="ic i-weibo"></i></a><a target="_blank" rel="noopener" href="https://www.douban.com/people234187316/" class="item douban" title="https:&#x2F;&#x2F;www.douban.com&#x2F;people234187316&#x2F;"><i class="ic i-douban"></i></a><a href="mailto:yanglinzhuo@outlook.com" class="item email" title="mailto:yanglinzhuo@outlook.com"><i class="ic i-envelope"></i></a></div><div class="menu"><li class="item"><a href="/" rel="section"><i class="ic i-home"></i>首页</a></li><li class="item dropdown"><a href="#" onclick="return false;"><i class="ic i-feather"></i>文章</a><ul class="submenu"><li class="item"><a href="/archives/" rel="section"><i class="ic i-list-alt"></i>归档</a></li><li class="item"><a href="/categories/" rel="section"><i class="ic i-th"></i>分类</a></li><li class="item"><a href="/tags/" rel="section"><i class="ic i-tags"></i>标签</a></li></ul></li><li class="item dropdown"><a href="/links/" rel="section"><i class="ic i-link"></i>链接</a><ul class="submenu"><li class="item"><a href="/links/friend/" rel="section"><i class="ic i-heart"></i>友链</a></li><li class="item"><a href="/links/webstack/" rel="section"><i class="ic i-external-link-alt"></i>书签</a></li></ul></li></div></div></div></div><ul id="quick"><li class="prev pjax"><a href="/Computer-Science/Algorithm/binary-search-revision/" rel="prev" title="上一篇"><i class="ic i-chevron-left"></i></a></li><li class="up"><i class="ic i-arrow-up"></i></li><li class="down"><i class="ic i-arrow-down"></i></li><li class="next pjax"><a href="/Computer-Science/Python/python-type-annotations-and-custom-types/" rel="next" title="下一篇"><i class="ic i-chevron-right"></i></a></li><li class="percent"></li></ul></div></div><div class="dimmer"></div></div></main><footer id="footer"><div class="inner"><div class="widgets"><div class="rpost pjax"><h2>随机文章</h2><ul><li class="item"><div class="breadcrumb"><a href="/categories/Computer-Science/" title="分类于Computer-Science">Computer-Science</a><i class="ic i-angle-right"></i><a href="/categories/Computer-Science/Coding-Interviews/" title="分类于Coding-Interviews">Coding-Interviews</a></div><span><a href="/Computer-Science/Coding-Interviews/coding-interviews-8/">剑指 Offer （八）</a></span></li><li class="item"><div class="breadcrumb"><a href="/categories/Computer-Science/" title="分类于Computer-Science">Computer-Science</a><i class="ic i-angle-right"></i><a href="/categories/Computer-Science/Programming-Pearls/" title="分类于Programming-Pearls">Programming-Pearls</a></div><span><a href="/Computer-Science/Programming-Pearls/chapter-1-cracking-the-oyster/">《编程珠玑》（一）——开篇</a></span></li><li class="item"><div class="breadcrumb"><a href="/categories/Hexo/" title="分类于Hexo">Hexo</a></div><span><a href="/Hexo/transfer-waline-2/">ShokaX 主题迁移</a></span></li><li class="item"><div class="breadcrumb"><a href="/categories/Computer-Science/" title="分类于Computer-Science">Computer-Science</a><i class="ic i-angle-right"></i><a href="/categories/Computer-Science/Configs/" title="分类于Configs">Configs</a></div><span><a href="/Computer-Science/Configs/oh-my-zsh-and-plugins/">Oh My Zsh 及插件配置</a></span></li><li class="item"><div class="breadcrumb"><a href="/categories/History/" title="分类于History">History</a><i class="ic i-angle-right"></i><a href="/categories/History/ChineseHistory/" title="分类于ChineseHistory">ChineseHistory</a></div><span><a href="/History/Chinese-History/chinese-era-table/">中國歷史紀年表</a></span></li><li class="item"><div class="breadcrumb"><a href="/categories/Computer-Science/" title="分类于Computer-Science">Computer-Science</a><i class="ic i-angle-right"></i><a href="/categories/Computer-Science/Emacs/" title="分类于Emacs">Emacs</a></div><span><a href="/Computer-Science/Emacs/emacs-learning-3/">Emacs 学习（三）Org-mode 学习</a></span></li><li class="item"><div class="breadcrumb"><a href="/categories/Computer-Science/" title="分类于Computer-Science">Computer-Science</a><i class="ic i-angle-right"></i><a href="/categories/Computer-Science/Coding-Interviews/" title="分类于Coding-Interviews">Coding-Interviews</a></div><span><a href="/Computer-Science/Coding-Interviews/coding-interviews-6/">剑指 Offer （六）</a></span></li><li class="item"><div class="breadcrumb"><a href="/categories/Computer-Science/" title="分类于Computer-Science">Computer-Science</a><i class="ic i-angle-right"></i><a href="/categories/Computer-Science/Coding-Interviews/" title="分类于Coding-Interviews">Coding-Interviews</a></div><span><a href="/Computer-Science/Coding-Interviews/coding-interviews-2/">剑指 Offer （二）</a></span></li><li class="item"><div class="breadcrumb"><a href="/categories/Essay/" title="分类于Essay">Essay</a></div><span><a href="/Essay/chinese-ancient-book/">中国古籍电子化尝试</a></span></li><li class="item"><div class="breadcrumb"><a href="/categories/Computer-Science/" title="分类于Computer-Science">Computer-Science</a><i class="ic i-angle-right"></i><a href="/categories/Computer-Science/Configs/" title="分类于Configs">Configs</a></div><span><a href="/Computer-Science/Configs/clion-wsl2-cuda-configs/">通过 CLion 在 WSL2 的 CUDA 环境下使用 libtorch</a></span></li></ul></div><div class="rpost pjax"><h2>最新评论</h2><ul class="leancloud-recent-comment" id="new-comment"></ul></div></div><div class="status"><div class="copyright">&copy; 2021 -<span itemprop="copyrightYear">2025</span><span class="with-love"><i class="ic i-sakura rotate"></i></span><span class="author" itemprop="copyrightHolder">Linn @ Linn's Shoka</span></div><div class="count"><span class="post-meta-item-icon"><i class="ic i-chart-area"></i></span><span title="站点总字数">310k 字</span><span class="post-meta-divider"> | </span><span class="post-meta-item-icon"><i class="ic i-coffee"></i></span><span title="站点阅读时长">4:42</span></div><div class="powered-by">基于 <a target="_blank" rel="noopener" href="https://hexo.io/">Hexo</a> & Theme.<a target="_blank" rel="noopener" href="https://github.com/theme-shoka-x/hexo-theme-shokaX/">ShokaX</a></div></div></div></footer></div><script data-config type="text/javascript">var LOCAL = {
    ispost: true,
    path: `Computer-Science/CUDA/CUDA-SGEMM-optimization-notes/`,
    favicon: {
        show: `（●´3｀●）やれやれだぜ`,
        hide: `(´Д｀)大変だ！`
    },
    search: {
        placeholder: "文章搜索",
        empty: "关于 「 ${query} 」，什么也没搜到",
        stats: "${time} ms 内找到 ${hits} 条结果"
    },
    nocopy: "false",
    copyright: `复制成功，转载请遵守 <i class="ic i-creative-commons"></i>BY-NC-SA 协议。`,
    copy_tex: true,
    katex: true,
    mermaid: false,
    audio: undefined,
    fancybox: true,
    nocopy: false,
    outime: true,
    template: `<div class="note warning"><p><span class="label warning">文章时效性提示</span><br>这是一篇发布于 {{publish}} 天前，最后一次更新在 {{updated}} 天前的文章，部分信息可能已经发生改变，请注意甄别。</p></div>`,
    quiz: {
        choice: `单选题`,
        multiple: `多选题`,
        true_false: `判断题`,
        essay: `问答题`,
        gap_fill: `填空题`,
        mistake: `错题备注`
    },
    ignores: [
        (uri) => uri.includes('#'),
        (uri) => new RegExp(LOCAL.path + '$').test(uri),
            []
    ]
};
</script><script src="https://s4.zstatic.net/ajax/libs/pace/1.2.4/pace.min.js" integrity="sha384-k6YtvFUEIuEFBdrLKJ3YAUbBki333tj1CSUisai5Cswsg9wcLNaPzsTHDswp4Az8" crossorigin="anonymous" fetchpriority="high"></script><script src="https://s4.zstatic.net/ajax/libs/jquery/3.5.1/jquery.min.js" integrity="sha384-ZvpUoO&#x2F;+PpLXR1lu4jmpXWu80pZlYUAfxl5NsBMWOEPSjUn&#x2F;6Z&#x2F;hRTt8+pR6L4N2" crossorigin="anonymous" fetchpriority="high"></script><script src="https://s4.zstatic.net/ajax/libs/fancybox/3.5.7/jquery.fancybox.min.js" integrity="sha384-Zm+UU4tdcfAm29vg+MTbfu&#x2F;&#x2F;q5B&#x2F;lInMbMCr4T8c9rQFyOv6PlfQYpB5wItcXWe7" crossorigin="anonymous" fetchpriority="high"></script><script src="https://s4.zstatic.net/ajax/libs/justifiedGallery/3.8.1/js/jquery.justifiedGallery.min.js" integrity="sha384-TOxsBplaL96&#x2F;QDWPIUg+ye3v89qSE3s22XNtJMmCeZEep3cVDmXy1zEfZvVv+y2m" crossorigin="anonymous" fetchpriority="high"></script><script src="/js/siteInit.js?v=0.4.21" type="module" fetchpriority="high" defer></script><!-- hexo injector body_end start --><script src="/assets/mmedia/mmedia-loader.js"></script><!-- hexo injector body_end end --></body></html>