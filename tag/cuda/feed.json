{
    "version": "https://jsonfeed.org/version/1",
    "title": "林•初夏 • All posts by \"cuda\" tag",
    "description": "",
    "home_page_url": "https://linn-ylz.com",
    "items": [
        {
            "id": "https://linn-ylz.com/Computer-Science/CUDA/CUDA-SGEMM-optimization-notes/",
            "url": "https://linn-ylz.com/Computer-Science/CUDA/CUDA-SGEMM-optimization-notes/",
            "title": "CUDA SGEMM优化笔记",
            "date_published": "2023-10-01T01:19:53.000Z",
            "content_html": "<h2 id=\"前言\"><a class=\"markdownIt-Anchor\" href=\"#前言\">#</a> 前言</h2>\n<p>本篇博客记录了最近学习的 CUDA 单精度 GEMM 算法的优化过程。</p>\n<p>GEMM 算法是指 General Matrix Multiplication 算法，可以说是大多数线性代数算法的基础，也是目前热门的深度学习中最常用的基础计算，因此优化 GEMM 算法对于许多的应用有着重大意义。本篇博客关注的是 NVIDIA 的 GPU 设备上的 GEMM 算法实现，以 cuBLAS 库的算法性能作为比较基线，不断优化算法以逼近该基线。</p>\n<p><img loading=\"lazy\" data-src=\"/images/cuda/SGEMM-optimization/kernel-performance/kernel-cublas.png\" alt=\"cuBLAS kernel\"></p>\n<h2 id=\"基础知识\"><a class=\"markdownIt-Anchor\" href=\"#基础知识\">#</a> 基础知识</h2>\n<p>本节将简要介绍 GPU 的计算模型和内存模型的基础知识。因为算法优化部分的内容较长，本节尽量精简。如果之后有时间，后续可能会详细介绍该部分的内容。</p>\n<h3 id=\"gpu-计算模型\"><a class=\"markdownIt-Anchor\" href=\"#gpu-计算模型\">#</a> GPU 计算模型</h3>\n<p><img loading=\"lazy\" data-src=\"/images/cuda/SGEMM-optimization/CUDA-computation-model.png\" alt=\"CUDA Computation Model\"></p>\n<p>GPU 的计算模型可以分为上图所示的三级。最基础的执行单元是 thread，用于执行控制单元下发的指令。每个 thread 都属于某一个 block，block 可以有三个维度，在线程中可以通过 CUDA 内置的变量来获取线程对应的 id。每个 block 则又属于一个 grid，grid 也可以有三个维度，有 CUDA 内置变量用于确定 block 的 id。</p>\n<p>对于 thread，可以使用  <code>threadIdx.x</code> ， <code>threadIdx.y</code> ， <code>threadIdx.z</code>  获取其在三个维度上的坐标以确定其 “身份”。当然，如果某一个维度的大小为 1，那么我们计算时可以省略。我们可以通过  <code>blockDim.x</code> ， <code>blockDim.y</code> ， <code>blockDim.z</code>  获取线程所在 block 三个维度的大小。类似地，block 可以使用  <code>blockIdx.x</code> ， <code>bloxkIdx.y</code> ， <code>blockIdx.z</code>  获取其在三个维度上的坐标， <code>gridDim.x</code> ， <code>gridDim.y</code> ， <code>gridDim.z</code>  可以获取 block 所在 grid 的三个维度的大小。</p>\n<p>而具体到调度层面，需要注意，CUDA 以 block 为单位，将其中的线程调度到某一个 SM（Streaming Multiprocessor）上执行，而在真正执行的时候，CUDA 会将 block 中的线程以 32 个为一个 warp 进行调度，它们的线程 id 连续。如果线程数量不是 32 的倍数，那么 CUDA 会将其补齐。所以我们为每个 block 分配线程时，尽量将数量设置为 32 的倍数。</p>\n<p>另外提一句，在访存的时候，会以 half-warp 为单位访存，也就是线程 id 连续的 16 个线程一组进行访存，在考虑 bank conflict 的时候需要注意这一点。</p>\n<p>在调用编写的核函数时，我们需要指定 grid 和 block 的维度，一个简单的示例如下：</p>\n<figure class=\"highlight c\"><figcaption data-lang=\"c\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre><span class=\"token comment\">// Kernel definition  </span></pre></td></tr><tr><td data-num=\"2\"></td><td><pre>__global__ <span class=\"token keyword\">void</span> <span class=\"token function\">MatAdd</span><span class=\"token punctuation\">(</span><span class=\"token keyword\">float</span> A<span class=\"token punctuation\">[</span>N<span class=\"token punctuation\">]</span><span class=\"token punctuation\">[</span>N<span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span> <span class=\"token keyword\">float</span> B<span class=\"token punctuation\">[</span>N<span class=\"token punctuation\">]</span><span class=\"token punctuation\">[</span>N<span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span> <span class=\"token keyword\">float</span> C<span class=\"token punctuation\">[</span>N<span class=\"token punctuation\">]</span><span class=\"token punctuation\">[</span>N<span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>  </pre></td></tr><tr><td data-num=\"3\"></td><td><pre><span class=\"token punctuation\">&#123;</span>  </pre></td></tr><tr><td data-num=\"4\"></td><td><pre>    <span class=\"token keyword\">int</span> i <span class=\"token operator\">=</span> blockIdx<span class=\"token punctuation\">.</span>x <span class=\"token operator\">*</span> blockDim<span class=\"token punctuation\">.</span>x <span class=\"token operator\">+</span> threadIdx<span class=\"token punctuation\">.</span>x<span class=\"token punctuation\">;</span>  </pre></td></tr><tr><td data-num=\"5\"></td><td><pre>    <span class=\"token keyword\">int</span> j <span class=\"token operator\">=</span> blockIdx<span class=\"token punctuation\">.</span>y <span class=\"token operator\">*</span> blockDim<span class=\"token punctuation\">.</span>y <span class=\"token operator\">+</span> threadIdx<span class=\"token punctuation\">.</span>y<span class=\"token punctuation\">;</span>  </pre></td></tr><tr><td data-num=\"6\"></td><td><pre>    <span class=\"token keyword\">if</span> <span class=\"token punctuation\">(</span>i <span class=\"token operator\">&lt;</span> N <span class=\"token operator\">&amp;&amp;</span> j <span class=\"token operator\">&lt;</span> N<span class=\"token punctuation\">)</span>  </pre></td></tr><tr><td data-num=\"7\"></td><td><pre>        C<span class=\"token punctuation\">[</span>i<span class=\"token punctuation\">]</span><span class=\"token punctuation\">[</span>j<span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> A<span class=\"token punctuation\">[</span>i<span class=\"token punctuation\">]</span><span class=\"token punctuation\">[</span>j<span class=\"token punctuation\">]</span> <span class=\"token operator\">+</span> B<span class=\"token punctuation\">[</span>i<span class=\"token punctuation\">]</span><span class=\"token punctuation\">[</span>j<span class=\"token punctuation\">]</span><span class=\"token punctuation\">;</span>  </pre></td></tr><tr><td data-num=\"8\"></td><td><pre><span class=\"token punctuation\">&#125;</span>  </pre></td></tr><tr><td data-num=\"9\"></td><td><pre><span class=\"token keyword\">int</span> <span class=\"token function\">main</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>  </pre></td></tr><tr><td data-num=\"10\"></td><td><pre><span class=\"token punctuation\">&#123;</span>  </pre></td></tr><tr><td data-num=\"11\"></td><td><pre>    <span class=\"token punctuation\">.</span><span class=\"token punctuation\">.</span><span class=\"token punctuation\">.</span>  </pre></td></tr><tr><td data-num=\"12\"></td><td><pre>    <span class=\"token comment\">// Kernel invocation  </span></pre></td></tr><tr><td data-num=\"13\"></td><td><pre>    dim3 <span class=\"token function\">threadsPerBlock</span><span class=\"token punctuation\">(</span><span class=\"token number\">16</span><span class=\"token punctuation\">,</span> <span class=\"token number\">16</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>  </pre></td></tr><tr><td data-num=\"14\"></td><td><pre>    dim3 <span class=\"token function\">numBlocks</span><span class=\"token punctuation\">(</span>N <span class=\"token operator\">/</span> threadsPerBlock<span class=\"token punctuation\">.</span>x<span class=\"token punctuation\">,</span> N <span class=\"token operator\">/</span> threadsPerBlock<span class=\"token punctuation\">.</span>y<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>  </pre></td></tr><tr><td data-num=\"15\"></td><td><pre>    MatAdd<span class=\"token operator\">&lt;&lt;</span><span class=\"token operator\">&lt;</span>numBlocks<span class=\"token punctuation\">,</span> threadsPerBlock<span class=\"token operator\">>></span><span class=\"token operator\">></span><span class=\"token punctuation\">(</span>A<span class=\"token punctuation\">,</span> B<span class=\"token punctuation\">,</span> C<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>  </pre></td></tr><tr><td data-num=\"16\"></td><td><pre>    <span class=\"token punctuation\">.</span><span class=\"token punctuation\">.</span><span class=\"token punctuation\">.</span>  </pre></td></tr><tr><td data-num=\"17\"></td><td><pre><span class=\"token punctuation\">&#125;</span></pre></td></tr></table></figure><h3 id=\"gpu-内存模型\"><a class=\"markdownIt-Anchor\" href=\"#gpu-内存模型\">#</a> GPU 内存模型</h3>\n<p>GPU 的内存可以分为 off-chip 和 on-chip 内存两大类别。off-chip 的特点是容量大，但是访存延迟高；on-chip 的特点则是容量小，但是访存延迟低。</p>\n<p>off-chip 内存主要有 global memory，on-chip 内存则主要有 shared memory 和 register。三者中，register 的访存速度最快，shared memory 次之，global memory 最慢。</p>\n<p><img loading=\"lazy\" data-src=\"/images/cuda/SGEMM-optimization/memory-hierarchy.png\" alt=\"CUDA Memory Hierarchy\"></p>\n<p>如上图所示，每个 block 之间共享 global memory，而每个 block 自己则有一块 shared memory，block 中的每个 thread 共享这块 shared memory。此外，每个线程有自己独占的 register 和 local memory，local memory 一般也存放在 global memory 中。</p>\n<p>由于 global memory 访存延迟较高，我们很多时候都会将数据读取到 shared memory 中；在某些情况下，甚至会手动使用 register 来缓存 shared memory 中的数据。</p>\n<p>可以说，想要优化好 CUDA 上的算法，必须要注意降低或者隐藏访存延迟的开销，在后续的算法优化中我们可以看到这一点。</p>\n<p>在调用编写的核函数之前，我们需要使用  <code>cudaMalloc</code>  和  <code>cudaMemcpy</code>  函数来在 GPU 上分配内存，并将 host 侧的数据拷贝到 device 侧。</p>\n<h2 id=\"gemm-算法优化\"><a class=\"markdownIt-Anchor\" href=\"#gemm-算法优化\">#</a> GEMM 算法优化</h2>\n<p>cuBLAS 中实现的通用的 GEMM 算法形式为 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>C</mi><mo>=</mo><mi>α</mi><mi>A</mi><mi>B</mi><mo>+</mo><mi>β</mi><mi>C</mi></mrow><annotation encoding=\"application/x-tex\">C=\\alpha AB+\\beta C</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.6833em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.07153em;\">C</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.7667em;vertical-align:-0.0833em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.0037em;\">α</span><span class=\"mord mathnormal\">A</span><span class=\"mord mathnormal\" style=\"margin-right:0.05017em;\">B</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span><span class=\"mbin\">+</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.8889em;vertical-align:-0.1944em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.07153em;\">βC</span></span></span></span>。其中 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>A</mi><mo separator=\"true\">,</mo><mi>B</mi><mo separator=\"true\">,</mo><mi>C</mi></mrow><annotation encoding=\"application/x-tex\">A,B,C</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8778em;vertical-align:-0.1944em;\"></span><span class=\"mord mathnormal\">A</span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.1667em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.05017em;\">B</span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.1667em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.07153em;\">C</span></span></span></span> 均为矩阵，shape 为 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>M</mi><mo>×</mo><mi>K</mi><mo separator=\"true\">,</mo><mi>K</mi><mo>×</mo><mi>N</mi><mo separator=\"true\">,</mo><mi>M</mi><mo>×</mo><mi>N</mi></mrow><annotation encoding=\"application/x-tex\">M\\times K,K\\times N,M \\times N</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.7667em;vertical-align:-0.0833em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.10903em;\">M</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span><span class=\"mbin\">×</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.8778em;vertical-align:-0.1944em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.07153em;\">K</span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.1667em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.07153em;\">K</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span><span class=\"mbin\">×</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.8778em;vertical-align:-0.1944em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.10903em;\">N</span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.1667em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.10903em;\">M</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span><span class=\"mbin\">×</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.6833em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.10903em;\">N</span></span></span></span>，<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>α</mi></mrow><annotation encoding=\"application/x-tex\">\\alpha</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.4306em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.0037em;\">α</span></span></span></span> 和 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>β</mi></mrow><annotation encoding=\"application/x-tex\">\\beta</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8889em;vertical-align:-0.1944em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.05278em;\">β</span></span></span></span> 为标量。</p>\n<p>最简单的实现是 CPU 的串行算法。如果我们对于某个算法在 GPU 中的实现感到难以下手，那么我们可以先从 CPU 算法开始。</p>\n<figure class=\"highlight cpp\"><figcaption data-lang=\"C++\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre><span class=\"token macro property\"><span class=\"token directive-hash\">#</span><span class=\"token directive keyword\">define</span> <span class=\"token macro-name function\">OFFSET</span><span class=\"token expression\"><span class=\"token punctuation\">(</span>row<span class=\"token punctuation\">,</span> col<span class=\"token punctuation\">,</span> stride<span class=\"token punctuation\">)</span> <span class=\"token punctuation\">(</span><span class=\"token punctuation\">(</span>row<span class=\"token punctuation\">)</span> <span class=\"token operator\">*</span> <span class=\"token punctuation\">(</span>stride<span class=\"token punctuation\">)</span> <span class=\"token operator\">+</span> <span class=\"token punctuation\">(</span>col<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span></span></span></pre></td></tr><tr><td data-num=\"2\"></td><td><pre><span class=\"token keyword\">void</span> <span class=\"token function\">cpu_naive_matmul</span><span class=\"token punctuation\">(</span><span class=\"token keyword\">int</span> M<span class=\"token punctuation\">,</span> <span class=\"token keyword\">int</span> N<span class=\"token punctuation\">,</span> <span class=\"token keyword\">int</span> K<span class=\"token punctuation\">,</span> <span class=\"token keyword\">float</span> alpha<span class=\"token punctuation\">,</span> <span class=\"token keyword\">float</span> <span class=\"token operator\">*</span>A<span class=\"token punctuation\">,</span> <span class=\"token keyword\">float</span> <span class=\"token operator\">*</span>B<span class=\"token punctuation\">,</span> <span class=\"token keyword\">float</span> beta<span class=\"token punctuation\">,</span> <span class=\"token keyword\">float</span> <span class=\"token operator\">*</span>C<span class=\"token punctuation\">)</span> <span class=\"token punctuation\">&#123;</span></pre></td></tr><tr><td data-num=\"3\"></td><td><pre>    <span class=\"token keyword\">for</span> <span class=\"token punctuation\">(</span><span class=\"token keyword\">int</span> m <span class=\"token operator\">=</span> <span class=\"token number\">0</span><span class=\"token punctuation\">;</span> m <span class=\"token operator\">&lt;</span> M<span class=\"token punctuation\">;</span> <span class=\"token operator\">++</span>m<span class=\"token punctuation\">)</span> <span class=\"token punctuation\">&#123;</span></pre></td></tr><tr><td data-num=\"4\"></td><td><pre>        <span class=\"token keyword\">for</span> <span class=\"token punctuation\">(</span><span class=\"token keyword\">int</span> n <span class=\"token operator\">=</span> <span class=\"token number\">0</span><span class=\"token punctuation\">;</span> n <span class=\"token operator\">&lt;</span> N<span class=\"token punctuation\">;</span> <span class=\"token operator\">++</span>n<span class=\"token punctuation\">)</span> <span class=\"token punctuation\">&#123;</span></pre></td></tr><tr><td data-num=\"5\"></td><td><pre>            <span class=\"token keyword\">float</span> val <span class=\"token operator\">=</span> <span class=\"token number\">0.</span><span class=\"token punctuation\">;</span></pre></td></tr><tr><td data-num=\"6\"></td><td><pre>            <span class=\"token keyword\">for</span> <span class=\"token punctuation\">(</span><span class=\"token keyword\">int</span> k <span class=\"token operator\">=</span> <span class=\"token number\">0</span><span class=\"token punctuation\">;</span> k <span class=\"token operator\">&lt;</span> K<span class=\"token punctuation\">;</span> <span class=\"token operator\">++</span>k<span class=\"token punctuation\">)</span> <span class=\"token punctuation\">&#123;</span></pre></td></tr><tr><td data-num=\"7\"></td><td><pre>                val <span class=\"token operator\">+=</span> A<span class=\"token punctuation\">[</span><span class=\"token function\">OFFSET</span><span class=\"token punctuation\">(</span>m<span class=\"token punctuation\">,</span> k<span class=\"token punctuation\">,</span> K<span class=\"token punctuation\">)</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">*</span> B<span class=\"token punctuation\">[</span><span class=\"token function\">OFFSET</span><span class=\"token punctuation\">(</span>k<span class=\"token punctuation\">,</span> n<span class=\"token punctuation\">,</span> N<span class=\"token punctuation\">)</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">;</span></pre></td></tr><tr><td data-num=\"8\"></td><td><pre>            <span class=\"token punctuation\">&#125;</span></pre></td></tr><tr><td data-num=\"9\"></td><td><pre>            C<span class=\"token punctuation\">[</span><span class=\"token function\">OFFSET</span><span class=\"token punctuation\">(</span>m<span class=\"token punctuation\">,</span> n<span class=\"token punctuation\">,</span> N<span class=\"token punctuation\">)</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> alpha <span class=\"token operator\">*</span> val <span class=\"token operator\">+</span> beta <span class=\"token operator\">*</span> C<span class=\"token punctuation\">[</span><span class=\"token function\">OFFSET</span><span class=\"token punctuation\">(</span>m<span class=\"token punctuation\">,</span> n<span class=\"token punctuation\">,</span> N<span class=\"token punctuation\">)</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">;</span></pre></td></tr><tr><td data-num=\"10\"></td><td><pre>        <span class=\"token punctuation\">&#125;</span></pre></td></tr><tr><td data-num=\"11\"></td><td><pre>    <span class=\"token punctuation\">&#125;</span></pre></td></tr><tr><td data-num=\"12\"></td><td><pre><span class=\"token punctuation\">&#125;</span></pre></td></tr></table></figure><h3 id=\"naive-实现\"><a class=\"markdownIt-Anchor\" href=\"#naive-实现\">#</a> Naive 实现</h3>\n<p>本节介绍最简单的 CUDA SGEMM 实现，每个线程负责矩阵 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>C</mi></mrow><annotation encoding=\"application/x-tex\">C</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.6833em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.07153em;\">C</span></span></span></span> 中的一个元素的计算。</p>\n<p><img loading=\"lazy\" data-src=\"/images/cuda/SGEMM-optimization/naive-kernel.png\" alt=\"CUDA naive kernel 实现\"></p>\n<p>假定我们启动核函数时的 block 大小为 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>B</mi><mi>M</mi><mo>×</mo><mi>B</mi><mi>N</mi></mrow><annotation encoding=\"application/x-tex\">BM\\times BN</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.7667em;vertical-align:-0.0833em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.10903em;\">BM</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span><span class=\"mbin\">×</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.6833em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.10903em;\">BN</span></span></span></span>，那么我们可以计算每个线程对应的 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>C</mi></mrow><annotation encoding=\"application/x-tex\">C</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.6833em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.07153em;\">C</span></span></span></span> 中元素的下标：</p>\n<figure class=\"highlight c\"><figcaption data-lang=\"c\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre><span class=\"token keyword\">int</span> col <span class=\"token operator\">=</span> blockIdx<span class=\"token punctuation\">.</span>x <span class=\"token operator\">*</span> blockDim<span class=\"token punctuation\">.</span>x <span class=\"token operator\">+</span> threadIdx<span class=\"token punctuation\">.</span>x<span class=\"token punctuation\">;</span>  </pre></td></tr><tr><td data-num=\"2\"></td><td><pre><span class=\"token keyword\">int</span> row <span class=\"token operator\">=</span> blockIdx<span class=\"token punctuation\">.</span>y <span class=\"token operator\">*</span> blockDim<span class=\"token punctuation\">.</span>y <span class=\"token operator\">+</span> threadIdx<span class=\"token punctuation\">.</span>y<span class=\"token punctuation\">;</span></pre></td></tr></table></figure><p>我们在启动核函数时，一个 grid 中可能会包含多个 block，所以这里还要使用  <code>blockIdx.x</code> ， <code>blockIdx.y</code>  和  <code>blockDim.x</code>  和  <code>blockDim.y</code>  相乘获取每个 block 的基址，即每个 block 最左上方的元素对应的下标。然后再分别加上线程在 block 中的偏移  <code>threadIdx.x</code>  和  <code>threadIdx.y</code> 。</p>\n<p>后续的步骤就和 CPU 版本的代码相差无几了：</p>\n<figure class=\"highlight c\"><figcaption data-lang=\"c\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre><span class=\"token keyword\">if</span> <span class=\"token punctuation\">(</span>row <span class=\"token operator\">&lt;</span> M <span class=\"token operator\">&amp;&amp;</span> col <span class=\"token operator\">&lt;</span> N<span class=\"token punctuation\">)</span> <span class=\"token punctuation\">&#123;</span>  </pre></td></tr><tr><td data-num=\"2\"></td><td><pre>    <span class=\"token keyword\">float</span> val <span class=\"token operator\">=</span> <span class=\"token number\">0.</span><span class=\"token punctuation\">;</span>  </pre></td></tr><tr><td data-num=\"3\"></td><td><pre>    <span class=\"token keyword\">for</span> <span class=\"token punctuation\">(</span><span class=\"token keyword\">int</span> k <span class=\"token operator\">=</span> <span class=\"token number\">0</span><span class=\"token punctuation\">;</span> k <span class=\"token operator\">&lt;</span> K<span class=\"token punctuation\">;</span> <span class=\"token operator\">++</span>k<span class=\"token punctuation\">)</span> <span class=\"token punctuation\">&#123;</span>  </pre></td></tr><tr><td data-num=\"4\"></td><td><pre>        val <span class=\"token operator\">+=</span> A<span class=\"token punctuation\">[</span><span class=\"token function\">OFFSET</span><span class=\"token punctuation\">(</span>row<span class=\"token punctuation\">,</span> k<span class=\"token punctuation\">,</span> K<span class=\"token punctuation\">)</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">*</span> B<span class=\"token punctuation\">[</span><span class=\"token function\">OFFSET</span><span class=\"token punctuation\">(</span>k<span class=\"token punctuation\">,</span> col<span class=\"token punctuation\">,</span> N<span class=\"token punctuation\">)</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">;</span>  </pre></td></tr><tr><td data-num=\"5\"></td><td><pre>    <span class=\"token punctuation\">&#125;</span>  </pre></td></tr><tr><td data-num=\"6\"></td><td><pre>    C<span class=\"token punctuation\">[</span><span class=\"token function\">OFFSET</span><span class=\"token punctuation\">(</span>row<span class=\"token punctuation\">,</span> col<span class=\"token punctuation\">,</span> N<span class=\"token punctuation\">)</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> alpha <span class=\"token operator\">*</span> val <span class=\"token operator\">+</span> beta <span class=\"token operator\">*</span> C<span class=\"token punctuation\">[</span><span class=\"token function\">OFFSET</span><span class=\"token punctuation\">(</span>row<span class=\"token punctuation\">,</span> col<span class=\"token punctuation\">,</span> N<span class=\"token punctuation\">)</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">;</span>  </pre></td></tr><tr><td data-num=\"7\"></td><td><pre><span class=\"token punctuation\">&#125;</span></pre></td></tr></table></figure><p>这里加上了  <code>if (row &lt; M &amp;&amp; col &lt; N)</code>  判断以防越界，因为有时候<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>M</mi></mrow><annotation encoding=\"application/x-tex\">M</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.6833em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.10903em;\">M</span></span></span></span> 无法被 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>B</mi><mi>M</mi></mrow><annotation encoding=\"application/x-tex\">BM</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.6833em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.10903em;\">BM</span></span></span></span>，或者 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>N</mi></mrow><annotation encoding=\"application/x-tex\">N</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.6833em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.10903em;\">N</span></span></span></span> 无法被 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>B</mi><mi>N</mi></mrow><annotation encoding=\"application/x-tex\">BN</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.6833em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.10903em;\">BN</span></span></span></span> 整除。</p>\n<p>完整代码如下：</p>\n<figure class=\"highlight c\"><figcaption data-lang=\"c\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre><span class=\"token macro property\"><span class=\"token directive-hash\">#</span><span class=\"token directive keyword\">define</span> <span class=\"token macro-name function\">OFFSET</span><span class=\"token expression\"><span class=\"token punctuation\">(</span>row<span class=\"token punctuation\">,</span> col<span class=\"token punctuation\">,</span> stride<span class=\"token punctuation\">)</span> <span class=\"token punctuation\">(</span><span class=\"token punctuation\">(</span>row<span class=\"token punctuation\">)</span> <span class=\"token operator\">*</span> <span class=\"token punctuation\">(</span>stride<span class=\"token punctuation\">)</span> <span class=\"token operator\">+</span> <span class=\"token punctuation\">(</span>col<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>  </span></span></pre></td></tr><tr><td data-num=\"2\"></td><td><pre>__global__ <span class=\"token keyword\">void</span> <span class=\"token function\">naive_kernel</span><span class=\"token punctuation\">(</span><span class=\"token keyword\">int</span> M<span class=\"token punctuation\">,</span> <span class=\"token keyword\">int</span> N<span class=\"token punctuation\">,</span> <span class=\"token keyword\">int</span> K<span class=\"token punctuation\">,</span> </pre></td></tr><tr><td data-num=\"3\"></td><td><pre>                             <span class=\"token keyword\">float</span> alpha<span class=\"token punctuation\">,</span> <span class=\"token keyword\">float</span> <span class=\"token operator\">*</span>A<span class=\"token punctuation\">,</span> <span class=\"token keyword\">float</span> <span class=\"token operator\">*</span>B<span class=\"token punctuation\">,</span> <span class=\"token keyword\">float</span> beta<span class=\"token punctuation\">,</span> <span class=\"token keyword\">float</span> <span class=\"token operator\">*</span>C<span class=\"token punctuation\">)</span> <span class=\"token punctuation\">&#123;</span>  </pre></td></tr><tr><td data-num=\"4\"></td><td><pre>    <span class=\"token keyword\">int</span> col <span class=\"token operator\">=</span> blockIdx<span class=\"token punctuation\">.</span>x <span class=\"token operator\">*</span> blockDim<span class=\"token punctuation\">.</span>x <span class=\"token operator\">+</span> threadIdx<span class=\"token punctuation\">.</span>x<span class=\"token punctuation\">;</span>  </pre></td></tr><tr><td data-num=\"5\"></td><td><pre>    <span class=\"token keyword\">int</span> row <span class=\"token operator\">=</span> blockIdx<span class=\"token punctuation\">.</span>y <span class=\"token operator\">*</span> blockDim<span class=\"token punctuation\">.</span>y <span class=\"token operator\">+</span> threadIdx<span class=\"token punctuation\">.</span>y<span class=\"token punctuation\">;</span>  </pre></td></tr><tr><td data-num=\"6\"></td><td><pre>    <span class=\"token keyword\">if</span> <span class=\"token punctuation\">(</span>row <span class=\"token operator\">&lt;</span> M <span class=\"token operator\">&amp;&amp;</span> col <span class=\"token operator\">&lt;</span> N<span class=\"token punctuation\">)</span> <span class=\"token punctuation\">&#123;</span>  </pre></td></tr><tr><td data-num=\"7\"></td><td><pre>        <span class=\"token keyword\">float</span> val <span class=\"token operator\">=</span> <span class=\"token number\">0.</span><span class=\"token punctuation\">;</span>  </pre></td></tr><tr><td data-num=\"8\"></td><td><pre>        <span class=\"token keyword\">for</span> <span class=\"token punctuation\">(</span><span class=\"token keyword\">int</span> k <span class=\"token operator\">=</span> <span class=\"token number\">0</span><span class=\"token punctuation\">;</span> k <span class=\"token operator\">&lt;</span> K<span class=\"token punctuation\">;</span> <span class=\"token operator\">++</span>k<span class=\"token punctuation\">)</span> <span class=\"token punctuation\">&#123;</span>  </pre></td></tr><tr><td data-num=\"9\"></td><td><pre>            val <span class=\"token operator\">+=</span> A<span class=\"token punctuation\">[</span><span class=\"token function\">OFFSET</span><span class=\"token punctuation\">(</span>row<span class=\"token punctuation\">,</span> k<span class=\"token punctuation\">,</span> K<span class=\"token punctuation\">)</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">*</span> B<span class=\"token punctuation\">[</span><span class=\"token function\">OFFSET</span><span class=\"token punctuation\">(</span>k<span class=\"token punctuation\">,</span> col<span class=\"token punctuation\">,</span> N<span class=\"token punctuation\">)</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">;</span>  </pre></td></tr><tr><td data-num=\"10\"></td><td><pre>        <span class=\"token punctuation\">&#125;</span>  </pre></td></tr><tr><td data-num=\"11\"></td><td><pre>        C<span class=\"token punctuation\">[</span><span class=\"token function\">OFFSET</span><span class=\"token punctuation\">(</span>row<span class=\"token punctuation\">,</span> col<span class=\"token punctuation\">,</span> N<span class=\"token punctuation\">)</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> alpha <span class=\"token operator\">*</span> val <span class=\"token operator\">+</span> beta <span class=\"token operator\">*</span> C<span class=\"token punctuation\">[</span><span class=\"token function\">OFFSET</span><span class=\"token punctuation\">(</span>row<span class=\"token punctuation\">,</span> col<span class=\"token punctuation\">,</span> N<span class=\"token punctuation\">)</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">;</span>  </pre></td></tr><tr><td data-num=\"12\"></td><td><pre>    <span class=\"token punctuation\">&#125;</span>  </pre></td></tr><tr><td data-num=\"13\"></td><td><pre><span class=\"token punctuation\">&#125;</span></pre></td></tr></table></figure><p>性能比较如下：</p>\n<p><img loading=\"lazy\" data-src=\"/images/cuda/SGEMM-optimization/kernel-performance/kernel-naive.png\" alt=\"naive kernel\"></p>\n<p>可以看到，朴素实现的性能基本都在 1000 GFLOPS 左右，只有 cuBLAS 库性能的十分之一。</p>\n<p>我们可以做一个简单的计算。对于矩阵 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>C</mi></mrow><annotation encoding=\"application/x-tex\">C</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.6833em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.07153em;\">C</span></span></span></span> 中的每个元素，我们需要访问 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>A</mi></mrow><annotation encoding=\"application/x-tex\">A</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.6833em;\"></span><span class=\"mord mathnormal\">A</span></span></span></span> 和 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>B</mi></mrow><annotation encoding=\"application/x-tex\">B</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.6833em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.05017em;\">B</span></span></span></span> 中各 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>K</mi></mrow><annotation encoding=\"application/x-tex\">K</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.6833em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.07153em;\">K</span></span></span></span> 个元素，总共 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mn>2</mn><mi>K</mi></mrow><annotation encoding=\"application/x-tex\">2K</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.6833em;\"></span><span class=\"mord\">2</span><span class=\"mord mathnormal\" style=\"margin-right:0.07153em;\">K</span></span></span></span> 次全局内存访问。同时，循环中进行了 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>K</mi></mrow><annotation encoding=\"application/x-tex\">K</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.6833em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.07153em;\">K</span></span></span></span> 次乘法和加法共 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mn>2</mn><mi>K</mi></mrow><annotation encoding=\"application/x-tex\">2K</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.6833em;\"></span><span class=\"mord\">2</span><span class=\"mord mathnormal\" style=\"margin-right:0.07153em;\">K</span></span></span></span> 次运算。计算下来，平均每一次计算就需要一次访存。考虑到 global memory 的访存延迟，这样的做法显然是非常没有效率的。</p>\n<p>通过 Nsight Compute 工具也可以看到， <code>warp</code>  花费了大量时间等待全局内存的读写：</p>\n<p><img loading=\"lazy\" data-src=\"/images/cuda/SGEMM-optimization/naive-kernel-warp-state.png\" alt=\"naive kernel warp state\"></p>\n<p>切换到代码页面也能看到具体是哪些代码导致了这些 stall。可以发现，我们的核心计算语句耗费了大量时间等待访存读写，这也是我们可以优化的着手点。</p>\n<p><img loading=\"lazy\" data-src=\"/images/cuda/SGEMM-optimization/naive-kernel-hotspot-code.png\" alt=\"naive kernel hotspot code\"></p>\n<h3 id=\"使用-shared-memory-优化访存\"><a class=\"markdownIt-Anchor\" href=\"#使用-shared-memory-优化访存\">#</a> 使用 Shared Memory 优化访存</h3>\n<p>朴素实现中对输入的访问全部都是直接对全局内存进行操作。前文中我们提到，全局内存的访存速度是最慢的，这限制了核函数的计算效率，每个线程耗费了大量的时间等待访存。我们可以尝试使用共享内存来缓存一部分的输入。</p>\n<p>可以发现，对于 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>C</mi></mrow><annotation encoding=\"application/x-tex\">C</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.6833em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.07153em;\">C</span></span></span></span> 中的每一行元素，在计算过程中都需要访问 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>A</mi></mrow><annotation encoding=\"application/x-tex\">A</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.6833em;\"></span><span class=\"mord mathnormal\">A</span></span></span></span> 矩阵中的同一行元素；对于 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>C</mi></mrow><annotation encoding=\"application/x-tex\">C</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.6833em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.07153em;\">C</span></span></span></span> 中每一列元素，在计算过程中需要访问 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>B</mi></mrow><annotation encoding=\"application/x-tex\">B</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.6833em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.05017em;\">B</span></span></span></span> 矩阵中的同一列元素。那么，对于一个 block 中需要计算的 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>B</mi><mi>M</mi><mo>×</mo><mi>B</mi><mi>N</mi></mrow><annotation encoding=\"application/x-tex\">BM \\times BN</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.7667em;vertical-align:-0.0833em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.10903em;\">BM</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span><span class=\"mbin\">×</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.6833em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.10903em;\">BN</span></span></span></span> 元素，有许多对相同地址的重复访问。因此，我们可以使用共享内存预先读取全局内存中所需要的元素，然后计算时直接读取共享内存，节省访存时的等待时间。</p>\n<p><img loading=\"lazy\" data-src=\"/images/cuda/SGEMM-optimization/shared-memory-kernel.png\" alt=\"CUDA 使用 shared memory 的实现\"></p>\n<p>我们开辟两块 shared memory 中的空间，分别用于存储从 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>A</mi></mrow><annotation encoding=\"application/x-tex\">A</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.6833em;\"></span><span class=\"mord mathnormal\">A</span></span></span></span> 和 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>B</mi></mrow><annotation encoding=\"application/x-tex\">B</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.6833em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.05017em;\">B</span></span></span></span> 中读取的元素：</p>\n<figure class=\"highlight c\"><figcaption data-lang=\"c\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre>__shared__ <span class=\"token keyword\">float</span> As<span class=\"token punctuation\">[</span>BM<span class=\"token punctuation\">]</span><span class=\"token punctuation\">[</span>BK<span class=\"token punctuation\">]</span><span class=\"token punctuation\">;</span>  </pre></td></tr><tr><td data-num=\"2\"></td><td><pre>__shared__ <span class=\"token keyword\">float</span> Bs<span class=\"token punctuation\">[</span>BK<span class=\"token punctuation\">]</span><span class=\"token punctuation\">[</span>BN<span class=\"token punctuation\">]</span><span class=\"token punctuation\">;</span></pre></td></tr></table></figure><p>计算时，我们每次需要读取每行或者每列中的 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>B</mi><mi>K</mi></mrow><annotation encoding=\"application/x-tex\">BK</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.6833em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.05017em;\">B</span><span class=\"mord mathnormal\" style=\"margin-right:0.07153em;\">K</span></span></span></span> 个元素，那么需要迭代 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>K</mi><mi mathvariant=\"normal\">/</mi><mi>B</mi><mi>K</mi></mrow><annotation encoding=\"application/x-tex\">K/BK</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.07153em;\">K</span><span class=\"mord\">/</span><span class=\"mord mathnormal\" style=\"margin-right:0.05017em;\">B</span><span class=\"mord mathnormal\" style=\"margin-right:0.07153em;\">K</span></span></span></span> 次，每次读取 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>A</mi></mrow><annotation encoding=\"application/x-tex\">A</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.6833em;\"></span><span class=\"mord mathnormal\">A</span></span></span></span> 和 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>B</mi></mrow><annotation encoding=\"application/x-tex\">B</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.6833em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.05017em;\">B</span></span></span></span> 中的一块区域的元素。然后对读取的元素，每个线程使用其所需的元素进行计算。</p>\n<figure class=\"highlight c\"><figcaption data-lang=\"c\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre><span class=\"token keyword\">float</span> val <span class=\"token operator\">=</span> <span class=\"token number\">0.</span><span class=\"token punctuation\">;</span>  </pre></td></tr><tr><td data-num=\"2\"></td><td><pre><span class=\"token keyword\">int</span> num_shared_block <span class=\"token operator\">=</span> <span class=\"token function\">CEIL_DIV</span><span class=\"token punctuation\">(</span>K<span class=\"token punctuation\">,</span> BK<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span> </pre></td></tr><tr><td data-num=\"3\"></td><td><pre>A <span class=\"token operator\">=</span> <span class=\"token operator\">&amp;</span>A<span class=\"token punctuation\">[</span><span class=\"token function\">OFFSET</span><span class=\"token punctuation\">(</span>blockIdx<span class=\"token punctuation\">.</span>y <span class=\"token operator\">*</span> BM<span class=\"token punctuation\">,</span> <span class=\"token number\">0</span><span class=\"token punctuation\">,</span> K<span class=\"token punctuation\">)</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">;</span> <span class=\"token comment\">// Relative position </span></pre></td></tr><tr><td data-num=\"4\"></td><td><pre>B <span class=\"token operator\">=</span> <span class=\"token operator\">&amp;</span>B<span class=\"token punctuation\">[</span><span class=\"token function\">OFFSET</span><span class=\"token punctuation\">(</span><span class=\"token number\">0</span><span class=\"token punctuation\">,</span> blockIdx<span class=\"token punctuation\">.</span>x <span class=\"token operator\">*</span> BN<span class=\"token punctuation\">,</span> N<span class=\"token punctuation\">)</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">;</span> <span class=\"token comment\">// Relative position</span></pre></td></tr><tr><td data-num=\"5\"></td><td><pre>C <span class=\"token operator\">=</span> <span class=\"token operator\">&amp;</span>C<span class=\"token punctuation\">[</span><span class=\"token function\">OFFSET</span><span class=\"token punctuation\">(</span>blockIdx<span class=\"token punctuation\">.</span>y <span class=\"token operator\">*</span> BM<span class=\"token punctuation\">,</span> blockIdx<span class=\"token punctuation\">.</span>x <span class=\"token operator\">*</span> BN<span class=\"token punctuation\">,</span> N<span class=\"token punctuation\">)</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">;</span> <span class=\"token comment\">// Relative position</span></pre></td></tr><tr><td data-num=\"6\"></td><td><pre>  </pre></td></tr><tr><td data-num=\"7\"></td><td><pre><span class=\"token keyword\">for</span> <span class=\"token punctuation\">(</span><span class=\"token keyword\">int</span> i <span class=\"token operator\">=</span> <span class=\"token number\">0</span><span class=\"token punctuation\">;</span> i <span class=\"token operator\">&lt;</span> num_shared_block<span class=\"token punctuation\">;</span> <span class=\"token operator\">++</span>i<span class=\"token punctuation\">)</span> <span class=\"token punctuation\">&#123;</span>  </pre></td></tr><tr><td data-num=\"8\"></td><td><pre>    <span class=\"token comment\">// Copy data from global memory to shared memory  </span></pre></td></tr><tr><td data-num=\"9\"></td><td><pre>    <span class=\"token keyword\">int</span> A_row <span class=\"token operator\">=</span> threadIdx<span class=\"token punctuation\">.</span>y<span class=\"token punctuation\">;</span>  </pre></td></tr><tr><td data-num=\"10\"></td><td><pre>    <span class=\"token keyword\">int</span> A_col <span class=\"token operator\">=</span> threadIdx<span class=\"token punctuation\">.</span>x<span class=\"token punctuation\">;</span>  </pre></td></tr><tr><td data-num=\"11\"></td><td><pre>    <span class=\"token keyword\">if</span> <span class=\"token punctuation\">(</span><span class=\"token punctuation\">(</span>blockIdx<span class=\"token punctuation\">.</span>y <span class=\"token operator\">*</span> BM <span class=\"token operator\">+</span> A_row<span class=\"token punctuation\">)</span> <span class=\"token operator\">&lt;</span> M <span class=\"token operator\">&amp;&amp;</span> <span class=\"token punctuation\">(</span>i <span class=\"token operator\">*</span> BK <span class=\"token operator\">+</span> A_col<span class=\"token punctuation\">)</span> <span class=\"token operator\">&lt;</span> K<span class=\"token punctuation\">)</span> <span class=\"token punctuation\">&#123;</span>  </pre></td></tr><tr><td data-num=\"12\"></td><td><pre>        As<span class=\"token punctuation\">[</span>threadIdx<span class=\"token punctuation\">.</span>y<span class=\"token punctuation\">]</span><span class=\"token punctuation\">[</span>threadIdx<span class=\"token punctuation\">.</span>x<span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> A<span class=\"token punctuation\">[</span><span class=\"token function\">OFFSET</span><span class=\"token punctuation\">(</span>A_row<span class=\"token punctuation\">,</span> A_col<span class=\"token punctuation\">,</span> K<span class=\"token punctuation\">)</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">;</span>  </pre></td></tr><tr><td data-num=\"13\"></td><td><pre>    <span class=\"token punctuation\">&#125;</span> <span class=\"token keyword\">else</span> <span class=\"token punctuation\">&#123;</span>  </pre></td></tr><tr><td data-num=\"14\"></td><td><pre>        As<span class=\"token punctuation\">[</span>threadIdx<span class=\"token punctuation\">.</span>y<span class=\"token punctuation\">]</span><span class=\"token punctuation\">[</span>threadIdx<span class=\"token punctuation\">.</span>x<span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> <span class=\"token number\">0.</span><span class=\"token punctuation\">;</span>  </pre></td></tr><tr><td data-num=\"15\"></td><td><pre>    <span class=\"token punctuation\">&#125;</span>  </pre></td></tr><tr><td data-num=\"16\"></td><td><pre>    <span class=\"token keyword\">int</span> B_row <span class=\"token operator\">=</span> threadIdx<span class=\"token punctuation\">.</span>y<span class=\"token punctuation\">;</span>  </pre></td></tr><tr><td data-num=\"17\"></td><td><pre>    <span class=\"token keyword\">int</span> B_col <span class=\"token operator\">=</span> threadIdx<span class=\"token punctuation\">.</span>x<span class=\"token punctuation\">;</span>  </pre></td></tr><tr><td data-num=\"18\"></td><td><pre>    <span class=\"token keyword\">if</span> <span class=\"token punctuation\">(</span><span class=\"token punctuation\">(</span>i <span class=\"token operator\">*</span> BK <span class=\"token operator\">+</span> B_row<span class=\"token punctuation\">)</span> <span class=\"token operator\">&lt;</span> K <span class=\"token operator\">&amp;&amp;</span> <span class=\"token punctuation\">(</span>blockIdx<span class=\"token punctuation\">.</span>x <span class=\"token operator\">*</span> BN <span class=\"token operator\">+</span> B_col<span class=\"token punctuation\">)</span> <span class=\"token operator\">&lt;</span> N<span class=\"token punctuation\">)</span> <span class=\"token punctuation\">&#123;</span>  </pre></td></tr><tr><td data-num=\"19\"></td><td><pre>        Bs<span class=\"token punctuation\">[</span>threadIdx<span class=\"token punctuation\">.</span>y<span class=\"token punctuation\">]</span><span class=\"token punctuation\">[</span>threadIdx<span class=\"token punctuation\">.</span>x<span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> B<span class=\"token punctuation\">[</span><span class=\"token function\">OFFSET</span><span class=\"token punctuation\">(</span>B_row<span class=\"token punctuation\">,</span> B_col<span class=\"token punctuation\">,</span> N<span class=\"token punctuation\">)</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">;</span>  </pre></td></tr><tr><td data-num=\"20\"></td><td><pre>    <span class=\"token punctuation\">&#125;</span> <span class=\"token keyword\">else</span> <span class=\"token punctuation\">&#123;</span>  </pre></td></tr><tr><td data-num=\"21\"></td><td><pre>        Bs<span class=\"token punctuation\">[</span>threadIdx<span class=\"token punctuation\">.</span>y<span class=\"token punctuation\">]</span><span class=\"token punctuation\">[</span>threadIdx<span class=\"token punctuation\">.</span>x<span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> <span class=\"token number\">0.</span><span class=\"token punctuation\">;</span>  </pre></td></tr><tr><td data-num=\"22\"></td><td><pre>    <span class=\"token punctuation\">&#125;</span>  </pre></td></tr><tr><td data-num=\"23\"></td><td><pre>    <span class=\"token function\">__syncthreads</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>  </pre></td></tr><tr><td data-num=\"24\"></td><td><pre>    A <span class=\"token operator\">+=</span> BK<span class=\"token punctuation\">;</span>  <span class=\"token comment\">// Add offset</span></pre></td></tr><tr><td data-num=\"25\"></td><td><pre>    B <span class=\"token operator\">+=</span> BK <span class=\"token operator\">*</span> N<span class=\"token punctuation\">;</span>  <span class=\"token comment\">// Add offset</span></pre></td></tr><tr><td data-num=\"26\"></td><td><pre>    <span class=\"token keyword\">for</span> <span class=\"token punctuation\">(</span><span class=\"token keyword\">int</span> k <span class=\"token operator\">=</span> <span class=\"token number\">0</span><span class=\"token punctuation\">;</span> k <span class=\"token operator\">&lt;</span> BK<span class=\"token punctuation\">;</span> <span class=\"token operator\">++</span>k<span class=\"token punctuation\">)</span> <span class=\"token punctuation\">&#123;</span>  </pre></td></tr><tr><td data-num=\"27\"></td><td><pre>        val <span class=\"token operator\">+=</span> As<span class=\"token punctuation\">[</span>threadIdx<span class=\"token punctuation\">.</span>y<span class=\"token punctuation\">]</span><span class=\"token punctuation\">[</span>k<span class=\"token punctuation\">]</span> <span class=\"token operator\">*</span> Bs<span class=\"token punctuation\">[</span>k<span class=\"token punctuation\">]</span><span class=\"token punctuation\">[</span>threadIdx<span class=\"token punctuation\">.</span>x<span class=\"token punctuation\">]</span><span class=\"token punctuation\">;</span>  </pre></td></tr><tr><td data-num=\"28\"></td><td><pre>    <span class=\"token punctuation\">&#125;</span>  </pre></td></tr><tr><td data-num=\"29\"></td><td><pre>    <span class=\"token function\">__syncthreads</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>  </pre></td></tr><tr><td data-num=\"30\"></td><td><pre><span class=\"token punctuation\">&#125;</span></pre></td></tr></table></figure><p>注意上述代码中，我们为三个矩阵的指针添加了偏移量，后续计算坐标时，只需要计算其在子矩阵中的相对位置即可。不过也要注意，在判断是否越界时，需要转换为全局的下标，否则会判断错误。</p>\n<p>每次迭代中，我们只计算了 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>C</mi></mrow><annotation encoding=\"application/x-tex\">C</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.6833em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.07153em;\">C</span></span></span></span> 中对应元素值的一部分，待到迭代完毕，便得到了最终的结果。注意迭代过程中，使用了  <code>__syncthreads()</code>  来同步每个线程，防止数据读取不同步，造成读取的数据错误。</p>\n<p>最后，将计算结果写回：</p>\n<figure class=\"highlight c\"><figcaption data-lang=\"c\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre><span class=\"token keyword\">int</span> C_row <span class=\"token operator\">=</span> threadIdx<span class=\"token punctuation\">.</span>y<span class=\"token punctuation\">;</span>  </pre></td></tr><tr><td data-num=\"2\"></td><td><pre><span class=\"token keyword\">int</span> C_col <span class=\"token operator\">=</span> threadIdx<span class=\"token punctuation\">.</span>x<span class=\"token punctuation\">;</span>  </pre></td></tr><tr><td data-num=\"3\"></td><td><pre><span class=\"token keyword\">if</span> <span class=\"token punctuation\">(</span><span class=\"token punctuation\">(</span>blockIdx<span class=\"token punctuation\">.</span>y <span class=\"token operator\">*</span> BM <span class=\"token operator\">+</span> C_row<span class=\"token punctuation\">)</span> <span class=\"token operator\">&lt;</span> M <span class=\"token operator\">&amp;&amp;</span> <span class=\"token punctuation\">(</span>blockIdx<span class=\"token punctuation\">.</span>x <span class=\"token operator\">*</span> BN <span class=\"token operator\">+</span> C_col<span class=\"token punctuation\">)</span> <span class=\"token operator\">&lt;</span> N<span class=\"token punctuation\">)</span> <span class=\"token punctuation\">&#123;</span>  </pre></td></tr><tr><td data-num=\"4\"></td><td><pre>    C<span class=\"token punctuation\">[</span><span class=\"token function\">OFFSET</span><span class=\"token punctuation\">(</span>C_row<span class=\"token punctuation\">,</span> C_col<span class=\"token punctuation\">,</span> N<span class=\"token punctuation\">)</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> alpha <span class=\"token operator\">*</span> val <span class=\"token operator\">+</span> beta <span class=\"token operator\">*</span> C<span class=\"token punctuation\">[</span><span class=\"token function\">OFFSET</span><span class=\"token punctuation\">(</span>C_row<span class=\"token punctuation\">,</span> C_col<span class=\"token punctuation\">,</span> N<span class=\"token punctuation\">)</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">;</span>  </pre></td></tr><tr><td data-num=\"5\"></td><td><pre><span class=\"token punctuation\">&#125;</span></pre></td></tr></table></figure><p><img loading=\"lazy\" data-src=\"/images/cuda/SGEMM-optimization/kernel-performance/kernel-sm.png\" alt=\"shared memory kernel\"></p>\n<p>emmm，理论上而言，每个 block 需要从全局内存中读取 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mfrac><mi>K</mi><mrow><mi>B</mi><mi>K</mi></mrow></mfrac><mo>×</mo><mo stretchy=\"false\">(</mo><mi>B</mi><mi>M</mi><mo>×</mo><mi>B</mi><mi>K</mi><mo>+</mo><mi>B</mi><mi>K</mi><mo>×</mo><mi>B</mi><mi>N</mi><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">\\frac{K}{BK}\\times(BM\\times BK + BK\\times BN)</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1.2173em;vertical-align:-0.345em;\"></span><span class=\"mord\"><span class=\"mopen nulldelimiter\"></span><span class=\"mfrac\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8723em;\"><span style=\"top:-2.655em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.05017em;\">B</span><span class=\"mord mathnormal mtight\" style=\"margin-right:0.07153em;\">K</span></span></span></span><span style=\"top:-3.23em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"frac-line\" style=\"border-bottom-width:0.04em;\"></span></span><span style=\"top:-3.394em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.07153em;\">K</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.345em;\"><span></span></span></span></span></span><span class=\"mclose nulldelimiter\"></span></span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span><span class=\"mbin\">×</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mopen\">(</span><span class=\"mord mathnormal\" style=\"margin-right:0.10903em;\">BM</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span><span class=\"mbin\">×</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.7667em;vertical-align:-0.0833em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.05017em;\">B</span><span class=\"mord mathnormal\" style=\"margin-right:0.07153em;\">K</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span><span class=\"mbin\">+</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.7667em;vertical-align:-0.0833em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.05017em;\">B</span><span class=\"mord mathnormal\" style=\"margin-right:0.07153em;\">K</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span><span class=\"mbin\">×</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.10903em;\">BN</span><span class=\"mclose\">)</span></span></span></span> 个浮点数。而朴素算法中，一个 block 总共需要 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mn>2</mn><mi>K</mi><mo>×</mo><mi>B</mi><mi>M</mi><mo>×</mo><mi>B</mi><mi>N</mi></mrow><annotation encoding=\"application/x-tex\">2K\\times BM \\times BN</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.7667em;vertical-align:-0.0833em;\"></span><span class=\"mord\">2</span><span class=\"mord mathnormal\" style=\"margin-right:0.07153em;\">K</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span><span class=\"mbin\">×</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.7667em;vertical-align:-0.0833em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.10903em;\">BM</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span><span class=\"mbin\">×</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.6833em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.10903em;\">BN</span></span></span></span> 次访存。可以看到，使用了一维 Tile 方法之后，访存降为了原来的 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mfrac><mn>1</mn><mn>2</mn></mfrac><mo stretchy=\"false\">(</mo><mfrac><mn>1</mn><mrow><mi>B</mi><mi>N</mi></mrow></mfrac><mo>+</mo><mfrac><mn>1</mn><mrow><mi>B</mi><mi>M</mi></mrow></mfrac><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">\\frac{1}{2}(\\frac{1}{BN}+\\frac{1}{BM})</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1.1901em;vertical-align:-0.345em;\"></span><span class=\"mord\"><span class=\"mopen nulldelimiter\"></span><span class=\"mfrac\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8451em;\"><span style=\"top:-2.655em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\">2</span></span></span></span><span style=\"top:-3.23em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"frac-line\" style=\"border-bottom-width:0.04em;\"></span></span><span style=\"top:-3.394em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\">1</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.345em;\"><span></span></span></span></span></span><span class=\"mclose nulldelimiter\"></span></span><span class=\"mopen\">(</span><span class=\"mord\"><span class=\"mopen nulldelimiter\"></span><span class=\"mfrac\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8451em;\"><span style=\"top:-2.655em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.10903em;\">BN</span></span></span></span><span style=\"top:-3.23em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"frac-line\" style=\"border-bottom-width:0.04em;\"></span></span><span style=\"top:-3.394em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\">1</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.345em;\"><span></span></span></span></span></span><span class=\"mclose nulldelimiter\"></span></span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span><span class=\"mbin\">+</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1.1901em;vertical-align:-0.345em;\"></span><span class=\"mord\"><span class=\"mopen nulldelimiter\"></span><span class=\"mfrac\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8451em;\"><span style=\"top:-2.655em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.10903em;\">BM</span></span></span></span><span style=\"top:-3.23em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"frac-line\" style=\"border-bottom-width:0.04em;\"></span></span><span style=\"top:-3.394em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\">1</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.345em;\"><span></span></span></span></span></span><span class=\"mclose nulldelimiter\"></span></span><span class=\"mclose\">)</span></span></span></span>。一般有 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>B</mi><mi>M</mi><mo>=</mo><mi>B</mi><mi>N</mi></mrow><annotation encoding=\"application/x-tex\">BM=BN</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.6833em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.10903em;\">BM</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.6833em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.10903em;\">BN</span></span></span></span>，因此，全局内存访问将为了原来的 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mfrac><mn>1</mn><mrow><mi>B</mi><mi>M</mi></mrow></mfrac></mrow><annotation encoding=\"application/x-tex\">\\frac{1}{BM}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1.1901em;vertical-align:-0.345em;\"></span><span class=\"mord\"><span class=\"mopen nulldelimiter\"></span><span class=\"mfrac\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8451em;\"><span style=\"top:-2.655em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.10903em;\">BM</span></span></span></span><span style=\"top:-3.23em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"frac-line\" style=\"border-bottom-width:0.04em;\"></span></span><span style=\"top:-3.394em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\">1</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.345em;\"><span></span></span></span></span></span><span class=\"mclose nulldelimiter\"></span></span></span></span></span>。而每个线程的计算量不变，则计算访存比也降低为原来的 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mfrac><mn>1</mn><mrow><mi>B</mi><mi>N</mi></mrow></mfrac></mrow><annotation encoding=\"application/x-tex\">\\frac{1}{BN}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1.1901em;vertical-align:-0.345em;\"></span><span class=\"mord\"><span class=\"mopen nulldelimiter\"></span><span class=\"mfrac\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8451em;\"><span style=\"top:-2.655em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.10903em;\">BN</span></span></span></span><span style=\"top:-3.23em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"frac-line\" style=\"border-bottom-width:0.04em;\"></span></span><span style=\"top:-3.394em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\">1</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.345em;\"><span></span></span></span></span></span><span class=\"mclose nulldelimiter\"></span></span></span></span></span>。不过从我测试的结果来看，和 naive 的结果比较并没有明显的区别，甚至还变差了一丢丢。</p>\n<p><img loading=\"lazy\" data-src=\"/images/cuda/SGEMM-optimization/shared-memory-kernel-warp-state.png\" alt=\"shared memory kernel warp state\"></p>\n<p>可以看到，这次是  <code>Stall MIO Throttle</code>  这一项的 stall cycles 最多。这一项根据文档说明，一般是某些特殊的数学计算函数、动态分支、共享内存读写导致的，放在我们的上下文中，那就可以肯定是共享内存导致的瓶颈，在横轴上几乎和使用全局内存的代码一致，数值也很接近。这也是为什么这段代码和直接使用全局代码的性能几乎没有变化。</p>\n<h3 id=\"一维-tile\"><a class=\"markdownIt-Anchor\" href=\"#一维-tile\">#</a> 一维 Tile</h3>\n<p>要进一步优化，可以从前文的 profiling 结果入手。我们无论是使用全局内存还是共享内存，主要的瓶颈都在访存上。为了进一步掩盖访存开销，我们要么可以提高访存的效率，要么让每个线程的负载更多一点，以使得能够掩盖访存的开销。</p>\n<p>这里我们先尝试提高每个线程的负载， 让每个线程多计算一些元素的输出。这里我们让每个线程计算矩阵 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>C</mi></mrow><annotation encoding=\"application/x-tex\">C</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.6833em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.07153em;\">C</span></span></span></span> 一列中连续几个元素的值。</p>\n<p><img loading=\"lazy\" data-src=\"/images/cuda/SGEMM-optimization/thread-tile-1d-kernel.png\" alt=\"一维 Tile\"></p>\n<p>在使用共享内存的基础上，我们添加了一维 Tile 的代码。</p>\n<figure class=\"highlight c\"><figcaption data-lang=\"c\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre><span class=\"token keyword\">float</span> val<span class=\"token punctuation\">[</span>TM<span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> <span class=\"token punctuation\">&#123;</span><span class=\"token number\">0.</span><span class=\"token punctuation\">&#125;</span><span class=\"token punctuation\">;</span></pre></td></tr></table></figure><p>因为每个线程需要计算 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>T</mi><mi>M</mi></mrow><annotation encoding=\"application/x-tex\">TM</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.6833em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.10903em;\">TM</span></span></span></span> 个元素的结果，我们使用一个 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>T</mi><mi>M</mi></mrow><annotation encoding=\"application/x-tex\">TM</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.6833em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.10903em;\">TM</span></span></span></span> 大小的数组来存储中间结果。</p>\n<p>在拷贝数据时，每个线程需要在 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>A</mi></mrow><annotation encoding=\"application/x-tex\">A</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.6833em;\"></span><span class=\"mord mathnormal\">A</span></span></span></span> 矩阵中多拷贝 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>T</mi><mi>M</mi></mrow><annotation encoding=\"application/x-tex\">TM</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.6833em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.10903em;\">TM</span></span></span></span> 次：</p>\n<figure class=\"highlight c\"><figcaption data-lang=\"c\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre><span class=\"token comment\">// Copy data from global memory to shared memory  </span></pre></td></tr><tr><td data-num=\"2\"></td><td><pre><span class=\"token keyword\">for</span> <span class=\"token punctuation\">(</span><span class=\"token keyword\">int</span> m <span class=\"token operator\">=</span> <span class=\"token number\">0</span><span class=\"token punctuation\">;</span> m <span class=\"token operator\">&lt;</span> TM<span class=\"token punctuation\">;</span> <span class=\"token operator\">++</span>m<span class=\"token punctuation\">)</span> <span class=\"token punctuation\">&#123;</span>  </pre></td></tr><tr><td data-num=\"3\"></td><td><pre>    <span class=\"token keyword\">int</span> A_row <span class=\"token operator\">=</span> threadIdx<span class=\"token punctuation\">.</span>y <span class=\"token operator\">*</span> TM <span class=\"token operator\">+</span> m<span class=\"token punctuation\">;</span>  </pre></td></tr><tr><td data-num=\"4\"></td><td><pre>    <span class=\"token keyword\">int</span> A_col <span class=\"token operator\">=</span> threadIdx<span class=\"token punctuation\">.</span>x<span class=\"token punctuation\">;</span>  </pre></td></tr><tr><td data-num=\"5\"></td><td><pre>    <span class=\"token keyword\">if</span> <span class=\"token punctuation\">(</span><span class=\"token punctuation\">(</span>blockIdx<span class=\"token punctuation\">.</span>y <span class=\"token operator\">*</span> BM <span class=\"token operator\">+</span> A_row<span class=\"token punctuation\">)</span> <span class=\"token operator\">&lt;</span> M <span class=\"token operator\">&amp;&amp;</span> <span class=\"token punctuation\">(</span>i <span class=\"token operator\">*</span> BK <span class=\"token operator\">+</span> A_col<span class=\"token punctuation\">)</span> <span class=\"token operator\">&lt;</span> K<span class=\"token punctuation\">)</span> <span class=\"token punctuation\">&#123;</span>  </pre></td></tr><tr><td data-num=\"6\"></td><td><pre>        As<span class=\"token punctuation\">[</span>A_row<span class=\"token punctuation\">]</span><span class=\"token punctuation\">[</span>A_col<span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> A<span class=\"token punctuation\">[</span><span class=\"token function\">OFFSET</span><span class=\"token punctuation\">(</span>A_row<span class=\"token punctuation\">,</span> A_col<span class=\"token punctuation\">,</span> K<span class=\"token punctuation\">)</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">;</span>  </pre></td></tr><tr><td data-num=\"7\"></td><td><pre>    <span class=\"token punctuation\">&#125;</span> <span class=\"token keyword\">else</span> <span class=\"token punctuation\">&#123;</span>  </pre></td></tr><tr><td data-num=\"8\"></td><td><pre>        As<span class=\"token punctuation\">[</span>A_row<span class=\"token punctuation\">]</span><span class=\"token punctuation\">[</span>A_col<span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> <span class=\"token number\">0.</span><span class=\"token punctuation\">;</span>  </pre></td></tr><tr><td data-num=\"9\"></td><td><pre>    <span class=\"token punctuation\">&#125;</span>  </pre></td></tr><tr><td data-num=\"10\"></td><td><pre><span class=\"token punctuation\">&#125;</span></pre></td></tr></table></figure><p>计算中间结果时，也需要多一层循环：</p>\n<figure class=\"highlight c\"><figcaption data-lang=\"c\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre><span class=\"token keyword\">for</span> <span class=\"token punctuation\">(</span><span class=\"token keyword\">int</span> k <span class=\"token operator\">=</span> <span class=\"token number\">0</span><span class=\"token punctuation\">;</span> k <span class=\"token operator\">&lt;</span> BK<span class=\"token punctuation\">;</span> <span class=\"token operator\">++</span>k<span class=\"token punctuation\">)</span> <span class=\"token punctuation\">&#123;</span>  </pre></td></tr><tr><td data-num=\"2\"></td><td><pre>    <span class=\"token keyword\">for</span> <span class=\"token punctuation\">(</span><span class=\"token keyword\">int</span> m <span class=\"token operator\">=</span> <span class=\"token number\">0</span><span class=\"token punctuation\">;</span> m <span class=\"token operator\">&lt;</span> TM<span class=\"token punctuation\">;</span> <span class=\"token operator\">++</span>m<span class=\"token punctuation\">)</span> <span class=\"token punctuation\">&#123;</span>  </pre></td></tr><tr><td data-num=\"3\"></td><td><pre>        <span class=\"token keyword\">int</span> A_row <span class=\"token operator\">=</span> threadIdx<span class=\"token punctuation\">.</span>y <span class=\"token operator\">*</span> TM <span class=\"token operator\">+</span> m<span class=\"token punctuation\">;</span>  </pre></td></tr><tr><td data-num=\"4\"></td><td><pre>        <span class=\"token keyword\">int</span> B_col <span class=\"token operator\">=</span> threadIdx<span class=\"token punctuation\">.</span>x<span class=\"token punctuation\">;</span>  </pre></td></tr><tr><td data-num=\"5\"></td><td><pre>        val<span class=\"token punctuation\">[</span>m<span class=\"token punctuation\">]</span> <span class=\"token operator\">+=</span> As<span class=\"token punctuation\">[</span>A_row<span class=\"token punctuation\">]</span><span class=\"token punctuation\">[</span>k<span class=\"token punctuation\">]</span> <span class=\"token operator\">*</span> Bs<span class=\"token punctuation\">[</span>k<span class=\"token punctuation\">]</span><span class=\"token punctuation\">[</span>B_col<span class=\"token punctuation\">]</span><span class=\"token punctuation\">;</span>  </pre></td></tr><tr><td data-num=\"6\"></td><td><pre>    <span class=\"token punctuation\">&#125;</span>  </pre></td></tr><tr><td data-num=\"7\"></td><td><pre><span class=\"token punctuation\">&#125;</span></pre></td></tr></table></figure><p>最后，将计算结果写回：</p>\n<figure class=\"highlight c\"><figcaption data-lang=\"c\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre><span class=\"token keyword\">for</span> <span class=\"token punctuation\">(</span><span class=\"token keyword\">int</span> m <span class=\"token operator\">=</span> <span class=\"token number\">0</span><span class=\"token punctuation\">;</span> m <span class=\"token operator\">&lt;</span> TM<span class=\"token punctuation\">;</span> <span class=\"token operator\">++</span>m<span class=\"token punctuation\">)</span> <span class=\"token punctuation\">&#123;</span>  </pre></td></tr><tr><td data-num=\"2\"></td><td><pre>    <span class=\"token keyword\">int</span> C_row <span class=\"token operator\">=</span> threadIdx<span class=\"token punctuation\">.</span>y <span class=\"token operator\">*</span> TM <span class=\"token operator\">+</span> m<span class=\"token punctuation\">;</span>  </pre></td></tr><tr><td data-num=\"3\"></td><td><pre>    <span class=\"token keyword\">int</span> C_col <span class=\"token operator\">=</span> threadIdx<span class=\"token punctuation\">.</span>x<span class=\"token punctuation\">;</span>  </pre></td></tr><tr><td data-num=\"4\"></td><td><pre>    <span class=\"token keyword\">if</span> <span class=\"token punctuation\">(</span><span class=\"token punctuation\">(</span>blockIdx<span class=\"token punctuation\">.</span>y <span class=\"token operator\">*</span> BM <span class=\"token operator\">+</span> C_row<span class=\"token punctuation\">)</span> <span class=\"token operator\">&lt;</span> M <span class=\"token operator\">&amp;&amp;</span> <span class=\"token punctuation\">(</span>blockIdx<span class=\"token punctuation\">.</span>x <span class=\"token operator\">*</span> BN <span class=\"token operator\">+</span> C_col<span class=\"token punctuation\">)</span> <span class=\"token operator\">&lt;</span> N<span class=\"token punctuation\">)</span> <span class=\"token punctuation\">&#123;</span>  </pre></td></tr><tr><td data-num=\"5\"></td><td><pre>        C<span class=\"token punctuation\">[</span><span class=\"token function\">OFFSET</span><span class=\"token punctuation\">(</span>C_row<span class=\"token punctuation\">,</span> C_col<span class=\"token punctuation\">,</span> N<span class=\"token punctuation\">)</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> alpha <span class=\"token operator\">*</span> val<span class=\"token punctuation\">[</span>m<span class=\"token punctuation\">]</span> <span class=\"token operator\">+</span> beta <span class=\"token operator\">*</span> C<span class=\"token punctuation\">[</span><span class=\"token function\">OFFSET</span><span class=\"token punctuation\">(</span>C_row<span class=\"token punctuation\">,</span> C_col<span class=\"token punctuation\">,</span> N<span class=\"token punctuation\">)</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">;</span>  </pre></td></tr><tr><td data-num=\"6\"></td><td><pre>    <span class=\"token punctuation\">&#125;</span>  </pre></td></tr><tr><td data-num=\"7\"></td><td><pre><span class=\"token punctuation\">&#125;</span></pre></td></tr></table></figure><p><img loading=\"lazy\" data-src=\"/images/cuda/SGEMM-optimization/kernel-performance/kernel-tile-1d.png\" alt=\"1d tile kernel\"></p>\n<p>可以看到，使用 Tile 之后，性能得到了一定的提升，逼近了 2000 GFLOPS。一个 block 全局访存的数量依然为 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>K</mi><mo stretchy=\"false\">(</mo><mi>M</mi><mo>+</mo><mi>N</mi><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">K(M+N)</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.07153em;\">K</span><span class=\"mopen\">(</span><span class=\"mord mathnormal\" style=\"margin-right:0.10903em;\">M</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span><span class=\"mbin\">+</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.10903em;\">N</span><span class=\"mclose\">)</span></span></span></span>，但是每个线程负责的计算量为原来的 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>T</mi><mi>M</mi></mrow><annotation encoding=\"application/x-tex\">TM</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.6833em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.10903em;\">TM</span></span></span></span> 倍，因此计算访存比提升了 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>T</mi><mi>M</mi></mrow><annotation encoding=\"application/x-tex\">TM</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.6833em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.10903em;\">TM</span></span></span></span> 倍。</p>\n<p><img loading=\"lazy\" data-src=\"/images/cuda/SGEMM-optimization/tile-1d-kernel-warp-state.png\" alt=\"tile 1d kernel warp state\"></p>\n<p>这次可以看到，相比仅使用共享内存，增加线程计算负载之后  <code>Stall MIO Throttle</code>  这一项的横轴数值有了减小，之前超过了 20 cycles per instruction，现在已经在 20 以下了。不过也可以看出，这一项的延时依然较高，我们还可以有提升空间。</p>\n<h3 id=\"二维-tile\"><a class=\"markdownIt-Anchor\" href=\"#二维-tile\">#</a> 二维 Tile</h3>\n<p>和一维 Tile 类似，这次我们让每个线程负责计算矩阵 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>C</mi></mrow><annotation encoding=\"application/x-tex\">C</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.6833em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.07153em;\">C</span></span></span></span> 中一小块 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>T</mi><mi>M</mi><mo>×</mo><mi>T</mi><mi>N</mi></mrow><annotation encoding=\"application/x-tex\">TM \\times TN</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.7667em;vertical-align:-0.0833em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.10903em;\">TM</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span><span class=\"mbin\">×</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.6833em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.10903em;\">TN</span></span></span></span> 区域中的元素，进一步提升每个线程的负载。有了一维 Tile 的代码，我们简单地在其基础之上做少许修改，便可以得到二维 Tile 的代码。</p>\n<p>存储中间结果需要分配 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>T</mi><mi>M</mi><mo>×</mo><mi>T</mi><mi>N</mi></mrow><annotation encoding=\"application/x-tex\">TM \\times TN</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.7667em;vertical-align:-0.0833em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.10903em;\">TM</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span><span class=\"mbin\">×</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.6833em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.10903em;\">TN</span></span></span></span> 大小的空间：</p>\n<figure class=\"highlight c\"><figcaption data-lang=\"c\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre><span class=\"token keyword\">float</span> val<span class=\"token punctuation\">[</span>TM<span class=\"token punctuation\">]</span><span class=\"token punctuation\">[</span>TN<span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> <span class=\"token punctuation\">&#123;</span><span class=\"token number\">0.</span><span class=\"token punctuation\">&#125;</span><span class=\"token punctuation\">;</span></pre></td></tr></table></figure><p>注意这里的 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>T</mi><mi>M</mi></mrow><annotation encoding=\"application/x-tex\">TM</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.6833em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.10903em;\">TM</span></span></span></span> 和 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>T</mi><mi>N</mi></mrow><annotation encoding=\"application/x-tex\">TN</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.6833em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.10903em;\">TN</span></span></span></span> 不能设置过大，否则可能寄存器资源不够，导致 register spill，这时中间数据便会使用 local memory 存储，访存速度会慢很多。</p>\n<p>拷贝数据时，在矩阵 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>B</mi></mrow><annotation encoding=\"application/x-tex\">B</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.6833em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.05017em;\">B</span></span></span></span> 上也要多拷贝 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>T</mi><mi>N</mi></mrow><annotation encoding=\"application/x-tex\">TN</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.6833em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.10903em;\">TN</span></span></span></span> 次：</p>\n<figure class=\"highlight c\"><figcaption data-lang=\"c\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre><span class=\"token keyword\">for</span> <span class=\"token punctuation\">(</span><span class=\"token keyword\">int</span> n <span class=\"token operator\">=</span> <span class=\"token number\">0</span><span class=\"token punctuation\">;</span> n <span class=\"token operator\">&lt;</span> TN<span class=\"token punctuation\">;</span> <span class=\"token operator\">++</span>n<span class=\"token punctuation\">)</span> <span class=\"token punctuation\">&#123;</span>  </pre></td></tr><tr><td data-num=\"2\"></td><td><pre>    <span class=\"token keyword\">int</span> B_row <span class=\"token operator\">=</span> threadIdx<span class=\"token punctuation\">.</span>y<span class=\"token punctuation\">;</span>  </pre></td></tr><tr><td data-num=\"3\"></td><td><pre>    <span class=\"token keyword\">int</span> B_col <span class=\"token operator\">=</span> threadIdx<span class=\"token punctuation\">.</span>x <span class=\"token operator\">*</span> TN <span class=\"token operator\">+</span> n<span class=\"token punctuation\">;</span>  </pre></td></tr><tr><td data-num=\"4\"></td><td><pre>    <span class=\"token keyword\">if</span> <span class=\"token punctuation\">(</span><span class=\"token punctuation\">(</span>i <span class=\"token operator\">*</span> BK <span class=\"token operator\">+</span> B_row<span class=\"token punctuation\">)</span> <span class=\"token operator\">&lt;</span> K <span class=\"token operator\">&amp;&amp;</span> <span class=\"token punctuation\">(</span>blockIdx<span class=\"token punctuation\">.</span>x <span class=\"token operator\">*</span> BN <span class=\"token operator\">+</span> B_col<span class=\"token punctuation\">)</span> <span class=\"token operator\">&lt;</span> N<span class=\"token punctuation\">)</span> <span class=\"token punctuation\">&#123;</span>  </pre></td></tr><tr><td data-num=\"5\"></td><td><pre>        Bs<span class=\"token punctuation\">[</span>B_row<span class=\"token punctuation\">]</span><span class=\"token punctuation\">[</span>B_col<span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> B<span class=\"token punctuation\">[</span><span class=\"token function\">OFFSET</span><span class=\"token punctuation\">(</span>B_row<span class=\"token punctuation\">,</span> B_col<span class=\"token punctuation\">,</span> N<span class=\"token punctuation\">)</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">;</span>  </pre></td></tr><tr><td data-num=\"6\"></td><td><pre>    <span class=\"token punctuation\">&#125;</span> <span class=\"token keyword\">else</span> <span class=\"token punctuation\">&#123;</span>  </pre></td></tr><tr><td data-num=\"7\"></td><td><pre>        Bs<span class=\"token punctuation\">[</span>B_row<span class=\"token punctuation\">]</span><span class=\"token punctuation\">[</span>B_col<span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> <span class=\"token number\">0.</span><span class=\"token punctuation\">;</span>  </pre></td></tr><tr><td data-num=\"8\"></td><td><pre>    <span class=\"token punctuation\">&#125;</span>  </pre></td></tr><tr><td data-num=\"9\"></td><td><pre><span class=\"token punctuation\">&#125;</span></pre></td></tr></table></figure><p>同理，计算结果时需要使用二重循环：</p>\n<figure class=\"highlight c\"><figcaption data-lang=\"c\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre><span class=\"token keyword\">for</span> <span class=\"token punctuation\">(</span><span class=\"token keyword\">int</span> k <span class=\"token operator\">=</span> <span class=\"token number\">0</span><span class=\"token punctuation\">;</span> k <span class=\"token operator\">&lt;</span> BK<span class=\"token punctuation\">;</span> <span class=\"token operator\">++</span>k<span class=\"token punctuation\">)</span> <span class=\"token punctuation\">&#123;</span>  </pre></td></tr><tr><td data-num=\"2\"></td><td><pre>    <span class=\"token keyword\">for</span> <span class=\"token punctuation\">(</span><span class=\"token keyword\">int</span> m <span class=\"token operator\">=</span> <span class=\"token number\">0</span><span class=\"token punctuation\">;</span> m <span class=\"token operator\">&lt;</span> TM<span class=\"token punctuation\">;</span> <span class=\"token operator\">++</span>m<span class=\"token punctuation\">)</span> <span class=\"token punctuation\">&#123;</span>  </pre></td></tr><tr><td data-num=\"3\"></td><td><pre>        <span class=\"token keyword\">int</span> A_row <span class=\"token operator\">=</span> threadIdx<span class=\"token punctuation\">.</span>y <span class=\"token operator\">*</span> TM <span class=\"token operator\">+</span> m<span class=\"token punctuation\">;</span>  </pre></td></tr><tr><td data-num=\"4\"></td><td><pre>        <span class=\"token keyword\">for</span> <span class=\"token punctuation\">(</span><span class=\"token keyword\">int</span> n <span class=\"token operator\">=</span> <span class=\"token number\">0</span><span class=\"token punctuation\">;</span> n <span class=\"token operator\">&lt;</span> TN<span class=\"token punctuation\">;</span> <span class=\"token operator\">++</span>n<span class=\"token punctuation\">)</span> <span class=\"token punctuation\">&#123;</span>  </pre></td></tr><tr><td data-num=\"5\"></td><td><pre>            <span class=\"token keyword\">int</span> B_col <span class=\"token operator\">=</span> threadIdx<span class=\"token punctuation\">.</span>x <span class=\"token operator\">*</span> TN <span class=\"token operator\">+</span> n<span class=\"token punctuation\">;</span>  </pre></td></tr><tr><td data-num=\"6\"></td><td><pre>            val<span class=\"token punctuation\">[</span>m<span class=\"token punctuation\">]</span><span class=\"token punctuation\">[</span>n<span class=\"token punctuation\">]</span> <span class=\"token operator\">+=</span> As<span class=\"token punctuation\">[</span>A_row<span class=\"token punctuation\">]</span><span class=\"token punctuation\">[</span>k<span class=\"token punctuation\">]</span> <span class=\"token operator\">*</span> Bs<span class=\"token punctuation\">[</span>k<span class=\"token punctuation\">]</span><span class=\"token punctuation\">[</span>B_col<span class=\"token punctuation\">]</span><span class=\"token punctuation\">;</span>  </pre></td></tr><tr><td data-num=\"7\"></td><td><pre>        <span class=\"token punctuation\">&#125;</span>  </pre></td></tr><tr><td data-num=\"8\"></td><td><pre>    <span class=\"token punctuation\">&#125;</span>  </pre></td></tr><tr><td data-num=\"9\"></td><td><pre><span class=\"token punctuation\">&#125;</span></pre></td></tr></table></figure><p>结果写回：</p>\n<figure class=\"highlight c\"><figcaption data-lang=\"c\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre><span class=\"token keyword\">for</span> <span class=\"token punctuation\">(</span><span class=\"token keyword\">int</span> m <span class=\"token operator\">=</span> <span class=\"token number\">0</span><span class=\"token punctuation\">;</span> m <span class=\"token operator\">&lt;</span> TM<span class=\"token punctuation\">;</span> <span class=\"token operator\">++</span>m<span class=\"token punctuation\">)</span> <span class=\"token punctuation\">&#123;</span>  </pre></td></tr><tr><td data-num=\"2\"></td><td><pre>    <span class=\"token keyword\">int</span> C_row <span class=\"token operator\">=</span> threadIdx<span class=\"token punctuation\">.</span>y <span class=\"token operator\">*</span> TM <span class=\"token operator\">+</span> m<span class=\"token punctuation\">;</span>  </pre></td></tr><tr><td data-num=\"3\"></td><td><pre>    <span class=\"token keyword\">for</span> <span class=\"token punctuation\">(</span><span class=\"token keyword\">int</span> n <span class=\"token operator\">=</span> <span class=\"token number\">0</span><span class=\"token punctuation\">;</span> n <span class=\"token operator\">&lt;</span> TN<span class=\"token punctuation\">;</span> <span class=\"token operator\">++</span>n<span class=\"token punctuation\">)</span> <span class=\"token punctuation\">&#123;</span>  </pre></td></tr><tr><td data-num=\"4\"></td><td><pre>        <span class=\"token keyword\">int</span> C_col <span class=\"token operator\">=</span> threadIdx<span class=\"token punctuation\">.</span>x <span class=\"token operator\">*</span> TN <span class=\"token operator\">+</span> n<span class=\"token punctuation\">;</span>  </pre></td></tr><tr><td data-num=\"5\"></td><td><pre>        <span class=\"token keyword\">if</span> <span class=\"token punctuation\">(</span><span class=\"token punctuation\">(</span>blockIdx<span class=\"token punctuation\">.</span>y <span class=\"token operator\">*</span> BM <span class=\"token operator\">+</span> C_row<span class=\"token punctuation\">)</span> <span class=\"token operator\">&lt;</span> M <span class=\"token operator\">&amp;&amp;</span> <span class=\"token punctuation\">(</span>blockIdx<span class=\"token punctuation\">.</span>x <span class=\"token operator\">*</span> BN <span class=\"token operator\">+</span> C_col<span class=\"token punctuation\">)</span> <span class=\"token operator\">&lt;</span> N<span class=\"token punctuation\">)</span> <span class=\"token punctuation\">&#123;</span>  </pre></td></tr><tr><td data-num=\"6\"></td><td><pre>            C<span class=\"token punctuation\">[</span><span class=\"token function\">OFFSET</span><span class=\"token punctuation\">(</span>C_row<span class=\"token punctuation\">,</span> C_col<span class=\"token punctuation\">,</span> N<span class=\"token punctuation\">)</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> alpha <span class=\"token operator\">*</span> val<span class=\"token punctuation\">[</span>m<span class=\"token punctuation\">]</span><span class=\"token punctuation\">[</span>n<span class=\"token punctuation\">]</span> <span class=\"token operator\">+</span> beta <span class=\"token operator\">*</span> C<span class=\"token punctuation\">[</span><span class=\"token function\">OFFSET</span><span class=\"token punctuation\">(</span>C_row<span class=\"token punctuation\">,</span> C_col<span class=\"token punctuation\">,</span> N<span class=\"token punctuation\">)</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">;</span>  </pre></td></tr><tr><td data-num=\"7\"></td><td><pre>        <span class=\"token punctuation\">&#125;</span>  </pre></td></tr><tr><td data-num=\"8\"></td><td><pre>    <span class=\"token punctuation\">&#125;</span>  </pre></td></tr><tr><td data-num=\"9\"></td><td><pre><span class=\"token punctuation\">&#125;</span></pre></td></tr></table></figure><p><img loading=\"lazy\" data-src=\"/images/cuda/SGEMM-optimization/kernel-performance/kernel-tile-2d.png\" alt=\"2d tile kernel\"></p>\n<p>可以看到，现在的性能相比朴素的实现有了很大的提升，性能接近了 4000 GFLOPS。在一维 Tile 的基础之上，计算访存比进一步提升了 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>T</mi><mi>N</mi></mrow><annotation encoding=\"application/x-tex\">TN</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.6833em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.10903em;\">TN</span></span></span></span> 倍。</p>\n<p><img loading=\"lazy\" data-src=\"/images/cuda/SGEMM-optimization/tile-2d-kernel-warp-state.png\" alt=\"tile 2d kernel warp state\"></p>\n<p>可以看到，现在的  <code>Stall MIO Throttle</code>  已经降低到 11 cycles per instruction。相比仅使用共享内存，降低到了原来的不到一半。性能的数值也和 profiling 的结果能够互相印证。</p>\n<h3 id=\"使用寄存器进一步优化访存\"><a class=\"markdownIt-Anchor\" href=\"#使用寄存器进一步优化访存\">#</a> 使用寄存器进一步优化访存</h3>\n<p>对于二维 Tile 中计算矩阵 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>C</mi></mrow><annotation encoding=\"application/x-tex\">C</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.6833em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.07153em;\">C</span></span></span></span> 结果的代码：</p>\n<figure class=\"highlight c\"><figcaption data-lang=\"c\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre><span class=\"token keyword\">for</span> <span class=\"token punctuation\">(</span><span class=\"token keyword\">int</span> k <span class=\"token operator\">=</span> <span class=\"token number\">0</span><span class=\"token punctuation\">;</span> k <span class=\"token operator\">&lt;</span> BK<span class=\"token punctuation\">;</span> <span class=\"token operator\">++</span>k<span class=\"token punctuation\">)</span> <span class=\"token punctuation\">&#123;</span>  </pre></td></tr><tr><td data-num=\"2\"></td><td><pre>    <span class=\"token keyword\">for</span> <span class=\"token punctuation\">(</span><span class=\"token keyword\">int</span> m <span class=\"token operator\">=</span> <span class=\"token number\">0</span><span class=\"token punctuation\">;</span> m <span class=\"token operator\">&lt;</span> TM<span class=\"token punctuation\">;</span> <span class=\"token operator\">++</span>m<span class=\"token punctuation\">)</span> <span class=\"token punctuation\">&#123;</span>  </pre></td></tr><tr><td data-num=\"3\"></td><td><pre>        <span class=\"token keyword\">int</span> A_row <span class=\"token operator\">=</span> threadIdx<span class=\"token punctuation\">.</span>y <span class=\"token operator\">*</span> TM <span class=\"token operator\">+</span> m<span class=\"token punctuation\">;</span>  </pre></td></tr><tr><td data-num=\"4\"></td><td><pre>        <span class=\"token keyword\">for</span> <span class=\"token punctuation\">(</span><span class=\"token keyword\">int</span> n <span class=\"token operator\">=</span> <span class=\"token number\">0</span><span class=\"token punctuation\">;</span> n <span class=\"token operator\">&lt;</span> TN<span class=\"token punctuation\">;</span> <span class=\"token operator\">++</span>n<span class=\"token punctuation\">)</span> <span class=\"token punctuation\">&#123;</span>  </pre></td></tr><tr><td data-num=\"5\"></td><td><pre>            <span class=\"token keyword\">int</span> B_col <span class=\"token operator\">=</span> threadIdx<span class=\"token punctuation\">.</span>x <span class=\"token operator\">*</span> TN <span class=\"token operator\">+</span> n<span class=\"token punctuation\">;</span>  </pre></td></tr><tr><td data-num=\"6\"></td><td><pre>            val<span class=\"token punctuation\">[</span>m<span class=\"token punctuation\">]</span><span class=\"token punctuation\">[</span>n<span class=\"token punctuation\">]</span> <span class=\"token operator\">+=</span> As<span class=\"token punctuation\">[</span>A_row<span class=\"token punctuation\">]</span><span class=\"token punctuation\">[</span>k<span class=\"token punctuation\">]</span> <span class=\"token operator\">*</span> Bs<span class=\"token punctuation\">[</span>k<span class=\"token punctuation\">]</span><span class=\"token punctuation\">[</span>B_col<span class=\"token punctuation\">]</span><span class=\"token punctuation\">;</span>  </pre></td></tr><tr><td data-num=\"7\"></td><td><pre>        <span class=\"token punctuation\">&#125;</span>  </pre></td></tr><tr><td data-num=\"8\"></td><td><pre>    <span class=\"token punctuation\">&#125;</span>  </pre></td></tr><tr><td data-num=\"9\"></td><td><pre><span class=\"token punctuation\">&#125;</span></pre></td></tr></table></figure><p>可以看到，对于  <code>As</code>  中的内容重复访问了 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>T</mi><mi>N</mi></mrow><annotation encoding=\"application/x-tex\">TN</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.6833em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.10903em;\">TN</span></span></span></span> 次；对于  <code>Bs</code>  中的内容，在外层的  <code>m</code>  迭代中，也会重复访问 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>T</mi><mi>M</mi></mrow><annotation encoding=\"application/x-tex\">TM</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.6833em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.10903em;\">TM</span></span></span></span> 次。因此，我们可以使用寄存器将这部分内容缓存下来，进一步提升访存。</p>\n<figure class=\"highlight c\"><figcaption data-lang=\"c\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre><span class=\"token keyword\">for</span> <span class=\"token punctuation\">(</span><span class=\"token keyword\">int</span> k <span class=\"token operator\">=</span> <span class=\"token number\">0</span><span class=\"token punctuation\">;</span> k <span class=\"token operator\">&lt;</span> BK<span class=\"token punctuation\">;</span> <span class=\"token operator\">++</span>k<span class=\"token punctuation\">)</span> <span class=\"token punctuation\">&#123;</span>  </pre></td></tr><tr><td data-num=\"2\"></td><td><pre>    <span class=\"token keyword\">for</span> <span class=\"token punctuation\">(</span><span class=\"token keyword\">int</span> m <span class=\"token operator\">=</span> <span class=\"token number\">0</span><span class=\"token punctuation\">;</span> m <span class=\"token operator\">&lt;</span> TM<span class=\"token punctuation\">;</span> <span class=\"token operator\">++</span>m<span class=\"token punctuation\">)</span> <span class=\"token punctuation\">&#123;</span>  </pre></td></tr><tr><td data-num=\"3\"></td><td><pre>        <span class=\"token keyword\">int</span> A_row <span class=\"token operator\">=</span> threadIdx<span class=\"token punctuation\">.</span>y <span class=\"token operator\">*</span> TM <span class=\"token operator\">+</span> m<span class=\"token punctuation\">;</span>  </pre></td></tr><tr><td data-num=\"4\"></td><td><pre>        As_cache<span class=\"token punctuation\">[</span>m<span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> As<span class=\"token punctuation\">[</span>A_row<span class=\"token punctuation\">]</span><span class=\"token punctuation\">[</span>k<span class=\"token punctuation\">]</span><span class=\"token punctuation\">;</span>  </pre></td></tr><tr><td data-num=\"5\"></td><td><pre>    <span class=\"token punctuation\">&#125;</span>  </pre></td></tr><tr><td data-num=\"6\"></td><td><pre>    <span class=\"token keyword\">for</span> <span class=\"token punctuation\">(</span><span class=\"token keyword\">int</span> n <span class=\"token operator\">=</span> <span class=\"token number\">0</span><span class=\"token punctuation\">;</span> n <span class=\"token operator\">&lt;</span> TN<span class=\"token punctuation\">;</span> <span class=\"token operator\">++</span>n<span class=\"token punctuation\">)</span> <span class=\"token punctuation\">&#123;</span>  </pre></td></tr><tr><td data-num=\"7\"></td><td><pre>        <span class=\"token keyword\">int</span> B_col <span class=\"token operator\">=</span> threadIdx<span class=\"token punctuation\">.</span>x <span class=\"token operator\">*</span> TN <span class=\"token operator\">+</span> n<span class=\"token punctuation\">;</span>  </pre></td></tr><tr><td data-num=\"8\"></td><td><pre>        Bs_cache<span class=\"token punctuation\">[</span>n<span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> Bs<span class=\"token punctuation\">[</span>k<span class=\"token punctuation\">]</span><span class=\"token punctuation\">[</span>B_col<span class=\"token punctuation\">]</span><span class=\"token punctuation\">;</span>  </pre></td></tr><tr><td data-num=\"9\"></td><td><pre>    <span class=\"token punctuation\">&#125;</span>  </pre></td></tr><tr><td data-num=\"10\"></td><td><pre>    <span class=\"token keyword\">for</span> <span class=\"token punctuation\">(</span><span class=\"token keyword\">int</span> m <span class=\"token operator\">=</span> <span class=\"token number\">0</span><span class=\"token punctuation\">;</span> m <span class=\"token operator\">&lt;</span> TM<span class=\"token punctuation\">;</span> <span class=\"token operator\">++</span>m<span class=\"token punctuation\">)</span> <span class=\"token punctuation\">&#123;</span>  </pre></td></tr><tr><td data-num=\"11\"></td><td><pre>        <span class=\"token keyword\">for</span> <span class=\"token punctuation\">(</span><span class=\"token keyword\">int</span> n <span class=\"token operator\">=</span> <span class=\"token number\">0</span><span class=\"token punctuation\">;</span> n <span class=\"token operator\">&lt;</span> TN<span class=\"token punctuation\">;</span> <span class=\"token operator\">++</span>n<span class=\"token punctuation\">)</span> <span class=\"token punctuation\">&#123;</span>  </pre></td></tr><tr><td data-num=\"12\"></td><td><pre>            val<span class=\"token punctuation\">[</span>m<span class=\"token punctuation\">]</span><span class=\"token punctuation\">[</span>n<span class=\"token punctuation\">]</span> <span class=\"token operator\">+=</span> As_cache<span class=\"token punctuation\">[</span>m<span class=\"token punctuation\">]</span> <span class=\"token operator\">*</span> Bs_cache<span class=\"token punctuation\">[</span>n<span class=\"token punctuation\">]</span><span class=\"token punctuation\">;</span>  </pre></td></tr><tr><td data-num=\"13\"></td><td><pre>        <span class=\"token punctuation\">&#125;</span>  </pre></td></tr><tr><td data-num=\"14\"></td><td><pre>    <span class=\"token punctuation\">&#125;</span>  </pre></td></tr><tr><td data-num=\"15\"></td><td><pre><span class=\"token punctuation\">&#125;</span></pre></td></tr></table></figure><p>不过这部分的优化在我的测试中对性能的提升并不明显。</p>\n<p><img loading=\"lazy\" data-src=\"/images/cuda/SGEMM-optimization/kernel-performance/kernel-reg-cache.png\" alt=\"register cache kernel\"></p>\n<p>在 profiling 的结果中发现，和使用之前对于  <code>Stall MIO Throttle</code>  指标几乎没有降低，也就是并没有降低访存的开销。</p>\n<p><img loading=\"lazy\" data-src=\"/images/cuda/SGEMM-optimization/reg-cache-kernel-code.png\" alt=\"register cache kernel code\"></p>\n<p>从代码对应图中可以看到，虽然我们使用了寄存器，但是从共享内存读取数据到寄存器中的时候依然存在较大的  <code>MIO</code>  延迟，即这个延迟只是从一条语句转移到了其他语句之上，并没有被我们掩盖掉，所以没有性能提升也就是正常的了。</p>\n<h3 id=\"使用-float4-指令优化访存\"><a class=\"markdownIt-Anchor\" href=\"#使用-float4-指令优化访存\">#</a> 使用 FLOAT4 指令优化访存</h3>\n<p><img loading=\"lazy\" data-src=\"/images/cuda/SGEMM-optimization/kernel-performance/tile-2d-performance-analysis.png\" alt=\"tile 2d performance analysis\"></p>\n<p>通过前面 profiling 的结果，能够发现很大一部分时间仍然花在了等待访存之上。可以看到，内存带宽的使用负载大于计算的负载。访存延迟依然是程序性能的瓶颈。</p>\n<p>我们可以进一步利用 GPU  <code>float4</code>  访存特性来进一步优化，让每个元素一次获取 4 个浮点数，进一步减少访存次数。相比于访存 4 次获取 4 个浮点数，通过  <code>float4</code>  向量内存指令所需的访存指令数更少，减少了对内存访问的竞争；另一方面，使用向量加载每个字节需要的索引计算更少，我们只需要计算一次索引即可读取 4 个浮点数。但是这样一来，代码也会变得略显复杂。</p>\n<p>同时，我们在读取矩阵 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>A</mi></mrow><annotation encoding=\"application/x-tex\">A</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.6833em;\"></span><span class=\"mord mathnormal\">A</span></span></span></span> 的内容时，还要对其进行转置，然后再存储到 shared memory 中，以方便后续线程计算时使用  <code>float4</code>  读取，以避免共享内存的 bank conflict。</p>\n<p>我们使用以下宏来定义一次访问 4 个浮点数的操作：</p>\n<figure class=\"highlight c\"><figcaption data-lang=\"c\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre><span class=\"token macro property\"><span class=\"token directive-hash\">#</span><span class=\"token directive keyword\">define</span> <span class=\"token macro-name function\">FETCH_FLOAT4</span><span class=\"token expression\"><span class=\"token punctuation\">(</span>pointer<span class=\"token punctuation\">)</span> <span class=\"token punctuation\">(</span>reinterpret_cast<span class=\"token operator\">&lt;</span>float4<span class=\"token operator\">*</span><span class=\"token operator\">></span><span class=\"token punctuation\">(</span><span class=\"token operator\">&amp;</span><span class=\"token punctuation\">(</span>pointer<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span></span></span></pre></td></tr></table></figure><p>需要注意，因为使用了 FLOAT4 访存的缘故，矩阵的元素数量必须是 4 的倍数，不再能够支持任意大小的矩阵<sup class=\"footnote-ref\"><a href=\"#fn1\" id=\"fnref1\">[1]</a></sup>。</p>\n<p>对于  <code>As</code>  缓存，其分配的空间能够存储 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>B</mi><mi>M</mi><mo>×</mo><mi>B</mi><mi>K</mi></mrow><annotation encoding=\"application/x-tex\">BM\\times BK</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.7667em;vertical-align:-0.0833em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.10903em;\">BM</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span><span class=\"mbin\">×</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.6833em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.05017em;\">B</span><span class=\"mord mathnormal\" style=\"margin-right:0.07153em;\">K</span></span></span></span> 个浮点数，在一个 block 中共有 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mo stretchy=\"false\">(</mo><mi>B</mi><mi>M</mi><mi mathvariant=\"normal\">/</mi><mi>T</mi><mi>M</mi><mo stretchy=\"false\">)</mo><mo>×</mo><mo stretchy=\"false\">(</mo><mi>B</mi><mi>N</mi><mi mathvariant=\"normal\">/</mi><mi>T</mi><mi>N</mi><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">(BM/TM)\\times (BN/TN)</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mopen\">(</span><span class=\"mord mathnormal\" style=\"margin-right:0.10903em;\">BM</span><span class=\"mord\">/</span><span class=\"mord mathnormal\" style=\"margin-right:0.10903em;\">TM</span><span class=\"mclose\">)</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span><span class=\"mbin\">×</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mopen\">(</span><span class=\"mord mathnormal\" style=\"margin-right:0.10903em;\">BN</span><span class=\"mord\">/</span><span class=\"mord mathnormal\" style=\"margin-right:0.10903em;\">TN</span><span class=\"mclose\">)</span></span></span></span> 个线程，每个线程一次读取 4 个浮点数，那么总共需要读取 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mfrac><mrow><mi>B</mi><mi>M</mi><mo>×</mo><mi>B</mi><mi>K</mi></mrow><mrow><mi>B</mi><mi>M</mi><mi mathvariant=\"normal\">/</mi><mi>T</mi><mi>M</mi><mo>×</mo><mi>B</mi><mi>N</mi><mi mathvariant=\"normal\">/</mi><mi>T</mi><mi>N</mi><mo>×</mo><mn>4</mn></mrow></mfrac></mrow><annotation encoding=\"application/x-tex\">\\frac{BM\\times BK}{BM/TM\\times BN/TN \\times 4}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1.3923em;vertical-align:-0.52em;\"></span><span class=\"mord\"><span class=\"mopen nulldelimiter\"></span><span class=\"mfrac\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8723em;\"><span style=\"top:-2.655em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.10903em;\">BM</span><span class=\"mord mtight\">/</span><span class=\"mord mathnormal mtight\" style=\"margin-right:0.10903em;\">TM</span><span class=\"mbin mtight\">×</span><span class=\"mord mathnormal mtight\" style=\"margin-right:0.10903em;\">BN</span><span class=\"mord mtight\">/</span><span class=\"mord mathnormal mtight\" style=\"margin-right:0.10903em;\">TN</span><span class=\"mbin mtight\">×</span><span class=\"mord mtight\">4</span></span></span></span><span style=\"top:-3.23em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"frac-line\" style=\"border-bottom-width:0.04em;\"></span></span><span style=\"top:-3.394em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.10903em;\">BM</span><span class=\"mbin mtight\">×</span><span class=\"mord mathnormal mtight\" style=\"margin-right:0.05017em;\">B</span><span class=\"mord mathnormal mtight\" style=\"margin-right:0.07153em;\">K</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.52em;\"><span></span></span></span></span></span><span class=\"mclose nulldelimiter\"></span></span></span></span></span> 次；同理， <code>Bs</code>  缓存需要读取 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mfrac><mrow><mi>B</mi><mi>K</mi><mo>×</mo><mi>B</mi><mi>N</mi></mrow><mrow><mi>B</mi><mi>M</mi><mi mathvariant=\"normal\">/</mi><mi>T</mi><mi>M</mi><mo>×</mo><mi>B</mi><mi>N</mi><mi mathvariant=\"normal\">/</mi><mi>T</mi><mi>N</mi><mo>×</mo><mn>4</mn></mrow></mfrac></mrow><annotation encoding=\"application/x-tex\">\\frac{BK\\times BN}{BM/TM\\times BN/TN \\times 4}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1.3923em;vertical-align:-0.52em;\"></span><span class=\"mord\"><span class=\"mopen nulldelimiter\"></span><span class=\"mfrac\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8723em;\"><span style=\"top:-2.655em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.10903em;\">BM</span><span class=\"mord mtight\">/</span><span class=\"mord mathnormal mtight\" style=\"margin-right:0.10903em;\">TM</span><span class=\"mbin mtight\">×</span><span class=\"mord mathnormal mtight\" style=\"margin-right:0.10903em;\">BN</span><span class=\"mord mtight\">/</span><span class=\"mord mathnormal mtight\" style=\"margin-right:0.10903em;\">TN</span><span class=\"mbin mtight\">×</span><span class=\"mord mtight\">4</span></span></span></span><span style=\"top:-3.23em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"frac-line\" style=\"border-bottom-width:0.04em;\"></span></span><span style=\"top:-3.394em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.05017em;\">B</span><span class=\"mord mathnormal mtight\" style=\"margin-right:0.07153em;\">K</span><span class=\"mbin mtight\">×</span><span class=\"mord mathnormal mtight\" style=\"margin-right:0.10903em;\">BN</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.52em;\"><span></span></span></span></span></span><span class=\"mclose nulldelimiter\"></span></span></span></span></span>。</p>\n<figure class=\"highlight c\"><figcaption data-lang=\"c\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre><span class=\"token keyword\">const</span> <span class=\"token keyword\">int</span> block_row_thread <span class=\"token operator\">=</span> BN <span class=\"token operator\">/</span> TN<span class=\"token punctuation\">;</span>  </pre></td></tr><tr><td data-num=\"2\"></td><td><pre><span class=\"token keyword\">const</span> <span class=\"token keyword\">int</span> block_col_thread <span class=\"token operator\">=</span> BM <span class=\"token operator\">/</span> TM<span class=\"token punctuation\">;</span>  </pre></td></tr><tr><td data-num=\"3\"></td><td><pre><span class=\"token keyword\">const</span> <span class=\"token keyword\">int</span> thread_num <span class=\"token operator\">=</span> block_row_thread <span class=\"token operator\">*</span> block_col_thread<span class=\"token punctuation\">;</span></pre></td></tr><tr><td data-num=\"4\"></td><td><pre><span class=\"token keyword\">const</span> <span class=\"token keyword\">int</span> load_a_cache_time <span class=\"token operator\">=</span> <span class=\"token punctuation\">(</span>BK <span class=\"token operator\">*</span> BM<span class=\"token punctuation\">)</span> <span class=\"token operator\">/</span> thread_num <span class=\"token operator\">/</span> <span class=\"token number\">4</span><span class=\"token punctuation\">;</span>  <span class=\"token comment\">// Each thread load 4 float</span></pre></td></tr><tr><td data-num=\"5\"></td><td><pre><span class=\"token keyword\">const</span> <span class=\"token keyword\">int</span> load_b_cache_time <span class=\"token operator\">=</span> <span class=\"token punctuation\">(</span>BK <span class=\"token operator\">*</span> BN<span class=\"token punctuation\">)</span> <span class=\"token operator\">/</span> thread_num <span class=\"token operator\">/</span> <span class=\"token number\">4</span><span class=\"token punctuation\">;</span>  <span class=\"token comment\">// Each thread load 4 float</span></pre></td></tr></table></figure><p><img loading=\"lazy\" data-src=\"/images/cuda/SGEMM-optimization/float4-kernel.png\" alt=\"使用 float4 访存\"></p>\n<p>如上图所示，假设 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>B</mi><mi>K</mi><mo>=</mo><mn>16</mn></mrow><annotation encoding=\"application/x-tex\">BK=16</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.6833em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.05017em;\">B</span><span class=\"mord mathnormal\" style=\"margin-right:0.07153em;\">K</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.6444em;\"></span><span class=\"mord\">16</span></span></span></span>，共有 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mn>8</mn></mrow><annotation encoding=\"application/x-tex\">8</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.6444em;\"></span><span class=\"mord\">8</span></span></span></span> 个线程，那么一次读取就能够读完  <code>As</code>  中的两行。那么每个线程下一次读取时间隔的行数就是 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mn>8</mn><mi mathvariant=\"normal\">/</mi><mo stretchy=\"false\">(</mo><mi>B</mi><mi>K</mi><mi mathvariant=\"normal\">/</mi><mn>4</mn><mo stretchy=\"false\">)</mo><mo>=</mo><mn>2</mn></mrow><annotation encoding=\"application/x-tex\">8/(BK/4)=2</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord\">8/</span><span class=\"mopen\">(</span><span class=\"mord mathnormal\" style=\"margin-right:0.05017em;\">B</span><span class=\"mord mathnormal\" style=\"margin-right:0.07153em;\">K</span><span class=\"mord\">/4</span><span class=\"mclose\">)</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.6444em;\"></span><span class=\"mord\">2</span></span></span></span>。</p>\n<p>其实，我们不妨把  <code>As</code>  看成一个矩阵元素是  <code>float4</code>  的矩阵，那么原来的  <code>As</code>  就相当于一个大小为 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>B</mi><mi>M</mi><mo>×</mo><mo stretchy=\"false\">(</mo><mi>B</mi><mi>K</mi><mi mathvariant=\"normal\">/</mi><mn>4</mn><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">BM\\times (BK/4)</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.7667em;vertical-align:-0.0833em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.10903em;\">BM</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span><span class=\"mbin\">×</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mopen\">(</span><span class=\"mord mathnormal\" style=\"margin-right:0.05017em;\">B</span><span class=\"mord mathnormal\" style=\"margin-right:0.07153em;\">K</span><span class=\"mord\">/4</span><span class=\"mclose\">)</span></span></span></span> 大小的新矩阵  <code>As_new</code> 。那么，我们可以根据线程的  <code>id</code>  来计算其对应放置的地址偏移，我们不妨把线程看成一维的，这样更方便计算。</p>\n<p>首先，计算出线程的 id：</p>\n<figure class=\"highlight c\"><figcaption data-lang=\"c\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre><span class=\"token keyword\">int</span> thread_id <span class=\"token operator\">=</span> threadIdx<span class=\"token punctuation\">.</span>y <span class=\"token operator\">*</span> blockDim<span class=\"token punctuation\">.</span>x <span class=\"token operator\">+</span> threadIdx<span class=\"token punctuation\">.</span>x<span class=\"token punctuation\">;</span></pre></td></tr></table></figure><p><code>As</code>  中每一行需要 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>B</mi><mi>K</mi><mi mathvariant=\"normal\">/</mi><mn>4</mn></mrow><annotation encoding=\"application/x-tex\">BK/4</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.05017em;\">B</span><span class=\"mord mathnormal\" style=\"margin-right:0.07153em;\">K</span><span class=\"mord\">/4</span></span></span></span> 个线程读取，那么线程对应的行数为：</p>\n<figure class=\"highlight c\"><figcaption data-lang=\"c\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre><span class=\"token keyword\">int</span> a_tile_row <span class=\"token operator\">=</span> thread_id <span class=\"token operator\">/</span> <span class=\"token punctuation\">(</span>BK <span class=\"token operator\">/</span> <span class=\"token number\">4</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span></pre></td></tr></table></figure><p>同理，对应的列数为  <code>thread_id % (BK / 4)</code> 。不过这是  <code>As_new</code>  中地址便宜，换算回  <code>As</code>  还得乘 4，也就是：</p>\n<figure class=\"highlight c\"><figcaption data-lang=\"c\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre><span class=\"token keyword\">int</span> a_tile_col <span class=\"token operator\">=</span> thread_id <span class=\"token operator\">%</span> <span class=\"token punctuation\">(</span>BK <span class=\"token operator\">/</span> <span class=\"token number\">4</span><span class=\"token punctuation\">)</span> <span class=\"token operator\">*</span> <span class=\"token number\">4</span><span class=\"token punctuation\">;</span></pre></td></tr></table></figure><p>按照上述方式，我们也可以计算得出  <code>Bs</code>  的对应偏移：</p>\n<figure class=\"highlight c\"><figcaption data-lang=\"c\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre><span class=\"token keyword\">int</span> b_tile_row <span class=\"token operator\">=</span> thread_id <span class=\"token operator\">/</span> <span class=\"token punctuation\">(</span>BN <span class=\"token operator\">/</span> <span class=\"token number\">4</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>  </pre></td></tr><tr><td data-num=\"2\"></td><td><pre><span class=\"token keyword\">int</span> b_tile_col <span class=\"token operator\">=</span> thread_id <span class=\"token operator\">%</span> <span class=\"token punctuation\">(</span>BN <span class=\"token operator\">/</span> <span class=\"token number\">4</span><span class=\"token punctuation\">)</span> <span class=\"token operator\">*</span> <span class=\"token number\">4</span><span class=\"token punctuation\">;</span></pre></td></tr></table></figure><p>上述计算的地址是每次读取的子矩阵中的相对偏移，每次读取时，我们还需要添加一个基址偏移。对于  <code>As</code> ，共有 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>B</mi><mi>M</mi></mrow><annotation encoding=\"application/x-tex\">BM</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.6833em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.10903em;\">BM</span></span></span></span> 行，上面计算得到了共需要读取  <code>load_a_cache_time</code> ，那么可以知道每次需要偏移的大小为：</p>\n<figure class=\"highlight c\"><figcaption data-lang=\"c\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre><span class=\"token keyword\">int</span> a_tile_stride <span class=\"token operator\">=</span> BM <span class=\"token operator\">/</span> load_a_cache_time<span class=\"token punctuation\">;</span></pre></td></tr></table></figure><p>同理， <code>Bs</code>  中的对应大小为：</p>\n<figure class=\"highlight c\"><figcaption data-lang=\"c\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre><span class=\"token keyword\">int</span> b_tile_stride <span class=\"token operator\">=</span> BK <span class=\"token operator\">/</span> load_b_cache_time<span class=\"token punctuation\">;</span></pre></td></tr></table></figure><p>在读取  <code>As</code>  时，注意还需要对其进行转置，其代码如下：</p>\n<figure class=\"highlight c\"><figcaption data-lang=\"c\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre><span class=\"token keyword\">for</span> <span class=\"token punctuation\">(</span><span class=\"token keyword\">int</span> i <span class=\"token operator\">=</span> <span class=\"token number\">0</span><span class=\"token punctuation\">;</span> i <span class=\"token operator\">&lt;</span> BM<span class=\"token punctuation\">;</span> i <span class=\"token operator\">+=</span> a_tile_stride<span class=\"token punctuation\">)</span> <span class=\"token punctuation\">&#123;</span>  </pre></td></tr><tr><td data-num=\"2\"></td><td><pre>    <span class=\"token keyword\">int</span> cache_idx <span class=\"token operator\">=</span> i <span class=\"token operator\">/</span> a_tile_stride <span class=\"token operator\">*</span> <span class=\"token number\">4</span><span class=\"token punctuation\">;</span>  </pre></td></tr><tr><td data-num=\"3\"></td><td><pre>    <span class=\"token function\">FETCH_FLOAT4</span><span class=\"token punctuation\">(</span>load_a_cache<span class=\"token punctuation\">[</span>cache_idx<span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span> <span class=\"token operator\">=</span>  </pre></td></tr><tr><td data-num=\"4\"></td><td><pre>            <span class=\"token function\">FETCH_FLOAT4</span><span class=\"token punctuation\">(</span>A<span class=\"token punctuation\">[</span><span class=\"token function\">OFFSET</span><span class=\"token punctuation\">(</span>a_tile_row <span class=\"token operator\">+</span> i<span class=\"token punctuation\">,</span> a_tile_col<span class=\"token punctuation\">,</span> K<span class=\"token punctuation\">)</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>  </pre></td></tr><tr><td data-num=\"5\"></td><td><pre>    <span class=\"token comment\">// Use load_a_cache for load 4 float at a time  </span></pre></td></tr><tr><td data-num=\"6\"></td><td><pre>    <span class=\"token comment\">// As is saved as transpose matrix  </span></pre></td></tr><tr><td data-num=\"7\"></td><td><pre>    As<span class=\"token punctuation\">[</span>a_tile_col<span class=\"token punctuation\">]</span><span class=\"token punctuation\">[</span>a_tile_row <span class=\"token operator\">+</span> i<span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> load_a_cache<span class=\"token punctuation\">[</span>cache_idx<span class=\"token punctuation\">]</span><span class=\"token punctuation\">;</span>  </pre></td></tr><tr><td data-num=\"8\"></td><td><pre>    As<span class=\"token punctuation\">[</span>a_tile_col <span class=\"token operator\">+</span> <span class=\"token number\">1</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">[</span>a_tile_row <span class=\"token operator\">+</span> i<span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> load_a_cache<span class=\"token punctuation\">[</span>cache_idx <span class=\"token operator\">+</span> <span class=\"token number\">1</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">;</span>  </pre></td></tr><tr><td data-num=\"9\"></td><td><pre>    As<span class=\"token punctuation\">[</span>a_tile_col <span class=\"token operator\">+</span> <span class=\"token number\">2</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">[</span>a_tile_row <span class=\"token operator\">+</span> i<span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> load_a_cache<span class=\"token punctuation\">[</span>cache_idx <span class=\"token operator\">+</span> <span class=\"token number\">2</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">;</span>  </pre></td></tr><tr><td data-num=\"10\"></td><td><pre>    As<span class=\"token punctuation\">[</span>a_tile_col <span class=\"token operator\">+</span> <span class=\"token number\">3</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">[</span>a_tile_row <span class=\"token operator\">+</span> i<span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> load_a_cache<span class=\"token punctuation\">[</span>cache_idx <span class=\"token operator\">+</span> <span class=\"token number\">3</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">;</span>  </pre></td></tr><tr><td data-num=\"11\"></td><td><pre><span class=\"token punctuation\">&#125;</span></pre></td></tr></table></figure><p>这里开辟了一个寄存器缓存  <code>load_a_cache</code> ，作为转置时的临时存放空间，其大小为  <code>load_a_cache_time * 4</code> 。注意下面为每次读取单独开辟了空间存储，而不是复用之前的空间。我在测试的时候发现，如果复用之前的空间，会因为数据写入地址的依赖导致计算结果出错。</p>\n<figure class=\"highlight c\"><figcaption data-lang=\"c\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre><span class=\"token keyword\">float</span> load_a_cache<span class=\"token punctuation\">[</span><span class=\"token number\">4</span> <span class=\"token operator\">*</span> load_a_cache_time<span class=\"token punctuation\">]</span><span class=\"token punctuation\">;</span></pre></td></tr></table></figure><p>每次读取时，<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>A</mi></mrow><annotation encoding=\"application/x-tex\">A</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.6833em;\"></span><span class=\"mord mathnormal\">A</span></span></span></span> 矩阵的基础行偏移量为循环变量中的  <code>i</code> ，其每次变化  <code>a_tile_stride</code> ，在此基础之上，每个线程本身还需要添加一个行偏移量  <code>a_tile_row</code> ，和列偏移量  <code>a_tile_col</code> 。每次读取 4 个元素，将其存放在  <code>load_a_cache</code>  中的对应位置， <code>cache_idx</code>  可以由  <code>i / a_tile_stride * 4</code>  计算得到， <code>i / a_tile_stride</code>  表示迭代的次数，乘 4 表示每次存放 4 个元素。</p>\n<p>读取之后，我们将  <code>load_a_cache</code>  中的元素转置存放在  <code>As</code>  中，注意下标的计算。</p>\n<p>类似地， <code>Bs</code>  的读取代码如下：</p>\n<figure class=\"highlight c\"><figcaption data-lang=\"c\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre><span class=\"token keyword\">for</span> <span class=\"token punctuation\">(</span><span class=\"token keyword\">int</span> i <span class=\"token operator\">=</span> <span class=\"token number\">0</span><span class=\"token punctuation\">;</span> i <span class=\"token operator\">&lt;</span> BK<span class=\"token punctuation\">;</span> i <span class=\"token operator\">+=</span> b_tile_stride<span class=\"token punctuation\">)</span> <span class=\"token punctuation\">&#123;</span>  </pre></td></tr><tr><td data-num=\"2\"></td><td><pre>    <span class=\"token function\">FETCH_FLOAT4</span><span class=\"token punctuation\">(</span>Bs<span class=\"token punctuation\">[</span>b_tile_row <span class=\"token operator\">+</span> i<span class=\"token punctuation\">]</span><span class=\"token punctuation\">[</span>b_tile_col<span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span> <span class=\"token operator\">=</span>  </pre></td></tr><tr><td data-num=\"3\"></td><td><pre>            <span class=\"token function\">FETCH_FLOAT4</span><span class=\"token punctuation\">(</span>B<span class=\"token punctuation\">[</span><span class=\"token function\">OFFSET</span><span class=\"token punctuation\">(</span>b_tile_row <span class=\"token operator\">+</span> i<span class=\"token punctuation\">,</span> b_tile_col<span class=\"token punctuation\">,</span> N<span class=\"token punctuation\">)</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>  </pre></td></tr><tr><td data-num=\"4\"></td><td><pre><span class=\"token punctuation\">&#125;</span></pre></td></tr></table></figure><p>因为  <code>Bs</code>  不需要转置，我们可以直接将其存放在  <code>Bs</code>  对应位置中。</p>\n<p>注意上述代码中的  <code>A</code>  和  <code>B</code>  都预先添加了偏移量， <code>C</code>  也是：</p>\n<figure class=\"highlight c\"><figcaption data-lang=\"c\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre>A <span class=\"token operator\">=</span> <span class=\"token operator\">&amp;</span>A<span class=\"token punctuation\">[</span><span class=\"token function\">OFFSET</span><span class=\"token punctuation\">(</span>blockIdx<span class=\"token punctuation\">.</span>x <span class=\"token operator\">*</span> BN<span class=\"token punctuation\">;</span><span class=\"token punctuation\">,</span> <span class=\"token number\">0</span><span class=\"token punctuation\">,</span> K<span class=\"token punctuation\">)</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">;</span> <span class=\"token comment\">// Set block start position  </span></pre></td></tr><tr><td data-num=\"2\"></td><td><pre>B <span class=\"token operator\">=</span> <span class=\"token operator\">&amp;</span>B<span class=\"token punctuation\">[</span><span class=\"token function\">OFFSET</span><span class=\"token punctuation\">(</span><span class=\"token number\">0</span><span class=\"token punctuation\">,</span> blockIdx<span class=\"token punctuation\">.</span>y <span class=\"token operator\">*</span> BM<span class=\"token punctuation\">;</span><span class=\"token punctuation\">,</span> N<span class=\"token punctuation\">)</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">;</span>  </pre></td></tr><tr><td data-num=\"3\"></td><td><pre>C <span class=\"token operator\">=</span> <span class=\"token operator\">&amp;</span>C<span class=\"token punctuation\">[</span><span class=\"token function\">OFFSET</span><span class=\"token punctuation\">(</span>blockIdx<span class=\"token punctuation\">.</span>x <span class=\"token operator\">*</span> BN<span class=\"token punctuation\">,</span> blockIdx<span class=\"token punctuation\">.</span>y <span class=\"token operator\">*</span> BM<span class=\"token punctuation\">,</span> N<span class=\"token punctuation\">)</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">;</span></pre></td></tr></table></figure><p>后续的计算基本和二维 Tile 中的代码一致，只不过我们会一次性读取 4 个浮点数：</p>\n<figure class=\"highlight c\"><figcaption data-lang=\"c\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre><span class=\"token keyword\">for</span> <span class=\"token punctuation\">(</span><span class=\"token keyword\">int</span> i <span class=\"token operator\">=</span> <span class=\"token number\">0</span><span class=\"token punctuation\">;</span> i <span class=\"token operator\">&lt;</span> BK<span class=\"token punctuation\">;</span> <span class=\"token operator\">++</span>i<span class=\"token punctuation\">)</span> <span class=\"token punctuation\">&#123;</span>  </pre></td></tr><tr><td data-num=\"2\"></td><td><pre>    <span class=\"token keyword\">for</span> <span class=\"token punctuation\">(</span><span class=\"token keyword\">int</span> m <span class=\"token operator\">=</span> <span class=\"token number\">0</span><span class=\"token punctuation\">;</span> m <span class=\"token operator\">&lt;</span> TM<span class=\"token punctuation\">;</span> m <span class=\"token operator\">+=</span> <span class=\"token number\">4</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">&#123;</span>  </pre></td></tr><tr><td data-num=\"3\"></td><td><pre>        <span class=\"token function\">FETCH_FLOAT4</span><span class=\"token punctuation\">(</span>As_cache<span class=\"token punctuation\">[</span>m<span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span> <span class=\"token operator\">=</span> <span class=\"token function\">FETCH_FLOAT4</span><span class=\"token punctuation\">(</span>As<span class=\"token punctuation\">[</span>i<span class=\"token punctuation\">]</span><span class=\"token punctuation\">[</span>ty <span class=\"token operator\">+</span> m<span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>  </pre></td></tr><tr><td data-num=\"4\"></td><td><pre>    <span class=\"token punctuation\">&#125;</span>  </pre></td></tr><tr><td data-num=\"5\"></td><td><pre>    <span class=\"token keyword\">for</span> <span class=\"token punctuation\">(</span><span class=\"token keyword\">int</span> n <span class=\"token operator\">=</span> <span class=\"token number\">0</span><span class=\"token punctuation\">;</span> n <span class=\"token operator\">&lt;</span> TN<span class=\"token punctuation\">;</span> n <span class=\"token operator\">+=</span> <span class=\"token number\">4</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">&#123;</span>  </pre></td></tr><tr><td data-num=\"6\"></td><td><pre>        <span class=\"token function\">FETCH_FLOAT4</span><span class=\"token punctuation\">(</span>Bs_cache<span class=\"token punctuation\">[</span>n<span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span> <span class=\"token operator\">=</span> <span class=\"token function\">FETCH_FLOAT4</span><span class=\"token punctuation\">(</span>Bs<span class=\"token punctuation\">[</span>i<span class=\"token punctuation\">]</span><span class=\"token punctuation\">[</span>tx <span class=\"token operator\">+</span> n<span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>  </pre></td></tr><tr><td data-num=\"7\"></td><td><pre>    <span class=\"token punctuation\">&#125;</span>  </pre></td></tr><tr><td data-num=\"8\"></td><td><pre>    <span class=\"token keyword\">for</span> <span class=\"token punctuation\">(</span><span class=\"token keyword\">int</span> m <span class=\"token operator\">=</span> <span class=\"token number\">0</span><span class=\"token punctuation\">;</span> m <span class=\"token operator\">&lt;</span> TM<span class=\"token punctuation\">;</span> <span class=\"token operator\">++</span>m<span class=\"token punctuation\">)</span> <span class=\"token punctuation\">&#123;</span>  </pre></td></tr><tr><td data-num=\"9\"></td><td><pre>        <span class=\"token keyword\">for</span> <span class=\"token punctuation\">(</span><span class=\"token keyword\">int</span> n <span class=\"token operator\">=</span> <span class=\"token number\">0</span><span class=\"token punctuation\">;</span> n <span class=\"token operator\">&lt;</span> TN<span class=\"token punctuation\">;</span> <span class=\"token operator\">++</span>n<span class=\"token punctuation\">)</span> <span class=\"token punctuation\">&#123;</span>  </pre></td></tr><tr><td data-num=\"10\"></td><td><pre>            accum<span class=\"token punctuation\">[</span>m<span class=\"token punctuation\">]</span><span class=\"token punctuation\">[</span>n<span class=\"token punctuation\">]</span> <span class=\"token operator\">+=</span> As_cache<span class=\"token punctuation\">[</span>m<span class=\"token punctuation\">]</span> <span class=\"token operator\">*</span> Bs_cache<span class=\"token punctuation\">[</span>n<span class=\"token punctuation\">]</span><span class=\"token punctuation\">;</span>  </pre></td></tr><tr><td data-num=\"11\"></td><td><pre>        <span class=\"token punctuation\">&#125;</span>  </pre></td></tr><tr><td data-num=\"12\"></td><td><pre>    <span class=\"token punctuation\">&#125;</span>  </pre></td></tr><tr><td data-num=\"13\"></td><td><pre><span class=\"token punctuation\">&#125;</span></pre></td></tr></table></figure><div class=\"note info\">\n<p>注意本文的所有  <code>for</code>  循环代码中，为了简洁，去掉了每个  <code>for</code>  循环上的  <code>#pragma unroll</code>  循环展开指令。实际中可以添加该指令进一步提升指令吞吐。</p>\n</div>\n<p>后续写回结果，也可以使用  <code>float4</code>  来减少访存次数：</p>\n<figure class=\"highlight c\"><figcaption data-lang=\"c\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre><span class=\"token keyword\">float</span> tmp<span class=\"token punctuation\">[</span><span class=\"token number\">4</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> <span class=\"token punctuation\">&#123;</span><span class=\"token number\">0.</span><span class=\"token punctuation\">&#125;</span><span class=\"token punctuation\">;</span>  </pre></td></tr><tr><td data-num=\"2\"></td><td><pre><span class=\"token keyword\">for</span> <span class=\"token punctuation\">(</span><span class=\"token keyword\">int</span> m <span class=\"token operator\">=</span> <span class=\"token number\">0</span><span class=\"token punctuation\">;</span> m <span class=\"token operator\">&lt;</span> TM<span class=\"token punctuation\">;</span> <span class=\"token operator\">++</span>m<span class=\"token punctuation\">)</span> <span class=\"token punctuation\">&#123;</span>  </pre></td></tr><tr><td data-num=\"3\"></td><td><pre>    <span class=\"token keyword\">for</span> <span class=\"token punctuation\">(</span><span class=\"token keyword\">int</span> n <span class=\"token operator\">=</span> <span class=\"token number\">0</span><span class=\"token punctuation\">;</span> n <span class=\"token operator\">&lt;</span> TN<span class=\"token punctuation\">;</span> n <span class=\"token operator\">+=</span> <span class=\"token number\">4</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">&#123;</span>  </pre></td></tr><tr><td data-num=\"4\"></td><td><pre>        <span class=\"token function\">FETCH_FLOAT4</span><span class=\"token punctuation\">(</span>tmp<span class=\"token punctuation\">)</span> <span class=\"token operator\">=</span> <span class=\"token function\">FETCH_FLOAT4</span><span class=\"token punctuation\">(</span>C<span class=\"token punctuation\">[</span><span class=\"token function\">OFFSET</span><span class=\"token punctuation\">(</span>ty <span class=\"token operator\">+</span> m<span class=\"token punctuation\">,</span> tx <span class=\"token operator\">+</span> n<span class=\"token punctuation\">,</span> N<span class=\"token punctuation\">)</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>  </pre></td></tr><tr><td data-num=\"5\"></td><td><pre>        tmp<span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> alpha <span class=\"token operator\">*</span> accum<span class=\"token punctuation\">[</span>m<span class=\"token punctuation\">]</span><span class=\"token punctuation\">[</span>n<span class=\"token punctuation\">]</span> <span class=\"token operator\">+</span> beta <span class=\"token operator\">*</span> tmp<span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">;</span>  </pre></td></tr><tr><td data-num=\"6\"></td><td><pre>        tmp<span class=\"token punctuation\">[</span><span class=\"token number\">1</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> alpha <span class=\"token operator\">*</span> accum<span class=\"token punctuation\">[</span>m<span class=\"token punctuation\">]</span><span class=\"token punctuation\">[</span>n <span class=\"token operator\">+</span> <span class=\"token number\">1</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">+</span> beta <span class=\"token operator\">*</span> tmp<span class=\"token punctuation\">[</span><span class=\"token number\">1</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">;</span>  </pre></td></tr><tr><td data-num=\"7\"></td><td><pre>        tmp<span class=\"token punctuation\">[</span><span class=\"token number\">2</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> alpha <span class=\"token operator\">*</span> accum<span class=\"token punctuation\">[</span>m<span class=\"token punctuation\">]</span><span class=\"token punctuation\">[</span>n <span class=\"token operator\">+</span> <span class=\"token number\">2</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">+</span> beta <span class=\"token operator\">*</span> tmp<span class=\"token punctuation\">[</span><span class=\"token number\">2</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">;</span>  </pre></td></tr><tr><td data-num=\"8\"></td><td><pre>        tmp<span class=\"token punctuation\">[</span><span class=\"token number\">3</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> alpha <span class=\"token operator\">*</span> accum<span class=\"token punctuation\">[</span>m<span class=\"token punctuation\">]</span><span class=\"token punctuation\">[</span>n <span class=\"token operator\">+</span> <span class=\"token number\">3</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">+</span> beta <span class=\"token operator\">*</span> tmp<span class=\"token punctuation\">[</span><span class=\"token number\">3</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">;</span>  </pre></td></tr><tr><td data-num=\"9\"></td><td><pre>        <span class=\"token function\">FETCH_FLOAT4</span><span class=\"token punctuation\">(</span>C<span class=\"token punctuation\">[</span><span class=\"token function\">OFFSET</span><span class=\"token punctuation\">(</span>ty <span class=\"token operator\">+</span> m<span class=\"token punctuation\">,</span> tx <span class=\"token operator\">+</span> n<span class=\"token punctuation\">,</span> N<span class=\"token punctuation\">)</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span> <span class=\"token operator\">=</span> <span class=\"token function\">FETCH_FLOAT4</span><span class=\"token punctuation\">(</span>tmp<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>  </pre></td></tr><tr><td data-num=\"10\"></td><td><pre>    <span class=\"token punctuation\">&#125;</span>  </pre></td></tr><tr><td data-num=\"11\"></td><td><pre><span class=\"token punctuation\">&#125;</span></pre></td></tr></table></figure><p>性能对比如下：</p>\n<p><img loading=\"lazy\" data-src=\"/images/cuda/SGEMM-optimization/kernel-performance/kernel-float4.png\" alt=\"float4 kernel\"></p>\n<p>可以看到，使用  <code>float4</code>  访存之后性能得到了很大的提升。每个线程的计算量并没有改变，但是现在每次可以读取 4 个浮点数，全局内存访问次数进一步降低了四分之一。而且指令的执行效率也提升。相比于访存 4 次获取 4 个浮点数，通过  <code>float4</code>  向量内存指令所需的访存指令数更少，减少了对内存访问的竞争；另一方面，使用矢量加载每个字节需要的索引计算更少。这些是隐形的对性能的提升。</p>\n<p><img loading=\"lazy\" data-src=\"/images/cuda/SGEMM-optimization/float4-kernel-warp-state.png\" alt=\"float4 kernel warp state\"></p>\n<p>从 profiling 结果可以看到，通过使用  <code>float4</code>  访存基本上消除了  <code>MIO</code>  的延迟。图中的其他指标的延迟也在 1~1.5 cycles per instruction 之间。</p>\n<h3 id=\"数据预取\"><a class=\"markdownIt-Anchor\" href=\"#数据预取\">#</a> 数据预取</h3>\n<p>在上文的代码中，我们在循环中使用了两次  <code>__syncthreads()</code>  来做线程同步，以防止不同线程之间的数据不一致。其中第一个  <code>__syncthreads()</code>  是为了保证写后读（Read-After-Write）的顺序性，这个是无法避免的。</p>\n<p>关键在于后一个同步，它是为了防止部分线程还未读取  <code>As</code>  或者  <code>Bs</code>  中的内容，保证读后写（Write-After-Read）的顺序性。它本质上是因为我们在不同迭代中使用了同一块空间来保存我们所需的数据，这两次迭代中的数据之间并不存在真正的依赖关系。如果我们将其写入到其他地址上，那么就不需要使用同步了。</p>\n<p>这种方式称为数据预取，又可以称为双缓存（Double Buffering）。我们可以申请两倍所需的空间，用于在迭代中交替使用，从而省去后一次线程同步的操作。</p>\n<figure class=\"highlight c\"><figcaption data-lang=\"c\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre>__shared__ <span class=\"token keyword\">float</span> As<span class=\"token punctuation\">[</span><span class=\"token number\">2</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">[</span>BK<span class=\"token punctuation\">]</span><span class=\"token punctuation\">[</span>BM<span class=\"token punctuation\">]</span><span class=\"token punctuation\">;</span>    <span class=\"token comment\">// transpose shared A for avoid bank conflict, for double buffering  </span></pre></td></tr><tr><td data-num=\"2\"></td><td><pre>__shared__ <span class=\"token keyword\">float</span> Bs<span class=\"token punctuation\">[</span><span class=\"token number\">2</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">[</span>BK<span class=\"token punctuation\">]</span><span class=\"token punctuation\">[</span>BN<span class=\"token punctuation\">]</span><span class=\"token punctuation\">;</span>    <span class=\"token comment\">// for double buffering</span></pre></td></tr><tr><td data-num=\"3\"></td><td><pre></pre></td></tr><tr><td data-num=\"4\"></td><td><pre><span class=\"token keyword\">float</span> As_cache<span class=\"token punctuation\">[</span><span class=\"token number\">2</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">[</span>TM<span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> <span class=\"token punctuation\">&#123;</span><span class=\"token number\">0.</span><span class=\"token punctuation\">&#125;</span><span class=\"token punctuation\">;</span>  <span class=\"token comment\">// double buffering  </span></pre></td></tr><tr><td data-num=\"5\"></td><td><pre><span class=\"token keyword\">float</span> Bs_cache<span class=\"token punctuation\">[</span><span class=\"token number\">2</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">[</span>TN<span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> <span class=\"token punctuation\">&#123;</span><span class=\"token number\">0.</span><span class=\"token punctuation\">&#125;</span><span class=\"token punctuation\">;</span>  <span class=\"token comment\">// double buffering</span></pre></td></tr></table></figure><p>在迭代中，我们可以使用一个变量来控制写入的地址：</p>\n<figure class=\"highlight c\"><figcaption data-lang=\"c\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre><span class=\"token keyword\">int</span> write_idx <span class=\"token operator\">=</span> <span class=\"token number\">0</span><span class=\"token punctuation\">;</span></pre></td></tr><tr><td data-num=\"2\"></td><td><pre></pre></td></tr><tr><td data-num=\"3\"></td><td><pre><span class=\"token keyword\">for</span> <span class=\"token punctuation\">(</span><span class=\"token keyword\">int</span> k <span class=\"token operator\">=</span> <span class=\"token number\">0</span><span class=\"token punctuation\">;</span> k <span class=\"token operator\">&lt;</span> K<span class=\"token punctuation\">;</span> k <span class=\"token operator\">+=</span> BK<span class=\"token punctuation\">)</span> <span class=\"token punctuation\">&#123;</span>  </pre></td></tr><tr><td data-num=\"4\"></td><td><pre>    <span class=\"token keyword\">for</span> <span class=\"token punctuation\">(</span><span class=\"token keyword\">int</span> i <span class=\"token operator\">=</span> <span class=\"token number\">0</span><span class=\"token punctuation\">;</span> i <span class=\"token operator\">&lt;</span> BM<span class=\"token punctuation\">;</span> i <span class=\"token operator\">+=</span> a_tile_stride<span class=\"token punctuation\">)</span> <span class=\"token punctuation\">&#123;</span>  </pre></td></tr><tr><td data-num=\"5\"></td><td><pre>        <span class=\"token keyword\">int</span> cache_idx <span class=\"token operator\">=</span> i <span class=\"token operator\">/</span> a_tile_stride <span class=\"token operator\">*</span> <span class=\"token number\">4</span><span class=\"token punctuation\">;</span>  </pre></td></tr><tr><td data-num=\"6\"></td><td><pre>        <span class=\"token function\">FETCH_FLOAT4</span><span class=\"token punctuation\">(</span>load_a_cache<span class=\"token punctuation\">[</span>cache_idx<span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span> <span class=\"token operator\">=</span>  </pre></td></tr><tr><td data-num=\"7\"></td><td><pre>                <span class=\"token function\">FETCH_FLOAT4</span><span class=\"token punctuation\">(</span>A<span class=\"token punctuation\">[</span><span class=\"token function\">OFFSET</span><span class=\"token punctuation\">(</span>a_tile_row <span class=\"token operator\">+</span> i<span class=\"token punctuation\">,</span> a_tile_col<span class=\"token punctuation\">,</span> K<span class=\"token punctuation\">)</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>  </pre></td></tr><tr><td data-num=\"8\"></td><td><pre>        <span class=\"token comment\">// Use load_a_cache for load 4 float at a time  </span></pre></td></tr><tr><td data-num=\"9\"></td><td><pre>        <span class=\"token comment\">// As is saved as transpose matrix  </span></pre></td></tr><tr><td data-num=\"10\"></td><td><pre>        As<span class=\"token punctuation\">[</span>write_idx<span class=\"token punctuation\">]</span><span class=\"token punctuation\">[</span>a_tile_col<span class=\"token punctuation\">]</span><span class=\"token punctuation\">[</span>a_tile_row <span class=\"token operator\">+</span> i<span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> load_a_cache<span class=\"token punctuation\">[</span>cache_idx<span class=\"token punctuation\">]</span><span class=\"token punctuation\">;</span>  </pre></td></tr><tr><td data-num=\"11\"></td><td><pre>        As<span class=\"token punctuation\">[</span>write_idx<span class=\"token punctuation\">]</span><span class=\"token punctuation\">[</span>a_tile_col <span class=\"token operator\">+</span> <span class=\"token number\">1</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">[</span>a_tile_row <span class=\"token operator\">+</span> i<span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> load_a_cache<span class=\"token punctuation\">[</span>cache_idx <span class=\"token operator\">+</span> <span class=\"token number\">1</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">;</span>  </pre></td></tr><tr><td data-num=\"12\"></td><td><pre>        As<span class=\"token punctuation\">[</span>write_idx<span class=\"token punctuation\">]</span><span class=\"token punctuation\">[</span>a_tile_col <span class=\"token operator\">+</span> <span class=\"token number\">2</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">[</span>a_tile_row <span class=\"token operator\">+</span> i<span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> load_a_cache<span class=\"token punctuation\">[</span>cache_idx <span class=\"token operator\">+</span> <span class=\"token number\">2</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">;</span>  </pre></td></tr><tr><td data-num=\"13\"></td><td><pre>        As<span class=\"token punctuation\">[</span>write_idx<span class=\"token punctuation\">]</span><span class=\"token punctuation\">[</span>a_tile_col <span class=\"token operator\">+</span> <span class=\"token number\">3</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">[</span>a_tile_row <span class=\"token operator\">+</span> i<span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> load_a_cache<span class=\"token punctuation\">[</span>cache_idx <span class=\"token operator\">+</span> <span class=\"token number\">3</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">;</span>  </pre></td></tr><tr><td data-num=\"14\"></td><td><pre>    <span class=\"token punctuation\">&#125;</span></pre></td></tr><tr><td data-num=\"15\"></td><td><pre>    <span class=\"token punctuation\">.</span><span class=\"token punctuation\">.</span><span class=\"token punctuation\">.</span></pre></td></tr><tr><td data-num=\"16\"></td><td><pre>    </pre></td></tr><tr><td data-num=\"17\"></td><td><pre>    <span class=\"token keyword\">for</span> <span class=\"token punctuation\">(</span><span class=\"token keyword\">int</span> i <span class=\"token operator\">=</span> <span class=\"token number\">0</span><span class=\"token punctuation\">;</span> i <span class=\"token operator\">&lt;</span> BK<span class=\"token punctuation\">;</span> i <span class=\"token operator\">+=</span> b_tile_stride<span class=\"token punctuation\">)</span> <span class=\"token punctuation\">&#123;</span>  </pre></td></tr><tr><td data-num=\"18\"></td><td><pre>    <span class=\"token function\">FETCH_FLOAT4</span><span class=\"token punctuation\">(</span>Bs<span class=\"token punctuation\">[</span>write_idx<span class=\"token punctuation\">]</span><span class=\"token punctuation\">[</span>b_tile_row <span class=\"token operator\">+</span> i<span class=\"token punctuation\">]</span><span class=\"token punctuation\">[</span>b_tile_col<span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span> <span class=\"token operator\">=</span>  </pre></td></tr><tr><td data-num=\"19\"></td><td><pre>            <span class=\"token function\">FETCH_FLOAT4</span><span class=\"token punctuation\">(</span>B<span class=\"token punctuation\">[</span><span class=\"token function\">OFFSET</span><span class=\"token punctuation\">(</span>b_tile_row <span class=\"token operator\">+</span> i<span class=\"token punctuation\">,</span> b_tile_col<span class=\"token punctuation\">,</span> N<span class=\"token punctuation\">)</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>  </pre></td></tr><tr><td data-num=\"20\"></td><td><pre>    <span class=\"token punctuation\">&#125;</span>  </pre></td></tr><tr><td data-num=\"21\"></td><td><pre>    <span class=\"token function\">__syncthreads</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span></pre></td></tr><tr><td data-num=\"22\"></td><td><pre>    </pre></td></tr><tr><td data-num=\"23\"></td><td><pre>    <span class=\"token punctuation\">.</span><span class=\"token punctuation\">.</span><span class=\"token punctuation\">.</span></pre></td></tr><tr><td data-num=\"24\"></td><td><pre>    </pre></td></tr><tr><td data-num=\"25\"></td><td><pre>    <span class=\"token keyword\">for</span> <span class=\"token punctuation\">(</span><span class=\"token keyword\">int</span> i <span class=\"token operator\">=</span> <span class=\"token number\">0</span><span class=\"token punctuation\">;</span> i <span class=\"token operator\">&lt;</span> BK<span class=\"token punctuation\">;</span> <span class=\"token operator\">++</span>i<span class=\"token punctuation\">)</span> <span class=\"token punctuation\">&#123;</span>  </pre></td></tr><tr><td data-num=\"26\"></td><td><pre>        <span class=\"token keyword\">for</span> <span class=\"token punctuation\">(</span><span class=\"token keyword\">int</span> m <span class=\"token operator\">=</span> <span class=\"token number\">0</span><span class=\"token punctuation\">;</span> m <span class=\"token operator\">&lt;</span> TM<span class=\"token punctuation\">;</span> m <span class=\"token operator\">+=</span> <span class=\"token number\">4</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">&#123;</span>  </pre></td></tr><tr><td data-num=\"27\"></td><td><pre>            <span class=\"token function\">FETCH_FLOAT4</span><span class=\"token punctuation\">(</span>As_cache<span class=\"token punctuation\">[</span>write_idx<span class=\"token punctuation\">]</span><span class=\"token punctuation\">[</span>m<span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span> <span class=\"token operator\">=</span> <span class=\"token function\">FETCH_FLOAT4</span><span class=\"token punctuation\">(</span>As<span class=\"token punctuation\">[</span>write_idx<span class=\"token punctuation\">]</span><span class=\"token punctuation\">[</span>i<span class=\"token punctuation\">]</span><span class=\"token punctuation\">[</span>ty <span class=\"token operator\">+</span> m<span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>  </pre></td></tr><tr><td data-num=\"28\"></td><td><pre>        <span class=\"token punctuation\">&#125;</span>  </pre></td></tr><tr><td data-num=\"29\"></td><td><pre>        <span class=\"token keyword\">for</span> <span class=\"token punctuation\">(</span><span class=\"token keyword\">int</span> n <span class=\"token operator\">=</span> <span class=\"token number\">0</span><span class=\"token punctuation\">;</span> n <span class=\"token operator\">&lt;</span> TN<span class=\"token punctuation\">;</span> n <span class=\"token operator\">+=</span> <span class=\"token number\">4</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">&#123;</span>  </pre></td></tr><tr><td data-num=\"30\"></td><td><pre>            <span class=\"token function\">FETCH_FLOAT4</span><span class=\"token punctuation\">(</span>Bs_cache<span class=\"token punctuation\">[</span>write_idx<span class=\"token punctuation\">]</span><span class=\"token punctuation\">[</span>n<span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span> <span class=\"token operator\">=</span> <span class=\"token function\">FETCH_FLOAT4</span><span class=\"token punctuation\">(</span>Bs<span class=\"token punctuation\">[</span>write_idx<span class=\"token punctuation\">]</span><span class=\"token punctuation\">[</span>i<span class=\"token punctuation\">]</span><span class=\"token punctuation\">[</span>tx <span class=\"token operator\">+</span> n<span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>  </pre></td></tr><tr><td data-num=\"31\"></td><td><pre>        <span class=\"token punctuation\">&#125;</span>  </pre></td></tr><tr><td data-num=\"32\"></td><td><pre>        <span class=\"token keyword\">for</span> <span class=\"token punctuation\">(</span><span class=\"token keyword\">int</span> m <span class=\"token operator\">=</span> <span class=\"token number\">0</span><span class=\"token punctuation\">;</span> m <span class=\"token operator\">&lt;</span> TM<span class=\"token punctuation\">;</span> <span class=\"token operator\">++</span>m<span class=\"token punctuation\">)</span> <span class=\"token punctuation\">&#123;</span>  </pre></td></tr><tr><td data-num=\"33\"></td><td><pre>            <span class=\"token keyword\">for</span> <span class=\"token punctuation\">(</span><span class=\"token keyword\">int</span> n <span class=\"token operator\">=</span> <span class=\"token number\">0</span><span class=\"token punctuation\">;</span> n <span class=\"token operator\">&lt;</span> TN<span class=\"token punctuation\">;</span> <span class=\"token operator\">++</span>n<span class=\"token punctuation\">)</span> <span class=\"token punctuation\">&#123;</span>  </pre></td></tr><tr><td data-num=\"34\"></td><td><pre>                accum<span class=\"token punctuation\">[</span>m<span class=\"token punctuation\">]</span><span class=\"token punctuation\">[</span>n<span class=\"token punctuation\">]</span> <span class=\"token operator\">+=</span> As_cache<span class=\"token punctuation\">[</span>write_idx<span class=\"token punctuation\">]</span><span class=\"token punctuation\">[</span>m<span class=\"token punctuation\">]</span> <span class=\"token operator\">*</span> Bs_cache<span class=\"token punctuation\">[</span>write_idx<span class=\"token punctuation\">]</span><span class=\"token punctuation\">[</span>n<span class=\"token punctuation\">]</span><span class=\"token punctuation\">;</span>  </pre></td></tr><tr><td data-num=\"35\"></td><td><pre>            <span class=\"token punctuation\">&#125;</span>  </pre></td></tr><tr><td data-num=\"36\"></td><td><pre>        <span class=\"token punctuation\">&#125;</span>  </pre></td></tr><tr><td data-num=\"37\"></td><td><pre>    <span class=\"token punctuation\">&#125;</span>  </pre></td></tr><tr><td data-num=\"38\"></td><td><pre>    </pre></td></tr><tr><td data-num=\"39\"></td><td><pre>    <span class=\"token punctuation\">.</span><span class=\"token punctuation\">.</span><span class=\"token punctuation\">.</span></pre></td></tr><tr><td data-num=\"40\"></td><td><pre>    </pre></td></tr><tr><td data-num=\"41\"></td><td><pre>    write_idx <span class=\"token operator\">^=</span> <span class=\"token number\">1</span><span class=\"token punctuation\">;</span></pre></td></tr><tr><td data-num=\"42\"></td><td><pre><span class=\"token punctuation\">&#125;</span></pre></td></tr></table></figure><p>性能对比如下：</p>\n<p><img loading=\"lazy\" data-src=\"/images/cuda/SGEMM-optimization/kernel-performance/kernel-double-buffer.png\" alt=\"double buffer kernel\"></p>\n<p>使用双缓冲之后，因为避免了多一次的线程同步，性能得到了进一步提升。</p>\n<h3 id=\"避免-shared-memory-bank-conflict\"><a class=\"markdownIt-Anchor\" href=\"#避免-shared-memory-bank-conflict\">#</a> 避免 Shared Memory Bank Conflict</h3>\n<p>经过以上的优化，我们的性能已经非常接近 cuBLAS 的基线了。</p>\n<p><img loading=\"lazy\" data-src=\"/images/cuda/SGEMM-optimization/kernel-performance/shared-memory-bank-conflict.png\" alt=\"shared memory bank conflict\"></p>\n<p>但是通过 profiling 可以看到，对共享内存的访问上有 40% 的 Uncoalsced Memory Access。这说明共享内存的访问上存在许多 bank conflict。我们可以使用这篇<a href=\"https://zhuanlan.zhihu.com/p/518857175\">矩阵优化笔记</a> 中的思路来解决这一问题。</p>\n<p>我们在通过 Tile 计算的过程中，计算的都是矩阵 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>C</mi></mrow><annotation encoding=\"application/x-tex\">C</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.6833em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.07153em;\">C</span></span></span></span> 中的连续区域的值，我们可以通过 interleaved 的方式，进一步对其分块<sup class=\"footnote-ref\"><a href=\"#fn2\" id=\"fnref2\">[2]</a></sup>：</p>\n<p><img loading=\"lazy\" data-src=\"/images/cuda/SGEMM-optimization/tile-to-avoid-shared-memory-bank-conflict.png\" alt=\"避免 shared memory bank conflict\"></p>\n<p>对应到代码中，我们从  <code>As</code>  和  <code>Bs</code>  中读取数据时，不再是连续的一整块数据，而是以 4 为单位间隔读取：</p>\n<figure class=\"highlight c\"><figcaption data-lang=\"c\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre><span class=\"token keyword\">for</span> <span class=\"token punctuation\">(</span><span class=\"token keyword\">int</span> k <span class=\"token operator\">=</span> <span class=\"token number\">0</span><span class=\"token punctuation\">;</span> k <span class=\"token operator\">&lt;</span> BK<span class=\"token punctuation\">;</span> <span class=\"token operator\">++</span>k<span class=\"token punctuation\">)</span> <span class=\"token punctuation\">&#123;</span>  </pre></td></tr><tr><td data-num=\"2\"></td><td><pre>    <span class=\"token keyword\">for</span> <span class=\"token punctuation\">(</span><span class=\"token keyword\">int</span> m <span class=\"token operator\">=</span> <span class=\"token number\">0</span><span class=\"token punctuation\">,</span> mm <span class=\"token operator\">=</span> <span class=\"token number\">0</span><span class=\"token punctuation\">;</span> m <span class=\"token operator\">&lt;</span> BM <span class=\"token operator\">&amp;&amp;</span> mm <span class=\"token operator\">&lt;</span> TM<span class=\"token punctuation\">;</span> m <span class=\"token operator\">+=</span> block_row_thread <span class=\"token operator\">*</span> <span class=\"token number\">4</span><span class=\"token punctuation\">,</span> mm <span class=\"token operator\">+=</span> <span class=\"token number\">4</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">&#123;</span>  </pre></td></tr><tr><td data-num=\"3\"></td><td><pre>        <span class=\"token keyword\">int</span> A_row <span class=\"token operator\">=</span> m <span class=\"token operator\">+</span> threadIdx<span class=\"token punctuation\">.</span>y <span class=\"token operator\">*</span> <span class=\"token number\">4</span><span class=\"token punctuation\">;</span>  </pre></td></tr><tr><td data-num=\"4\"></td><td><pre>        <span class=\"token function\">FETCH_FLOAT4</span><span class=\"token punctuation\">(</span>As_cache<span class=\"token punctuation\">[</span>write_idx<span class=\"token punctuation\">]</span><span class=\"token punctuation\">[</span>mm<span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span> <span class=\"token operator\">=</span> <span class=\"token function\">FETCH_FLOAT4</span><span class=\"token punctuation\">(</span>As<span class=\"token punctuation\">[</span>write_idx<span class=\"token punctuation\">]</span><span class=\"token punctuation\">[</span>k<span class=\"token punctuation\">]</span><span class=\"token punctuation\">[</span>A_row<span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>  </pre></td></tr><tr><td data-num=\"5\"></td><td><pre>    <span class=\"token punctuation\">&#125;</span>  </pre></td></tr><tr><td data-num=\"6\"></td><td><pre>    <span class=\"token keyword\">for</span> <span class=\"token punctuation\">(</span><span class=\"token keyword\">int</span> n <span class=\"token operator\">=</span> <span class=\"token number\">0</span><span class=\"token punctuation\">,</span> nn <span class=\"token operator\">=</span> <span class=\"token number\">0</span><span class=\"token punctuation\">;</span> n <span class=\"token operator\">&lt;</span> BN <span class=\"token operator\">&amp;&amp;</span> nn <span class=\"token operator\">&lt;</span> TN<span class=\"token punctuation\">;</span> n <span class=\"token operator\">+=</span> block_col_thread <span class=\"token operator\">*</span> <span class=\"token number\">4</span><span class=\"token punctuation\">,</span> nn <span class=\"token operator\">+=</span> <span class=\"token number\">4</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">&#123;</span>  </pre></td></tr><tr><td data-num=\"7\"></td><td><pre>        <span class=\"token keyword\">int</span> B_col <span class=\"token operator\">=</span> n <span class=\"token operator\">+</span> threadIdx<span class=\"token punctuation\">.</span>x <span class=\"token operator\">*</span> <span class=\"token number\">4</span><span class=\"token punctuation\">;</span>  </pre></td></tr><tr><td data-num=\"8\"></td><td><pre>        <span class=\"token function\">FETCH_FLOAT4</span><span class=\"token punctuation\">(</span>Bs_cache<span class=\"token punctuation\">[</span>write_idx<span class=\"token punctuation\">]</span><span class=\"token punctuation\">[</span>nn<span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span> <span class=\"token operator\">=</span> <span class=\"token function\">FETCH_FLOAT4</span><span class=\"token punctuation\">(</span>Bs<span class=\"token punctuation\">[</span>write_idx<span class=\"token punctuation\">]</span><span class=\"token punctuation\">[</span>k<span class=\"token punctuation\">]</span><span class=\"token punctuation\">[</span>B_col<span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>  </pre></td></tr><tr><td data-num=\"9\"></td><td><pre>    <span class=\"token punctuation\">&#125;</span></pre></td></tr><tr><td data-num=\"10\"></td><td><pre>    <span class=\"token punctuation\">.</span><span class=\"token punctuation\">.</span><span class=\"token punctuation\">.</span></pre></td></tr><tr><td data-num=\"11\"></td><td><pre><span class=\"token punctuation\">&#125;</span></pre></td></tr></table></figure><p>而在写回结果时也要注意对矩阵 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>C</mi></mrow><annotation encoding=\"application/x-tex\">C</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.6833em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.07153em;\">C</span></span></span></span> 的下标计算：</p>\n<figure class=\"highlight c\"><figcaption data-lang=\"c\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre><span class=\"token keyword\">for</span> <span class=\"token punctuation\">(</span><span class=\"token keyword\">int</span> m <span class=\"token operator\">=</span> <span class=\"token number\">0</span><span class=\"token punctuation\">;</span> m <span class=\"token operator\">&lt;</span> TM<span class=\"token punctuation\">;</span> m <span class=\"token operator\">+=</span> <span class=\"token number\">4</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">&#123;</span>  </pre></td></tr><tr><td data-num=\"2\"></td><td><pre>    <span class=\"token keyword\">int</span> C_row <span class=\"token operator\">=</span> <span class=\"token punctuation\">(</span>m <span class=\"token operator\">/</span> <span class=\"token number\">4</span><span class=\"token punctuation\">)</span> <span class=\"token operator\">*</span> <span class=\"token punctuation\">(</span>block_row_thread <span class=\"token operator\">*</span> <span class=\"token number\">4</span><span class=\"token punctuation\">)</span> <span class=\"token operator\">+</span> threadIdx<span class=\"token punctuation\">.</span>y <span class=\"token operator\">*</span> <span class=\"token number\">4</span><span class=\"token punctuation\">;</span>  </pre></td></tr><tr><td data-num=\"3\"></td><td><pre>    <span class=\"token keyword\">for</span> <span class=\"token punctuation\">(</span><span class=\"token keyword\">int</span> n <span class=\"token operator\">=</span> <span class=\"token number\">0</span><span class=\"token punctuation\">;</span> n <span class=\"token operator\">&lt;</span> TN<span class=\"token punctuation\">;</span> n <span class=\"token operator\">+=</span> <span class=\"token number\">4</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">&#123;</span>  </pre></td></tr><tr><td data-num=\"4\"></td><td><pre>        <span class=\"token keyword\">int</span> C_col <span class=\"token operator\">=</span> <span class=\"token punctuation\">(</span>n <span class=\"token operator\">/</span> <span class=\"token number\">4</span><span class=\"token punctuation\">)</span> <span class=\"token operator\">*</span> <span class=\"token punctuation\">(</span>block_col_thread <span class=\"token operator\">*</span> <span class=\"token number\">4</span><span class=\"token punctuation\">)</span> <span class=\"token operator\">+</span> threadIdx<span class=\"token punctuation\">.</span>x <span class=\"token operator\">*</span> <span class=\"token number\">4</span><span class=\"token punctuation\">;</span>  </pre></td></tr><tr><td data-num=\"5\"></td><td><pre>        <span class=\"token keyword\">for</span> <span class=\"token punctuation\">(</span><span class=\"token keyword\">int</span> i <span class=\"token operator\">=</span> <span class=\"token number\">0</span><span class=\"token punctuation\">;</span> i <span class=\"token operator\">&lt;</span> <span class=\"token number\">4</span><span class=\"token punctuation\">;</span> <span class=\"token operator\">++</span>i<span class=\"token punctuation\">)</span> <span class=\"token punctuation\">&#123;</span>  </pre></td></tr><tr><td data-num=\"6\"></td><td><pre>            <span class=\"token function\">FETCH_FLOAT4</span><span class=\"token punctuation\">(</span>load_a_cache<span class=\"token punctuation\">)</span> <span class=\"token operator\">=</span> <span class=\"token function\">FETCH_FLOAT4</span><span class=\"token punctuation\">(</span>C<span class=\"token punctuation\">[</span><span class=\"token function\">OFFSET</span><span class=\"token punctuation\">(</span>C_row <span class=\"token operator\">+</span> i<span class=\"token punctuation\">,</span> C_col<span class=\"token punctuation\">,</span> N<span class=\"token punctuation\">)</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>  </pre></td></tr><tr><td data-num=\"7\"></td><td><pre>            load_a_cache<span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> alpha <span class=\"token operator\">*</span> accum<span class=\"token punctuation\">[</span>m <span class=\"token operator\">+</span> i<span class=\"token punctuation\">]</span><span class=\"token punctuation\">[</span>n<span class=\"token punctuation\">]</span> <span class=\"token operator\">+</span> beta <span class=\"token operator\">*</span> load_a_cache<span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">;</span>  </pre></td></tr><tr><td data-num=\"8\"></td><td><pre>            load_a_cache<span class=\"token punctuation\">[</span><span class=\"token number\">1</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> alpha <span class=\"token operator\">*</span> accum<span class=\"token punctuation\">[</span>m <span class=\"token operator\">+</span> i<span class=\"token punctuation\">]</span><span class=\"token punctuation\">[</span>n <span class=\"token operator\">+</span> <span class=\"token number\">1</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">+</span> beta <span class=\"token operator\">*</span> load_a_cache<span class=\"token punctuation\">[</span><span class=\"token number\">1</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">;</span>  </pre></td></tr><tr><td data-num=\"9\"></td><td><pre>            load_a_cache<span class=\"token punctuation\">[</span><span class=\"token number\">2</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> alpha <span class=\"token operator\">*</span> accum<span class=\"token punctuation\">[</span>m <span class=\"token operator\">+</span> i<span class=\"token punctuation\">]</span><span class=\"token punctuation\">[</span>n <span class=\"token operator\">+</span> <span class=\"token number\">2</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">+</span> beta <span class=\"token operator\">*</span> load_a_cache<span class=\"token punctuation\">[</span><span class=\"token number\">2</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">;</span>  </pre></td></tr><tr><td data-num=\"10\"></td><td><pre>            load_a_cache<span class=\"token punctuation\">[</span><span class=\"token number\">3</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> alpha <span class=\"token operator\">*</span> accum<span class=\"token punctuation\">[</span>m <span class=\"token operator\">+</span> i<span class=\"token punctuation\">]</span><span class=\"token punctuation\">[</span>n <span class=\"token operator\">+</span> <span class=\"token number\">3</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">+</span> beta <span class=\"token operator\">*</span> load_a_cache<span class=\"token punctuation\">[</span><span class=\"token number\">3</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">;</span>  </pre></td></tr><tr><td data-num=\"11\"></td><td><pre>            <span class=\"token function\">FETCH_FLOAT4</span><span class=\"token punctuation\">(</span>C<span class=\"token punctuation\">[</span><span class=\"token function\">OFFSET</span><span class=\"token punctuation\">(</span>C_row <span class=\"token operator\">+</span> i<span class=\"token punctuation\">,</span> C_col<span class=\"token punctuation\">,</span> N<span class=\"token punctuation\">)</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span> <span class=\"token operator\">=</span> <span class=\"token function\">FETCH_FLOAT4</span><span class=\"token punctuation\">(</span>load_a_cache<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>  </pre></td></tr><tr><td data-num=\"12\"></td><td><pre>        <span class=\"token punctuation\">&#125;</span>  </pre></td></tr><tr><td data-num=\"13\"></td><td><pre>    <span class=\"token punctuation\">&#125;</span>  </pre></td></tr><tr><td data-num=\"14\"></td><td><pre><span class=\"token punctuation\">&#125;</span></pre></td></tr></table></figure><p><img loading=\"lazy\" data-src=\"/images/cuda/SGEMM-optimization/split-tile-1d-kernel.png\" alt=\"access pattern to avoid shared memory bank conflict\"></p>\n<p><code>m</code>  和  <code>n</code>  除以 4 是因为读取时以 4 个浮点数为一组读取，这 4 个浮点数对应的行是相邻的，每 4 行之后，就需要跳跃到下一个对应的位置，乘以  <code>(block_row_thread * 4)</code>  和  <code>(block_col_thread * 4)</code>  即是为此。</p>\n<p>在行和列上分别有  <code>block_row_thread</code>  和  <code>block_col_thread</code>  个线程，那么当前线程下一次操作的数据的行和列的起始位置就是  <code>(m / 4) * (block_row_thread * 4)</code>  和  <code>(n / 4) * (block_col_thread * 4)</code> 。</p>\n<p>最后，再添加当前线程自己在行和列上的偏移  <code>threadIdx.y * 4</code>  和  <code>threadIdx.x * 4</code> 。</p>\n<p>对于  <code>n</code>  可以使用  <code>float4</code>  的方式读取和写入，而对于  <code>m</code> ，我们需要再使用一层循环写入相邻的行中。</p>\n<p><img loading=\"lazy\" data-src=\"/images/cuda/SGEMM-optimization/kernel-performance/kernel-share-bank.png\" alt=\"kernel avoid shared memory bank conflict\"></p>\n<p>可以看到，在大矩阵上，现在的性能基本和 cuBLAS 持平了。我们也基本实现了我们的性能优化目标。</p>\n<h3 id=\"寄存器-bank-冲突\"><a class=\"markdownIt-Anchor\" href=\"#寄存器-bank-冲突\">#</a> 寄存器 bank 冲突</h3>\n<p>在处理共享内存 bank 冲突的基础之上，其实还能够进一步考虑处理寄存器的 bank 冲突<sup class=\"footnote-ref\"><a href=\"#fn3\" id=\"fnref3\">[3]</a></sup><sup class=\"footnote-ref\"><a href=\"#fn4\" id=\"fnref4\">[4]</a></sup>。不过这部分内容过于复杂，需要使用到  <code>SASS</code>  的 CUDA 汇编代码。这里就不去具体实现了，仅在这里记录一下。</p>\n<h2 id=\"性能对比总结\"><a class=\"markdownIt-Anchor\" href=\"#性能对比总结\">#</a> 性能对比总结</h2>\n<p>这里以 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mn>4096</mn><mo>×</mo><mn>4096</mn></mrow><annotation encoding=\"application/x-tex\">4096\\times 4096</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.7278em;vertical-align:-0.0833em;\"></span><span class=\"mord\">4096</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span><span class=\"mbin\">×</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.6444em;\"></span><span class=\"mord\">4096</span></span></span></span> 大小矩阵的性能总结各个优化和 cuBLAS 库的性能比较。</p>\n<table>\n<thead>\n<tr>\n<th>Kernel</th>\n<th>Ratio to cuBLAS</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>cublas</td>\n<td>1</td>\n</tr>\n<tr>\n<td>naive</td>\n<td>0.106</td>\n</tr>\n<tr>\n<td>shared memory</td>\n<td>0.091</td>\n</tr>\n<tr>\n<td>tile 1d</td>\n<td>0.158</td>\n</tr>\n<tr>\n<td>tile 2d</td>\n<td>0.352</td>\n</tr>\n<tr>\n<td>float4</td>\n<td>0.857</td>\n</tr>\n<tr>\n<td>double buffering</td>\n<td>0.912</td>\n</tr>\n<tr>\n<td>avoid shared memory bank conflict</td>\n<td>0.995</td>\n</tr>\n</tbody>\n</table>\n<h2 id=\"总结\"><a class=\"markdownIt-Anchor\" href=\"#总结\">#</a> 总结</h2>\n<p>这次国庆假期前前后后断断续续花费了 5 天完成了这篇优化笔记。前两天几乎全部花在代码编写上，后面三天断断续续完成了文章的内容。为了完成这篇内容，这期间参考了许多的笔记和资料<sup class=\"footnote-ref\"><a href=\"#fn5\" id=\"fnref5\">[5]</a></sup><sup class=\"footnote-ref\"><a href=\"#fn6\" id=\"fnref6\">[6]</a></sup><sup class=\"footnote-ref\"><a href=\"#fn7\" id=\"fnref7\">[7]</a></sup>，最后总算也得到了一个很好的优化结果。之前一直都是单纯的资料阅读，这次的实践确实收获颇丰，自己动手编写代码和直接调用别人的接口感觉确实有很大不同。CUDA 编程也需要了解更多的硬件相关的知识，这次实践中也了解了不少。“纸上得来终觉浅，绝知此事要躬行”。后续可能进一步考虑学习其他深度学习的重要算子的优化。</p>\n<p>本次的代码放在我的<a href=\"https://github.com/YangLinzhuo/cuda-sgemm-optimization/tree/main\">仓库</a>上了，可供参考。</p>\n<p>以上。</p>\n<h2 id=\"change-log\"><a class=\"markdownIt-Anchor\" href=\"#change-log\">#</a> Change Log</h2>\n<ul>\n<li>2023-10-14：补充 Nsight Compute profiling 结果，修正部分文本错误和措辞</li>\n<li>2023-10-15：重绘一些插图</li>\n</ul>\n<h2 id=\"附录\"><a class=\"markdownIt-Anchor\" href=\"#附录\">#</a> 附录</h2>\n<h3 id=\"clion-cuda-编程配置\"><a class=\"markdownIt-Anchor\" href=\"#clion-cuda-编程配置\">#</a> CLion CUDA 编程配置</h3>\n<p>使用 CLion 创建 CUDA 工程， <code>CMakeLists.txt</code>  内容如下：</p>\n<figure class=\"highlight cmake\"><figcaption data-lang=\"CMake\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre><span class=\"token keyword\">cmake_minimum_required</span><span class=\"token punctuation\">(</span><span class=\"token property\">VERSION</span> <span class=\"token number\">3.22</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"2\"></td><td><pre><span class=\"token keyword\">project</span><span class=\"token punctuation\">(</span>sgemm LANGUAGES CXX CUDA<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"3\"></td><td><pre></pre></td></tr><tr><td data-num=\"4\"></td><td><pre><span class=\"token keyword\">set</span><span class=\"token punctuation\">(</span><span class=\"token variable\">CMAKE_CUDA_STANDARD</span> <span class=\"token number\">20</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"5\"></td><td><pre><span class=\"token keyword\">set</span><span class=\"token punctuation\">(</span><span class=\"token variable\">CMAKE_CUDA_FLAGS</span> <span class=\"token string\">\"-O3\"</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"6\"></td><td><pre><span class=\"token comment\"># For debug</span></pre></td></tr><tr><td data-num=\"7\"></td><td><pre><span class=\"token comment\"># set(CMAKE_CUDA_FLAGS \"-g -G\")</span></pre></td></tr><tr><td data-num=\"8\"></td><td><pre><span class=\"token comment\"># For Nsight Compute Profiling</span></pre></td></tr><tr><td data-num=\"9\"></td><td><pre><span class=\"token comment\"># set (CMAKE_CUDA_FLAGS \"$&#123;CMAKE_CUDA_FLAGS&#125; -lineinfo\")</span></pre></td></tr><tr><td data-num=\"10\"></td><td><pre></pre></td></tr><tr><td data-num=\"11\"></td><td><pre><span class=\"token keyword\">find_package</span><span class=\"token punctuation\">(</span>CUDAToolkit REQUIRED<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"12\"></td><td><pre></pre></td></tr><tr><td data-num=\"13\"></td><td><pre><span class=\"token keyword\">add_executable</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">$&#123;</span><span class=\"token variable\">PROJECT_NAME</span><span class=\"token punctuation\">&#125;</span> main.cu</pre></td></tr><tr><td data-num=\"14\"></td><td><pre>        src/utils.cu</pre></td></tr><tr><td data-num=\"15\"></td><td><pre>        src/kernels.cu<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"16\"></td><td><pre></pre></td></tr><tr><td data-num=\"17\"></td><td><pre><span class=\"token comment\"># 可执行文件输出路径</span></pre></td></tr><tr><td data-num=\"18\"></td><td><pre><span class=\"token comment\"># https://gist.github.com/gavinb/c993f71cf33d2354515c4452a3f8ef30</span></pre></td></tr><tr><td data-num=\"19\"></td><td><pre><span class=\"token keyword\">set</span><span class=\"token punctuation\">(</span><span class=\"token variable\">EXECUTABLE_OUTPUT_PATH</span> <span class=\"token punctuation\">$&#123;</span><span class=\"token variable\">PROJECT_SOURCE_DIR</span><span class=\"token punctuation\">&#125;</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"20\"></td><td><pre></pre></td></tr><tr><td data-num=\"21\"></td><td><pre><span class=\"token keyword\">set_target_properties</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">$&#123;</span><span class=\"token variable\">PROJECT_NAME</span><span class=\"token punctuation\">&#125;</span> <span class=\"token namespace\">PROPERTIES</span></pre></td></tr><tr><td data-num=\"22\"></td><td><pre>        <span class=\"token property\">CUDA_SEPARABLE_COMPILATION</span> <span class=\"token boolean\">ON</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"23\"></td><td><pre><span class=\"token comment\"># 查询 compute capability https://developer.nvidia.com/cuda-gpus</span></pre></td></tr><tr><td data-num=\"24\"></td><td><pre><span class=\"token keyword\">set_target_properties</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">$&#123;</span><span class=\"token variable\">PROJECT_NAME</span><span class=\"token punctuation\">&#125;</span> <span class=\"token namespace\">PROPERTIES</span> CUDA_ARCHITECTURES <span class=\"token string\">\"86\"</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"25\"></td><td><pre></pre></td></tr><tr><td data-num=\"26\"></td><td><pre><span class=\"token comment\"># 配置头文件搜索路径</span></pre></td></tr><tr><td data-num=\"27\"></td><td><pre><span class=\"token comment\"># 配置 CUDA 相关库头文件</span></pre></td></tr><tr><td data-num=\"28\"></td><td><pre><span class=\"token comment\"># 参考</span></pre></td></tr><tr><td data-num=\"29\"></td><td><pre><span class=\"token comment\"># https://stackoverflow.com/questions/51756562/obtaining-the-cuda-include-dir-in-c-targets-with-native-cuda-support-cmake</span></pre></td></tr><tr><td data-num=\"30\"></td><td><pre><span class=\"token keyword\">target_include_directories</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">$&#123;</span><span class=\"token variable\">PROJECT_NAME</span><span class=\"token punctuation\">&#125;</span> <span class=\"token namespace\">PRIVATE</span> <span class=\"token punctuation\">$&#123;</span><span class=\"token variable\">CMAKE_CUDA_TOOLKIT_INCLUDE_DIRECTORIES</span><span class=\"token punctuation\">&#125;</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"31\"></td><td><pre><span class=\"token keyword\">target_include_directories</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">$&#123;</span><span class=\"token variable\">PROJECT_NAME</span><span class=\"token punctuation\">&#125;</span> <span class=\"token namespace\">PUBLIC</span> <span class=\"token punctuation\">$&#123;</span><span class=\"token variable\">PROJECT_SOURCE_DIR</span><span class=\"token punctuation\">&#125;</span>/src<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"32\"></td><td><pre></pre></td></tr><tr><td data-num=\"33\"></td><td><pre><span class=\"token comment\"># link cudart cublas</span></pre></td></tr><tr><td data-num=\"34\"></td><td><pre><span class=\"token keyword\">target_link_libraries</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">$&#123;</span><span class=\"token variable\">PROJECT_NAME</span><span class=\"token punctuation\">&#125;</span> <span class=\"token namespace\">PRIVATE</span> <span class=\"token inserted class-name\">CUDA::cublas</span><span class=\"token punctuation\">)</span></pre></td></tr></table></figure><p>此外，需要在  <code>Settings -&gt; Build,Execution,Deployment -&gt; CMake</code>  中的  <code>CMake options</code>  中添加以下参数：</p>\n<figure class=\"highlight txt\"><figcaption data-lang=\"txt\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre>-DCMAKE_CUDA_COMPILER=/usr/local/cuda/bin/nvcc</pre></td></tr></table></figure><h3 id=\"cublas-库接口调用\"><a class=\"markdownIt-Anchor\" href=\"#cublas-库接口调用\">#</a> cuBLAS 库接口调用</h3>\n<p>使用  <code>cuBLAS</code>  的矩阵乘法接口  <code>cublasSgemm</code>  函数时，需要注意其参数传递<sup class=\"footnote-ref\"><a href=\"#fn8\" id=\"fnref8\">[8]</a></sup>。</p>\n<p>具体的封装参考如下：</p>\n<figure class=\"highlight c\"><figcaption data-lang=\"c\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre><span class=\"token keyword\">void</span> <span class=\"token function\">test_cublas</span><span class=\"token punctuation\">(</span><span class=\"token class-name\">cublasHandle_t</span> handle<span class=\"token punctuation\">,</span> <span class=\"token keyword\">int</span> M<span class=\"token punctuation\">,</span> <span class=\"token keyword\">int</span> N<span class=\"token punctuation\">,</span> <span class=\"token keyword\">int</span> K<span class=\"token punctuation\">,</span></pre></td></tr><tr><td data-num=\"2\"></td><td><pre>                 <span class=\"token keyword\">float</span> alpha<span class=\"token punctuation\">,</span> <span class=\"token keyword\">float</span> <span class=\"token operator\">*</span>A<span class=\"token punctuation\">,</span> <span class=\"token keyword\">float</span> <span class=\"token operator\">*</span>B<span class=\"token punctuation\">,</span> <span class=\"token keyword\">float</span> beta<span class=\"token punctuation\">,</span> <span class=\"token keyword\">float</span> <span class=\"token operator\">*</span>C<span class=\"token punctuation\">)</span> <span class=\"token punctuation\">&#123;</span></pre></td></tr><tr><td data-num=\"3\"></td><td><pre>    <span class=\"token comment\">//cublas 列主序计算：https://www.cnblogs.com/cuancuancuanhao/p/7763256.html</span></pre></td></tr><tr><td data-num=\"4\"></td><td><pre>    <span class=\"token function\">cublasSgemm</span><span class=\"token punctuation\">(</span>handle<span class=\"token punctuation\">,</span> CUBLAS_OP_N<span class=\"token punctuation\">,</span> CUBLAS_OP_N<span class=\"token punctuation\">,</span> N<span class=\"token punctuation\">,</span> M<span class=\"token punctuation\">,</span> K<span class=\"token punctuation\">,</span> <span class=\"token operator\">&amp;</span>alpha<span class=\"token punctuation\">,</span> B<span class=\"token punctuation\">,</span> N<span class=\"token punctuation\">,</span> A<span class=\"token punctuation\">,</span> K<span class=\"token punctuation\">,</span> <span class=\"token operator\">&amp;</span>beta<span class=\"token punctuation\">,</span> C<span class=\"token punctuation\">,</span> N<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span></pre></td></tr><tr><td data-num=\"5\"></td><td><pre><span class=\"token punctuation\">&#125;</span></pre></td></tr></table></figure><h3 id=\"cuda-程序性能-profiling\"><a class=\"markdownIt-Anchor\" href=\"#cuda-程序性能-profiling\">#</a> CUDA 程序性能 Profiling</h3>\n<p>CUDA 性能 profiling 可以去官网<sup class=\"footnote-ref\"><a href=\"#fn9\" id=\"fnref9\">[9]</a></sup>下载 Nsight Compute 和 Nsight System 工具。其中 System 用于粗粒度的性能分析，Compute 用于对核函数的细粒度性能分析。</p>\n<hr class=\"footnotes-sep\">\n<section class=\"footnotes\">\n<ol class=\"footnotes-list\">\n<li id=\"fn1\" class=\"footnote-item\"><p>实际上，对于非 4 的倍数的元素个数，也是可以使用  <code>float4</code>  来访存的，但是在边界条件判断上需要更细致的处理，对性能也会有一定的影响。 <a href=\"#fnref1\" class=\"footnote-backref\">↩︎</a></p>\n</li>\n<li id=\"fn2\" class=\"footnote-item\"><p>图片来自于这篇知乎的<a href=\"https://zhuanlan.zhihu.com/p/518857175\">矩阵优化笔记</a> <a href=\"#fnref2\" class=\"footnote-backref\">↩︎</a></p>\n</li>\n<li id=\"fn3\" class=\"footnote-item\"><p><a href=\"http://zh0ngtian.tech/posts/96744e8c.html\">CUDA 知识点：bank 冲突 | CUDA - zhongtian’s blog (zh0ngtian.tech)</a> <a href=\"#fnref3\" class=\"footnote-backref\">↩︎</a></p>\n</li>\n<li id=\"fn4\" class=\"footnote-item\"><p><a href=\"https://zhuanlan.zhihu.com/p/481600052\">深入浅出 GPU 优化系列：GEMM 优化（三） - 知乎 (zhihu.com)</a> <a href=\"#fnref4\" class=\"footnote-backref\">↩︎</a></p>\n</li>\n<li id=\"fn5\" class=\"footnote-item\"><p><a href=\"https://zhuanlan.zhihu.com/p/518857175\">CUDA SGEMM 矩阵乘法优化笔记 —— 从入门到 cublas - 知乎 (zhihu.com)</a> <a href=\"#fnref5\" class=\"footnote-backref\">↩︎</a></p>\n</li>\n<li id=\"fn6\" class=\"footnote-item\"><p><a href=\"https://github.com/wangzyon/NVIDIA_SGEMM_PRACTICE\">wangzyon/NVIDIA_SGEMM_PRACTICE: Step-by-step optimization of CUDA SGEMM (github.com)</a> <a href=\"#fnref6\" class=\"footnote-backref\">↩︎</a></p>\n</li>\n<li id=\"fn7\" class=\"footnote-item\"><p><a href=\"https://siboehm.com/articles/22/CUDA-MMM\">How to Optimize a CUDA Matmul Kernel for cuBLAS-like Performance: a Worklog (siboehm.com)</a> <a href=\"#fnref7\" class=\"footnote-backref\">↩︎</a></p>\n</li>\n<li id=\"fn8\" class=\"footnote-item\"><p><a href=\"https://www.cnblogs.com/cuancuancuanhao/p/7763256.html\">有关 CUBLAS 中的矩阵乘法函数 - 爨爨爨好 - 博客园 (cnblogs.com)</a> <a href=\"#fnref8\" class=\"footnote-backref\">↩︎</a></p>\n</li>\n<li id=\"fn9\" class=\"footnote-item\"><p><a href=\"https://developer.nvidia.com/gameworksdownload#?dn=nsight-systems-2023-3\">Gameworks Download Center | NVIDIA Developer</a> <a href=\"#fnref9\" class=\"footnote-backref\">↩︎</a></p>\n</li>\n</ol>\n</section>\n",
            "tags": [
                "Computer-Science",
                "Algorithm",
                "CUDA"
            ]
        },
        {
            "id": "https://linn-ylz.com/Computer-Science/Configs/clion-wsl2-cuda-configs/",
            "url": "https://linn-ylz.com/Computer-Science/Configs/clion-wsl2-cuda-configs/",
            "title": "通过 CLion 在 WSL2 的 CUDA 环境下使用 libtorch",
            "date_published": "2021-10-08T15:32:30.000Z",
            "content_html": "<h1 id=\"说明\"><a class=\"markdownIt-Anchor\" href=\"#说明\">#</a> 说明</h1>\n<p>本文记录使用  <code>CLion</code>  的  <code>IDE</code>  环境，使用  <code>WSL2</code>  环境下的  <code>CUDA</code>  来调用  <code>PyTorch</code>  的  <code>libtorch</code>  库内容。</p>\n<p><code>libtorch</code>  是  <code>PyTorch</code>  框架提供的  <code>C++</code>  接口，因为最近的课题对性能有比较高的要求，并且有自定义算子的需求，所以需要用到相关的代码。</p>\n<p><code>WSL2</code>  下的  <code>CUDA</code>  环境配置可以参考<a href=\"/Computer-Science/Configs/wsl2-cuda-configs/\" title=\"WSL2 下的 CUDA 配置\">这篇文章</a>。</p>\n<h1 id=\"配置\"><a class=\"markdownIt-Anchor\" href=\"#配置\">#</a> 配置</h1>\n<h2 id=\"下载-libtorch\"><a class=\"markdownIt-Anchor\" href=\"#下载-libtorch\">#</a> 下载  <code>libtorch</code></h2>\n<p>从  <code>PyTorch</code>  的<a href=\"https://pytorch.org/\">官方网站</a>下载自己所需版本的  <code>libtorch</code>  。注意和自己的  <code>CUDA</code>  版本也要对应。</p>\n<h2 id=\"clion-配置\"><a class=\"markdownIt-Anchor\" href=\"#clion-配置\">#</a>  <code>CLion</code>  配置</h2>\n<p>打开  <code>CLion</code>  新建一个  <code>CUDA executable</code>  工程。然后修改  <code>CMakeLists.txt</code>  和  <code>CMake</code>  的相关配置。</p>\n<h3 id=\"wsl2-环境配置\"><a class=\"markdownIt-Anchor\" href=\"#wsl2-环境配置\">#</a>  <code>WSL2</code>  环境配置</h3>\n<p>参考这篇<a href=\"https://zhuanlan.zhihu.com/p/272522594\">知乎文章</a>中的<strong>第三步 - 配置 Clion 内的 Toolchains</strong> 这一部分的内容。</p>\n<h3 id=\"cmake-配置\"><a class=\"markdownIt-Anchor\" href=\"#cmake-配置\">#</a>  <code>CMake</code>  配置</h3>\n<p>按照  <code>File</code> -&gt; <code>Settings</code> -&gt; <code>Build,Execution,Development</code> -&gt; <code>CMake</code>  的路径，在其中的  <code>CMake options</code>  选项中添加  <code>-DCMAKE_CUDA_COMPILER=/usr/local/cuda/bin/nvcc</code>  的内容。如下图所示：</p>\n<p><img loading=\"lazy\" data-src=\"/images/clion-wsl2-cuda-configs-cmake-options.jpg\" alt=\"CMake options\"></p>\n<h3 id=\"修改-cmakeliststxt\"><a class=\"markdownIt-Anchor\" href=\"#修改-cmakeliststxt\">#</a> 修改  <code>CMakeLists.txt</code></h3>\n<p>首先将下载好的  <code>libtorch</code>  文件解压，这里我解压到了本文件夹下的  <code>libtorch</code>  文件夹中。在  <code>CMakeLists.txt</code>  文件中设置  <code>CMAKE_PREFIX_PATH</code>  变量，添加  <code>libtorch</code>  的路径。添加  <code>find_package(Torch REQUIRED)</code>  语句，以及  <code>target_link_libraries(ProjectName &quot;$&#123;TORCH_LIBRARIES&#125;&quot;)</code> ，这两行是最关键的内容。</p>\n<figure class=\"highlight cmake\"><figcaption data-lang=\"CMake\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre><span class=\"token keyword\">project</span><span class=\"token punctuation\">(</span>ProjectName CXX CUDA<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"2\"></td><td><pre><span class=\"token keyword\">set</span><span class=\"token punctuation\">(</span><span class=\"token variable\">CMAKE_PREFIX_PATH</span> libtorch<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"3\"></td><td><pre><span class=\"token keyword\">find_package</span><span class=\"token punctuation\">(</span>Torch REQUIRED<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"4\"></td><td><pre><span class=\"token keyword\">target_link_libraries</span><span class=\"token punctuation\">(</span>ProjectName <span class=\"token string\">\"<span class=\"token interpolation\"><span class=\"token punctuation\">$&#123;</span><span class=\"token variable\">TORCH_LIBRARIES</span><span class=\"token punctuation\">&#125;</span></span>\"</span><span class=\"token punctuation\">)</span></pre></td></tr></table></figure><p>上方的代码中省去了  <code>CLion</code>  中默认提供的内容，以便让内容更清晰。</p>\n<h3 id=\"代码测试\"><a class=\"markdownIt-Anchor\" href=\"#代码测试\">#</a> 代码测试</h3>\n<p>在工程中添加一个  <code>main.cpp</code>  文件，注意在  <code>CMakeLists.txt</code>  也要对应修改  <code>add_executable(ProjectName main.cpp)</code>  这一行的内容。</p>\n<p>在  <code>main.cpp</code>  中添加如下的测试代码：</p>\n<figure class=\"highlight cpp\"><figcaption data-lang=\"C++\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre><span class=\"token macro property\"><span class=\"token directive-hash\">#</span><span class=\"token directive keyword\">include</span> <span class=\"token string\">&lt;iostream></span></span></pre></td></tr><tr><td data-num=\"2\"></td><td><pre><span class=\"token macro property\"><span class=\"token directive-hash\">#</span><span class=\"token directive keyword\">include</span> <span class=\"token string\">&lt;torch/torch.h></span></span></pre></td></tr><tr><td data-num=\"3\"></td><td><pre></pre></td></tr><tr><td data-num=\"4\"></td><td><pre><span class=\"token keyword\">int</span> <span class=\"token function\">main</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">&#123;</span></pre></td></tr><tr><td data-num=\"5\"></td><td><pre>    torch<span class=\"token double-colon punctuation\">::</span>Tensor tensor <span class=\"token operator\">=</span> torch<span class=\"token double-colon punctuation\">::</span><span class=\"token function\">rand</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">&#123;</span><span class=\"token number\">2</span><span class=\"token punctuation\">,</span><span class=\"token number\">3</span><span class=\"token punctuation\">&#125;</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span></pre></td></tr><tr><td data-num=\"6\"></td><td><pre>    std<span class=\"token double-colon punctuation\">::</span>cout <span class=\"token operator\">&lt;&lt;</span> tensor <span class=\"token operator\">&lt;&lt;</span> std<span class=\"token double-colon punctuation\">::</span>endl<span class=\"token punctuation\">;</span></pre></td></tr><tr><td data-num=\"7\"></td><td><pre>    std<span class=\"token double-colon punctuation\">::</span>cout <span class=\"token operator\">&lt;&lt;</span> tensor<span class=\"token punctuation\">.</span><span class=\"token function\">cuda</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span> <span class=\"token operator\">&lt;&lt;</span> std<span class=\"token double-colon punctuation\">::</span>endl<span class=\"token punctuation\">;</span></pre></td></tr><tr><td data-num=\"8\"></td><td><pre>    <span class=\"token keyword\">return</span> <span class=\"token number\">0</span><span class=\"token punctuation\">;</span></pre></td></tr><tr><td data-num=\"9\"></td><td><pre><span class=\"token punctuation\">&#125;</span></pre></td></tr></table></figure><p>如果编译并运行成功，那么配置完成。</p>\n<h1 id=\"可能的错误\"><a class=\"markdownIt-Anchor\" href=\"#可能的错误\">#</a> 可能的错误</h1>\n<p>如果碰到  <code>PyTorch requires cuDNN 7 and above.</code>  这一问题，可以参考这个 <a href=\"https://github.com/pytorch/pytorch/issues/40965\"> <code>GitHub</code>  链接</a>。问题的原因在于无法识别系统中的  <code>cuDNN</code>  版本。我自己碰到这个问题的原因是没有把  <code>cuDNN</code>  中的  <code>cudnn_version.h</code>  这一头文件复制到对应位置，在复制之后问题解决。</p>\n",
            "tags": [
                "Computer-Science",
                "CUDA",
                "Configs",
                "WSL2",
                "CLion",
                "PyTorch"
            ]
        },
        {
            "id": "https://linn-ylz.com/Computer-Science/Configs/wsl2-cuda-configs/",
            "url": "https://linn-ylz.com/Computer-Science/Configs/wsl2-cuda-configs/",
            "title": "WSL2 下的 CUDA 配置",
            "date_published": "2021-10-08T14:56:26.000Z",
            "content_html": "<h1 id=\"说明\"><a class=\"markdownIt-Anchor\" href=\"#说明\">#</a> 说明</h1>\n<p>本文记录  <code>Windows</code>  环境下  <code>WSL2</code>  系统中配置  <code>CUDA</code>  环境的过程。配置过程主要参考这篇<a href=\"https://zhuanlan.zhihu.com/p/350399229\">知乎文章</a>以及<a href=\"https://docs.nvidia.com/cuda/wsl-user-guide/index.html\">官方文档</a>。</p>\n<p>本文内容中省去在  <code>Windows</code>  下安装  <code>WSL2</code>  的过程，这里默认已经安装该环境。如果没有安装  <code>WSL2</code> ，可以参考官方文档中提供的说明。</p>\n<h1 id=\"配置\"><a class=\"markdownIt-Anchor\" href=\"#配置\">#</a> 配置</h1>\n<h2 id=\"安装驱动\"><a class=\"markdownIt-Anchor\" href=\"#安装驱动\">#</a> 安装驱动</h2>\n<p>参考官方文档中的 <a href=\"https://docs.nvidia.com/cuda/wsl-user-guide/index.html#:~:text=Release%20Preview%20Channel.-,2.3.%C2%A0Installing%20NVIDIA%20Windows%20Drivers%20for%20CUDA%2C%20DirectX%2C%20and%20DirectML%20Support,-Download%20the%20NVIDIA\">2.3 小节</a>。</p>\n<p>下载好驱动之后直接安装，安装选项均为默认值。</p>\n<h2 id=\"安装-cuda\"><a class=\"markdownIt-Anchor\" href=\"#安装-cuda\">#</a> 安装  <code>CUDA</code></h2>\n<p>参考官方文档中的 <a href=\"https://docs.nvidia.com/cuda/wsl-user-guide/index.html#ch03a-setting-up-cuda\">2.6 小节</a>。文档中提供了几种可选的方法，任选一种即可，如果全部执行一遍反而可能会出问题。我自己选择的是  <code>Installation of CUDA Toolkit using WSL-Ubuntu Package</code>  这一节中的方法。依照后续的指令来看， <code>WSL2</code>  需要安装  <code>Ubuntu-20.04</code>  的版本。</p>\n<p>首先依次执行以下指令：</p>\n<figure class=\"highlight bash\"><figcaption data-lang=\"bash\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre><span class=\"token function\">wget</span> https://developer.download.nvidia.com/compute/cuda/repos/wsl-ubuntu/x86_64/cuda-wsl-ubuntu.pin</pre></td></tr><tr><td data-num=\"2\"></td><td><pre><span class=\"token function\">sudo</span> <span class=\"token function\">mv</span> cuda-wsl-ubuntu.pin /etc/apt/preferences.d/cuda-repository-pin-600</pre></td></tr><tr><td data-num=\"3\"></td><td><pre><span class=\"token function\">wget</span> https://developer.download.nvidia.com/compute/cuda/11.4.0/local_installers/cuda-repo-wsl-ubuntu-11-4-local_11.4.0-1_amd64.deb</pre></td></tr><tr><td data-num=\"4\"></td><td><pre><span class=\"token function\">sudo</span> dpkg <span class=\"token parameter variable\">-i</span> cuda-repo-wsl-ubuntu-11-4-local_11.4.0-1_amd64.deb</pre></td></tr><tr><td data-num=\"5\"></td><td><pre><span class=\"token function\">sudo</span> apt-key <span class=\"token function\">add</span> /var/cuda-repo-wsl-ubuntu-11-4-local/7fa2af80.pub</pre></td></tr><tr><td data-num=\"6\"></td><td><pre><span class=\"token function\">sudo</span> <span class=\"token function\">apt-get</span> update</pre></td></tr><tr><td data-num=\"7\"></td><td><pre><span class=\"token function\">sudo</span> <span class=\"token function\">apt-get</span> <span class=\"token parameter variable\">-y</span> <span class=\"token function\">install</span> cuda</pre></td></tr></table></figure><p>上述指令中安装的  <code>CUDA</code>  版本是  <code>11.4</code>  的，虽然我自己的  <code>Windows</code>  中安装的  <code>CUDA</code>  版本是  <code>10.1</code> ，但是好像不匹配也并无大碍。安装过程中可以将  <code>apt</code>  的源更换为阿里提供的镜像，具体更改方法可以参考此<a href=\"https://cloud.tencent.com/developer/article/1538304\">链接</a>。</p>\n<p>安装完成后，修改  <code>WSL2</code>  系统的环境变量。通常是在  <code>~/.bashrc</code>  文件中添加如下内容：</p>\n<figure class=\"highlight bash\"><figcaption data-lang=\"bash\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre><span class=\"token builtin class-name\">export</span> <span class=\"token assign-left variable\">CUDA_HOME</span><span class=\"token operator\">=</span>/usr/local/cuda</pre></td></tr><tr><td data-num=\"2\"></td><td><pre><span class=\"token builtin class-name\">export</span> <span class=\"token assign-left variable\"><span class=\"token environment constant\">PATH</span></span><span class=\"token operator\">=</span><span class=\"token environment constant\">$PATH</span><span class=\"token builtin class-name\">:</span><span class=\"token variable\">$CUDA_HOME</span>/bin</pre></td></tr><tr><td data-num=\"3\"></td><td><pre><span class=\"token builtin class-name\">export</span> <span class=\"token assign-left variable\">LD_LIBRARY_PATH</span><span class=\"token operator\">=</span>/usr/local/cuda-11.4/lib64<span class=\"token variable\">$&#123;LD_LIBRARY_PATH<span class=\"token operator\">:+</span><span class=\"token operator\">:</span>$&#123;LD_LIBRARY_PATH&#125;</span><span class=\"token punctuation\">&#125;</span></pre></td></tr></table></figure><p>我自己因为安装了  <code>zsh</code>  中断，所以我在  <code>~/.zshrc</code>  文件中添加上述内容。注意其中的  <code>CUDA</code>  版本号和自己的版本对应。</p>\n<p>上述修改完成后，在终端输入如下指令：</p>\n<figure class=\"highlight bash\"><figcaption data-lang=\"bash\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre>nvcc <span class=\"token parameter variable\">--version</span></pre></td></tr></table></figure><p>如果得到如下类似的输出说明安装成功了：</p>\n<p><img loading=\"lazy\" data-src=\"/images/wsl2-cuda-configs-nvcc-version.jpg\" alt=\"nvcc version\"></p>\n<h2 id=\"安装-cudnn\"><a class=\"markdownIt-Anchor\" href=\"#安装-cudnn\">#</a> 安装  <code>cuDNN</code></h2>\n<p>在<a href=\"com/rdp/cudnn-download\">官网</a>下载和  <code>CUDA</code>  对应的  <code>cuDNN</code>  版本。可能需要预先注册账号。下载时选择  <code>cuDNN Library for Linux (x86)</code> 。</p>\n<p>下载完成后使用如下指令解压，并将文件移动到对应的文件夹：</p>\n<figure class=\"highlight bash\"><figcaption data-lang=\"bash\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre><span class=\"token function\">tar</span> <span class=\"token parameter variable\">-zxvf</span> cudnn-11.4-linux-x64-v8.2.4.15.tgz</pre></td></tr><tr><td data-num=\"2\"></td><td><pre><span class=\"token function\">sudo</span> <span class=\"token function\">cp</span> <span class=\"token parameter variable\">-P</span> cuda/lib64/libcudnn* /usr/local/cuda-11.4/lib64/</pre></td></tr><tr><td data-num=\"3\"></td><td><pre><span class=\"token function\">sudo</span> <span class=\"token function\">cp</span>  cuda/include/cudnn* /usr/local/cuda-11.4/include/</pre></td></tr></table></figure><p>然后为所有文件设置权限：</p>\n<figure class=\"highlight bash\"><figcaption data-lang=\"bash\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre><span class=\"token function\">sudo</span> <span class=\"token function\">chmod</span> a+r /usr/local/cuda-11.0/include/cudnn*</pre></td></tr><tr><td data-num=\"2\"></td><td><pre><span class=\"token function\">sudo</span> <span class=\"token function\">chmod</span> a+r /usr/local/cuda-11.0/lib64/libcudnn*</pre></td></tr></table></figure><h2 id=\"验证安装\"><a class=\"markdownIt-Anchor\" href=\"#验证安装\">#</a> 验证安装</h2>\n<p>执行以下指令：</p>\n<figure class=\"highlight bash\"><figcaption data-lang=\"bash\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre><span class=\"token builtin class-name\">cd</span> /usr/local/cuda/samples/4_Finance/BlackScholes</pre></td></tr><tr><td data-num=\"2\"></td><td><pre><span class=\"token function\">sudo</span> <span class=\"token function\">make</span></pre></td></tr><tr><td data-num=\"3\"></td><td><pre>./BlackScholes</pre></td></tr></table></figure><p>如果得到  <code>Test passed</code>  的输出说明安装成功：</p>\n<p><img loading=\"lazy\" data-src=\"/images/wsl2-cuda-configs-check-cuda-installation.jpg\" alt=\"check cuda installation\"></p>\n",
            "tags": [
                "Computer-Science",
                "CUDA",
                "Configs",
                "WSL"
            ]
        }
    ]
}